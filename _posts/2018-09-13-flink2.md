---
layout: post
title:  "初识flink2"
date:   "2018-09-13 10:00:00"
---

续上一篇Blog，我们从网上下载二进制的Flink包，在其外围进行一些脚本改造，

docker镜像的开发，可以让我们把Flink在K8s上跑起来了，接下来就是要接触Flink的源码了。

说道源码还是挺头大的一个事，目前apache下面的跟大数据相关的项目你下载下来就会发现

子项目子模块非常多，maven编译一下少说十几分钟，hadoop这种级别的项目编译1个小时都正常。

## Flink分支

将Flink从Git上clone下来，选择一个你中意的分支或者tag，注意Flink的分支和tag的命名规则。

因为我们后面要持续对Flink进行开发，而且要不断合并社区的更新，这里需要一些git的技巧。

我们主要是在1.5.X这个系列上进行开发，所以将Flink项目的1.5分支同步到我们自己的仓库里，

如果后面Flink发布了1.5.4的小版本，也会合并到1.5的分支上，我们只需要同步这些更新到我们

的仓库即可。

## 打包

Flink官网给了一个打包的命令，在我和同事的笔记本上执行了一下，大概20分钟左右。

```
mvn package -DskipTests -Dhadoop.version=2.7.X

```

因为初步接触Flink，我们打包非常频繁，调试一些问题增加日志之类的需求，所以这个打包

的速度是无法接受的，大概分析了一下他的打包过程，于是修改了一下打包的命令。


```
mvn package -DskipTests -Dcheckstyle.skip=true -Dhadoop.version=2.7.X
```

增加了忽略checkstyple过程，速度提升了一倍，十分钟左右可以打包完成。

如果你还想继续加速打包，可以考虑对pom进行裁剪，比如你不用mesos、yarn这些模块，

或者你不需要各种connect，也是可以忽略的。但是注意maven的依赖，忽略的子项目有可能

包含了Flink必须的一些依赖包，而且Flink的pom中大量的使用了shade，处理起来非常麻烦。

注意，如果你在主POM里裁剪掉了部分的module，一定要记得在dist子项目中也去掉相关的

dependency，要不然它会从maven仓库再下载一份。

## 类冲突

测试自定义版Flink的时候，我们与类冲突搏斗了三四天，主要的报错是noclassdeffounderror。

网上搜索相关错误，会告诉你与此类的static部分有关系，我们碰到的问题大多是hadoop有关的，

每次处理hadoop的依赖都是一万个XXX。因为公司的现状，我们需要使用定制化的hadoop。

最终我们在原版打包的基础上，通过控制classpath里jar的顺序，将公司的hdfs替换上去了。
