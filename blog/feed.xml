<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 27 Apr 2021 13:17:10 +0800</pubDate>
    <lastBuildDate>Tue, 27 Apr 2021 13:17:10 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>ETH合约</title>
        <description>&lt;p&gt;最近开始接触了一下ETH的智能合约，主要是通过Chainlink这个优秀的预言机项目。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;合约的特点&lt;/h2&gt;

&lt;p&gt;ETH上的合约主要是用Solidity语言来开发的，使用下来感觉语言本身还不是很成熟，&lt;/p&gt;

&lt;p&gt;数据结构比较单一，适合实现简单的计算逻辑和数据存储。&lt;/p&gt;

&lt;p&gt;与其他开发项目相比，代码一旦发布后很难修改，代码“性能”需要特别关注。&lt;/p&gt;

&lt;p&gt;合约代码在执行过程中依据Op来计算需要消耗的gas费，所以代码的质量非常关键。&lt;/p&gt;

&lt;p&gt;在我们了解Chainlink项目和开发自己的合约时碰到了下面几个案例，分享一下。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;写入与更新&lt;/h3&gt;

&lt;p&gt;Chainlink的历史数据是保存在合约的一个Map中，key是roundid，value是价格。&lt;/p&gt;

&lt;p&gt;在我们测试Map的写入与更新时发现，第一次写入某一个key和后面更新key的Value，&lt;/p&gt;

&lt;p&gt;费用差距是巨大的，大概是2倍左右。我们在设计类似保存历史数据的环节时，采用了&lt;/p&gt;

&lt;p&gt;循环key值，比如自增ID对1024取模，这样只有第一轮是insert，第1025次之后就是&lt;/p&gt;

&lt;p&gt;update了，费用会降低下来，在合约里只能查询一段时间的历史记录，之前的会被覆盖。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;代理&lt;/h3&gt;

&lt;p&gt;因为链上的合约一旦部署成功后，就不能修改了，如果想要升级就要使用新的合约地址了，&lt;/p&gt;

&lt;p&gt;这对外部依赖是非常不友好的。参考Chainlink和Openzapplin项目，一般都是采用代理&lt;/p&gt;

&lt;p&gt;模式将接口和实现解耦和，接口层记录了实现合约的地址，提供一个Update实现合约地址的&lt;/p&gt;

&lt;p&gt;方法，进行替换，来达到升级的目的。虽然可以实现，但是开发时非常繁琐。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;存储与计算分离&lt;/h3&gt;

&lt;p&gt;上面提到了升级的问题，如果你的合约里还保存了一些数据，那么在升级时也需要将其转移到&lt;/p&gt;

&lt;p&gt;新的合约里。部署合约是有费用成本的，如果在部署合约时，涉及到了大量的数据copy，&lt;/p&gt;

&lt;p&gt;这个成本会变得非常昂贵。代理模式只是解决了升级当中的持续稳定服务问题，在设计合约时，&lt;/p&gt;

&lt;p&gt;还需要将合约里的存储结构和计算逻辑进行解耦，一般我们只对计算逻辑进行升级，而存储部分&lt;/p&gt;

&lt;p&gt;不会移动，仅仅会修改一些写权限的控制，将新合约地址更新到存储数据的合约中去。&lt;/p&gt;
</description>
        <pubDate>Mon, 22 Feb 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-02-22-contract</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-02-22-contract</guid>
        
        
        <category>contract</category>
        
      </item>
    
      <item>
        <title>Master选举</title>
        <description>&lt;p&gt;今年的第一篇就写写Master的选举吧，在之前的工作经历中，我们经常碰到Master选举问题。&lt;/p&gt;

&lt;p&gt;比如Hbase、Hadoop的Master选举，都是通过Zookeeper来完成的，这几年比较流行K8s，&lt;/p&gt;

&lt;p&gt;很多组件的选举是通过ETCD来完成的。说到这需要补充一点背景知识，那就是Paxos和Raft，&lt;/p&gt;

&lt;p&gt;这里就不详细陈述了，自行搜索。&lt;/p&gt;

&lt;h2 id=&quot;redis&quot;&gt;通过Redis选举&lt;/h2&gt;

&lt;p&gt;不是任何时候我们都能使用ZK、ETCD来完成选举的，比如部署规模的限制。最近碰到了一个场景，&lt;/p&gt;

&lt;p&gt;需要进行Master的选举，但是部署规模非常小，无法引入其他组件来辅助，项目中有使用到Redis，&lt;/p&gt;

&lt;p&gt;于是开发了一个基于Redis的简易选举方案。&lt;/p&gt;

&lt;h3 id=&quot;redis-1&quot;&gt;如何利用Redis选举&lt;/h3&gt;

&lt;p&gt;网上有很多文章介绍，大体都是基于Redis的SetN指令的特性，进行一个分布式锁的争抢过程，&lt;/p&gt;

&lt;p&gt;抢到锁的即为Master。如果你使用过Redission的客户端，可以直接使用Rlock来完成这个工作。&lt;/p&gt;

&lt;p&gt;Redission中大量的封装了LuaScript，来完成一些事务性的工作。&lt;/p&gt;

&lt;h3 id=&quot;redis-2&quot;&gt;利用Redis选举的弊端&lt;/h3&gt;

&lt;p&gt;为了性能考量，在写入时只要主节点成功，就会返回True。所以在故障时，主从可能会不一致。&lt;/p&gt;

&lt;p&gt;在抢锁这个场景中，也就是会短暂出现两把锁。当然通过结构上的设计是可以尽量降低这个概率的，&lt;/p&gt;

&lt;p&gt;但无法彻底消除。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;选举的大致逻辑&lt;/h3&gt;

&lt;p&gt;1、 无锁时，争抢创建锁&lt;/p&gt;

&lt;p&gt;2、 有锁时，没有抢到锁的节点，观察等待锁消失&lt;/p&gt;

&lt;p&gt;3、 有锁时，抢到锁的节点，延续锁的TTL&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;代码示例&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while (true) {
            try {
                RBucket&amp;lt;String&amp;gt; currentLock = this.redis.getBucket(this.lockName, StringCodec.INSTANCE);
                String currentLockValue = currentLock.get();

                if (StringUtils.isBlank(currentLockValue)) {
                    if (log.isDebugEnabled()) {
                        log.debug(&quot;start election .&quot;);
                    }
                    boolean success = currentLock.trySet(this.deviceId, DURATION_TIME, TimeUnit.SECONDS);
                    if (log.isDebugEnabled()) {
                        log.debug(&quot;election result : &quot; + success);
                    }
                    update(success);
                    Util.sleepSec(10);
                } else {
                    long remainTime = currentLock.remainTimeToLive();
                    if (remainTime &amp;lt;= 0) {
                        continue;
                    }
                    String tValue = currentLock.get();
                    if (!currentLockValue.equals(tValue)) {
                        continue;
                    }

                    if (this.deviceId.equals(currentLockValue)) {
                        if (log.isDebugEnabled()) {
                            log.debug(&quot;I am master .&quot;);
                        }
                        if (remainTime &amp;gt;= TimeUnit.SECONDS.toMillis(DISPUTE_TIME)) {
                            currentLock.expire(DURATION_TIME, TimeUnit.SECONDS);
                            if (log.isDebugEnabled()) {
                                log.debug(&quot;renew lock ttl .&quot;);
                            }
                            update(true);
                        } else {
                            update(false);
                            if (log.isDebugEnabled()) {
                                log.debug(&quot;unstable .&quot;);
                            }
                        }
                        Util.sleepSec(10);
                    } else {
                        update(false);
                        if (log.isDebugEnabled()) {
                            log.debug(&quot;wait for next time .&quot;);
                        }
                        Util.sleepMS(remainTime);
                    }
                }
            } catch (Throwable e) {
                log.error(&quot;Election Error : &quot;, e);
                Util.sleepSec(1);
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jan 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-01-19-master</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-01-19-master</guid>
        
        
        <category>master</category>
        
      </item>
    
      <item>
        <title>2020年总结</title>
        <description>&lt;p&gt;2020年真的非常魔幻，也经历了很多变化。庆幸的是现在做的事情是自己喜欢的。&lt;/p&gt;

&lt;p&gt;以前都是写写总结，这次就写设想和展望吧。&lt;/p&gt;

&lt;p&gt;希望2021年能更新一下自己的Java知识，这几年一直在使用Java8，也是时候升级了。&lt;/p&gt;

&lt;p&gt;需要补充一点Go或者Rust的知识，看一些区块链项目的时候会用到。如果还有时间的话，&lt;/p&gt;

&lt;p&gt;Lua还需要捡起来了，未来也会用得上。&lt;/p&gt;

&lt;p&gt;2021年需要花点时间在机器学习的入门上，这方面之前没什么涉猎，可能会辛苦一点。&lt;/p&gt;

&lt;p&gt;之前几年的工作都和算法没什么关系，这方面需要多储备一点了。&lt;/p&gt;

&lt;p&gt;2021年需要多学习一些金融知识，尤其是期权和对冲相关的。&lt;/p&gt;

&lt;p&gt;之前几年都在做实时流计算方面的事，尤其是今年实时流计算非常的火热，但我并不看好这个方向。&lt;/p&gt;

&lt;p&gt;实时计算是个非常昂贵的事情，并不能普及在大多数无价值和意义的业务和数据上，完全是在浪费。&lt;/p&gt;

&lt;p&gt;真正有实时价值的业务其实非常的少，目前在跑的实时业务有很多是在滥竽充数，完成KPI而已。&lt;/p&gt;

&lt;p&gt;那些真正具有“实时”要求的业务，Flink也是无法满足的，因为他的实时能力是非常有限的。&lt;/p&gt;

&lt;p&gt;2021年我不会投入精力在这方面了，很有可能会转向CEP，也算是个延续吧。&lt;/p&gt;

&lt;p&gt;工作十年，大多实在研究技术本身，而非业务问题。从2021年开始，我会更关注问题本身，&lt;/p&gt;

&lt;p&gt;从另外一个角度来组合使用这些年的积累和认知。&lt;/p&gt;

&lt;p&gt;感谢各位看官，来年再见。&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Dec 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-12-30-summary</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-12-30-summary</guid>
        
        
        <category>summary</category>
        
      </item>
    
      <item>
        <title>double streaming 2</title>
        <description>&lt;p&gt;上期我们聊了双流的问题，接下来借着一个实际案例来看看。&lt;/p&gt;

&lt;p&gt;有两条信息流，一条是Tesla股票的K线行情变化，一条是用户设置的条件单记录。&lt;/p&gt;

&lt;p&gt;那么要如何设计一个流处理装置，来保证恰好一次计算呢？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;行情信息流&lt;/h2&gt;

&lt;p&gt;该流具备驱动流的特征，有单调性和持续性。因为一直有数据产生，所以不需要额外增加心跳数据包，&lt;/p&gt;

&lt;p&gt;只需要增加一个单调性的filter就可以了（当前数据的时间或者序号需要大于前一条）。当行情数据&lt;/p&gt;

&lt;p&gt;到达时会写入内存缓存中，该缓存会保持一段时间，后面会介绍它的用途。最后通过行情数据本身的&lt;/p&gt;

&lt;p&gt;时间戳来控制条件单记录的加载的时机。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;条件单信息流&lt;/h2&gt;

&lt;p&gt;该流的数据量比较小，而且可能局部乱序，为此增加了心跳数据包，代表时间进度。心跳数据包只包&lt;/p&gt;

&lt;p&gt;含一个时间戳，其含义是该信息流中不会再出现比此时间戳更早的数据了，在生成心跳包的时候我们&lt;/p&gt;

&lt;p&gt;可以刻意的delay几秒。这个和flink中的watermarket很相似。心跳包的数据到达时，可以触发过&lt;/p&gt;

&lt;p&gt;期行情缓存数据的清理工作。因为这些行情信息再也用不到了。条件单的数据到达时，如果早于行情&lt;/p&gt;

&lt;p&gt;当前的时间进度，那么就放在cache里，等待行情数据到达时触发其加载。如果晚于行情的当前的时&lt;/p&gt;

&lt;p&gt;间进度的话，就要触发一个特殊环节，利用行情缓存的历史数据进行计算，之后合并结果。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;上面两条流的处理方式就是前一篇Blog中提到的协调器，满足如下四个功能：&lt;/p&gt;

&lt;p&gt;驱动流缓存池、被动流缓存池、被动流增量加载方法、被流动回溯方法。&lt;/p&gt;

&lt;p&gt;具体代码可以在fevernova的markettracing中找到，这里就不多说了。&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Nov 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-11-19-doublestreaming</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-11-19-doublestreaming</guid>
        
        
        <category>streaming</category>
        
      </item>
    
      <item>
        <title>double streaming</title>
        <description>&lt;p&gt;今天聊聊双流的实时计算问题，我个人觉得算是流处理中最复杂的一个场景了。&lt;/p&gt;

&lt;p&gt;想要在两个Source同时作为input时，保证流处理的恰好一次计算，仅仅依靠chandy-lamport是不够的。&lt;/p&gt;

&lt;p&gt;两个Source的input交叉顺序是随机的行为，在业务上有严格的恰好一次要求，且代码还做不到&lt;/p&gt;

&lt;p&gt;顺序不敏感时，怎么办呢？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;合并流&lt;/h2&gt;

&lt;p&gt;最简单的办法是将两条流合并，将不确定的交叉行为给确定了,这样可以用chandy-lamport了。&lt;/p&gt;

&lt;p&gt;合并流会增加一个merge任务和一个新的kafka topic，相当于增加了一个环节、增加了一点延迟。&lt;/p&gt;

&lt;p&gt;虽然会浪费一点资源，但是简单高效。如果两个Source的Merge依据是Event Time，那么情况还&lt;/p&gt;

&lt;p&gt;要更复杂一些。单纯的把两条流Merge在一起并不能解决问题，还需要在一个时间窗口内进行缓冲排序。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;流转批&lt;/h2&gt;

&lt;p&gt;将流式处理转为批量处理也是可以解决这个问题的，以窗口1min为例。将两个Source的数据都&lt;/p&gt;

&lt;p&gt;缓存1min（内存里或者依赖外部存储），当窗口关闭时发起对这期间的数据进行处理。&lt;/p&gt;

&lt;p&gt;在处理时可指定某种确定的数据排序方法，保证处理顺序的一致性。这种方式只适用于数据量不大，&lt;/p&gt;

&lt;p&gt;对时效性要求不高的场景。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;限位器&lt;/h2&gt;

&lt;p&gt;不想合并出一个新的topic，也不想延迟太高，就需要在Streaming的模式下进行两个流的协调和缓冲。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;驱动流&lt;/h3&gt;

&lt;p&gt;首先，在两个Source中选出来一个，作为时间驱动的，要求是他的数据时间具备单调性，也就是有序的。&lt;/p&gt;

&lt;p&gt;在实际生产中，我们很难保证写入kafkaTopic里的数据一直单调有序，除非启用transaction。&lt;/p&gt;

&lt;p&gt;但是我个人觉得使用事务造成的问题远大于收益。我这里说的单调性和有序是相对的，应该叫整体有序，&lt;/p&gt;

&lt;p&gt;可以接受局部的重复和回退。当我们实时处理这个Source的数据时，有内存状态记录这上一条的时间&lt;/p&gt;

&lt;p&gt;或者序号进行过滤，一旦发生了回退或者重复的数据就直接跳过。这样我们在经过filter后，就得到了&lt;/p&gt;

&lt;p&gt;一条绝对有序的驱动数据流A，（后面简称为A）。注意，如果A在一定时间内没有数据产生，最好写入&lt;/p&gt;

&lt;p&gt;带有时间戳的心跳数据包，以方便时间管理的协调控制后。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;被动流&lt;/h3&gt;

&lt;p&gt;如果另外一个Source也是和驱动流一样，具备整体有序特征的话，就非常简单了。经过filter后，&lt;/p&gt;

&lt;p&gt;与A汇合入同一个Operator中，只需要按照两个流的时间进度进行控制，以A的时间为主，这个时候&lt;/p&gt;

&lt;p&gt;心跳数据包的作用就体现出来了，防止被动流的数据提前被加载进来。&lt;/p&gt;

&lt;p&gt;如果被动流的数据，不具备单调性，就需要建立缓冲空间，将被动流的数据变的有序起来。&lt;/p&gt;

&lt;p&gt;A可以适当延迟个几秒，等带被动流的窗口排序工作完成后再去驱动时间。同时也就是对被动流提出来&lt;/p&gt;

&lt;p&gt;新的要求，那就是虽然可以乱序，但是时效性必须高。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;协调器&lt;/h3&gt;

&lt;p&gt;一共需要四个组件：驱动流缓存池、被动流缓存池、被动流增量加载方法、被流动回溯方法。&lt;/p&gt;

&lt;p&gt;缓存驱动流最近N条数据，主要是给被动流严重delay数据进行回溯时使用的。&lt;/p&gt;

&lt;p&gt;如果被动数据没有严重delay，那么就写入到被动流缓冲池中。&lt;/p&gt;

&lt;p&gt;驱动流有新数据时，触发被流动缓冲池中的数据进行增量加载。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;上面提到的方案有很大的局限性，还需要进一步的实践的检验。&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Oct 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</guid>
        
        
        <category>streaming</category>
        
      </item>
    
      <item>
        <title>transaction</title>
        <description>&lt;p&gt;最近工作中大量的使用了Spring、Mybatis、JDBC的事务，这里稍作一下总结。&lt;/p&gt;

&lt;h2 id=&quot;springtransaction&quot;&gt;Spring的Transaction&lt;/h2&gt;

&lt;p&gt;现在Spring的Annotation就可以完成基本的事务配置，比起以前复杂的xml，确实方便了很多。&lt;/p&gt;

&lt;p&gt;网上能搜到很多介绍Spring-Transaction的，主要是讲事务的隔离级别和传播性，这里就不多说了。&lt;/p&gt;

&lt;p&gt;提醒大家去看看Spring-Transaction失效的N个原因，避免事务没有完整性的执行。&lt;/p&gt;

&lt;p&gt;我们犯的错是同class的非事务方法去调用事务方法，导致事务不起作用。&lt;/p&gt;

&lt;h2 id=&quot;jdbc&quot;&gt;JDBC事务&lt;/h2&gt;

&lt;p&gt;mysql有个参数是flush_tx_commit需要关注一下，可能会影响你的事务性能。&lt;/p&gt;

&lt;p&gt;事务中的操作肯定是串行的，所以还是尽量想办法让事务精简，能在事务外执行的尽量不要放进来。&lt;/p&gt;

&lt;p&gt;比如序列化、反序列化等耗时的操作，尽量提前准备好，再开启事务。单个事务的执行时间越短，&lt;/p&gt;

&lt;p&gt;多事务并发的性能才会更理想。在一些情况下，开启事务和逐个提交比起来会快一些，&lt;/p&gt;

&lt;p&gt;但不要为了追求这种性能而过分的扩大事务范围。锁的范围变大，大概率会与一些业务上的并发发生冲突，&lt;/p&gt;

&lt;p&gt;不利于整体性能的提升。&lt;/p&gt;

&lt;h2 id=&quot;mybatis&quot;&gt;Mybatis&lt;/h2&gt;

&lt;p&gt;这次项目中用的是mybatis-plus，在压测的时候关注了一下，性能确实很一般。&lt;/p&gt;

&lt;p&gt;但是因为项目本身的业务复杂性，直接使用jdbc确实很不方便。第一个性能问题就是分表plugin，&lt;/p&gt;

&lt;p&gt;做表名替换的开销比较大，从sql的参数中提取表名也可能比较慢。第二个性能问题就是通过mybatis&lt;/p&gt;

&lt;p&gt;处理数据，会导致比较频繁的ygc。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;之前并没有太多关于事务类型业务的开发经验，这次优化能提升两三倍还是很满意的。&lt;/p&gt;
</description>
        <pubDate>Sun, 27 Sep 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-09-27-transaction</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-09-27-transaction</guid>
        
        
        <category>transaction</category>
        
      </item>
    
      <item>
        <title>ta4j2</title>
        <description>&lt;p&gt;上期讲了我在造一个类似ta4j的轮子，这次讲讲造轮子过程中的一些体会。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;关于回调的使用场景&lt;/h2&gt;

&lt;p&gt;在我的实现中，回调是贯穿始终的，我之前使用这种模式的次数不多，稍微总结一下。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;粗粒度的K线可以由细粒度的K线回调触发更新，非常方便回测实现。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;指标可以由K线或者其他指标的回调触发更新，保证数据的实时更新。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;当K线触发完所有指标的更新后，会触发Rule的回调，进行Rule的判断。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;规则判断后如果为True，可触发规则结果的回调，比如发消息、更新趋势、信号等。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-1&quot;&gt;多依赖指标的回调问题&lt;/h2&gt;

&lt;p&gt;某些指标的计算依赖多个其他指标的计算结果，于是更新这个指标的回调就有了路径问题，比如MACD。&lt;/p&gt;

&lt;p&gt;可以看看PairIndicatorSeries这个源码，构造时会进行指标的回调血缘分析。&lt;/p&gt;

&lt;p&gt;多依赖指标的回调，并不需要人为设定，根据分析结果可自动选择最佳的触发时机（最近的共同父节点）。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;指标重用问题&lt;/h2&gt;

&lt;p&gt;如果两个指标都使用了某一条K线的MA(20)作为构成的一部分，那么这个MA(20)是可以共用的。&lt;/p&gt;

&lt;p&gt;这样可以极大的减少计算量和内存开销，最典型的就是取K线的Close，极为常用。&lt;/p&gt;

&lt;p&gt;指标在某一时刻无论重复计算多少次，其结果都是一样的。当然重复计算我们也想尽量避免，&lt;/p&gt;

&lt;p&gt;在回调中提供了一个sequence，可以辅助去重。&lt;/p&gt;

&lt;p&gt;指标的构造和相同功能节点的自动复用，目前这块设计是有问题的，还需要重构打磨。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;规则重用问题&lt;/h2&gt;

&lt;p&gt;上面提到的指标是可以复用的，但规则绝对不可以，在Manager中有是否使用过的检查。&lt;/p&gt;

&lt;p&gt;Rule在某一时刻重复判断，其结果可能是不一样的，比如翻转规则、连续N次等。&lt;/p&gt;

&lt;p&gt;举几个复杂规则的例子，有同时判断2条指标的规则，比如快慢指标的上穿判断；&lt;/p&gt;

&lt;p&gt;还有由两个规则叠加起来组成的规则集，比如逻辑与运算。规则比指标要略微复杂一点。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;订单与仓位&lt;/h2&gt;

&lt;p&gt;订单的止盈止损也是个复杂问题，比如简单的止盈止损、追踪止盈止损等。&lt;/p&gt;

&lt;p&gt;在波动幅度较大的标的物上，追踪止盈止损并不能起到很好的效果，需要谨慎使用。&lt;/p&gt;

&lt;p&gt;控制盈利率与仓位比重是相对合理的做法，这样才能相对安全的达到收益最大化。&lt;/p&gt;

&lt;p&gt;在回测中，经常有人会为了收益最大化而过度调节止盈止损，基本上都是过拟合效果。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;ta4j的话题就到此为止了，我个人认为简单的量化交易策略是不可能挣钱的，&lt;/p&gt;

&lt;p&gt;但是通过程序化的方式，做个辅助交易助手还是非常现实可行的。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Aug 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-08-18-ta4j2</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-08-18-ta4j2</guid>
        
        
        <category>ta4j</category>
        
      </item>
    
      <item>
        <title>ta4j</title>
        <description>&lt;p&gt;今天介绍一个比较有意思的java库叫&lt;a href=&quot;https://github.com/ta4j/ta4j&quot;&gt;ta4j&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;最近一段时间接触了一些跟程序化交易、自动交易有关的业务，每天跟k线、指标打交道，&lt;/p&gt;

&lt;p&gt;无意中在github上发现了一个叫ta4j的java库，虽然不是很成熟，但还是很有借鉴意义的。&lt;/p&gt;

&lt;p&gt;从综合成本上来说，不建议用java来搞程序化交易，python和nodejs更为合适一些，&lt;/p&gt;

&lt;p&gt;公共库更为成熟，而且更利于支持可视化的需求。&lt;/p&gt;

&lt;h2 id=&quot;ta4j&quot;&gt;ta4j主要提供了如下功能：&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;k线&lt;/li&gt;
    &lt;li&gt;指标&lt;/li&gt;
    &lt;li&gt;判断规则、规则的逻辑运算&lt;/li&gt;
    &lt;li&gt;策略&lt;/li&gt;
    &lt;li&gt;回测、报告&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section&quot;&gt;关于指标&lt;/h2&gt;

&lt;p&gt;k线的技术指标主要是基于k线值的算术运算得来的，比如均值、加权均值、差值、方差等。&lt;/p&gt;

&lt;p&gt;指标会随着k线的实时变化而变化，其表现形式跟K线是一样的，存储在一个时间序列数组里。&lt;/p&gt;

&lt;p&gt;ta4j在保存时间序列数据时采用的ArrayList，这个地方不是很好。当超过一定数量时，&lt;/p&gt;

&lt;p&gt;就需要淘汰最老的数据，会不断触发ArrayList的arraycopy，感觉换成ringbuffer更合理。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;关于规则、策略&lt;/h2&gt;

&lt;p&gt;基于K线和指标线的逻辑判断就是规则，比如在股票里我们常听说的多头排列。&lt;/p&gt;

&lt;p&gt;这种图形上的形态，需要转化为代码，成为一个识别规则(match)。ta4j里提供了一些常见的规则，&lt;/p&gt;

&lt;p&gt;比如交叉、向上突破、向下突破、阈值等等。&lt;/p&gt;

&lt;p&gt;因为在K线的使用和识别中，会应用到很多个规则的组合，所以规则需要支持逻辑运算(and/or/xor)。&lt;/p&gt;

&lt;p&gt;针对买入和卖出的一系列规则的集合，我们可以称之为策略，这个是整个程序交易的核心。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;关于回测&lt;/h2&gt;

&lt;p&gt;程序化交易里面回测是非常重要的一个环节，回测越接近真实，你的策略盈利的可能性就越大。&lt;/p&gt;

&lt;p&gt;最理想的回测就是将实时数据录制下来，这是最准的了。但是如此明细的数据是很难拿到的，&lt;/p&gt;

&lt;p&gt;大多数是用1min的k线替代明细数据。其实这样的数据是严重失真的，1min里的变化压缩为一个点。&lt;/p&gt;

&lt;p&gt;我一般的做法是将1min的k线点拆分为4个点，分别是开、高、低、收，依次写入数据集合进行测试。&lt;/p&gt;

&lt;p&gt;这样能尽量还原一个k线点的轨迹，比如一个K线点是上涨的，那就是开、低、高、收，依次变化。&lt;/p&gt;

&lt;p&gt;另外还要特别注意，在回测的时候用到的数据会不会是“未来的数据”，可能会让程序未卜先知。&lt;/p&gt;

&lt;p&gt;比如短线指标基于15min，中线是1hour的指标，在判断15min的指标规则时，1hour指标就是“未来”。&lt;/p&gt;

&lt;p&gt;我一般在回测的时候，其他粒度的k线会用1min的聚合而来，保持与1minK线的同步关系。&lt;/p&gt;

&lt;h2 id=&quot;watchdog-hubble&quot;&gt;watchdog-hubble&lt;/h2&gt;

&lt;p&gt;ta4j虽然给了我很多启发，但是问题还是非常多的。所以我自己造了一个轮子，放在watchdog下。&lt;/p&gt;

&lt;p&gt;结合上个月介绍的websocket和bark，我自己用起来还是非常顺手的。&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jul 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-07-20-ta4j</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-07-20-ta4j</guid>
        
        
        <category>ta4j</category>
        
      </item>
    
      <item>
        <title>websocket</title>
        <description>&lt;p&gt;最近一个多月在和websocket打交道，这次来总结一下最近一阶段的工作吧。&lt;/p&gt;

&lt;h2 id=&quot;hydra&quot;&gt;hydra&lt;/h2&gt;

&lt;p&gt;三月份写了一篇关于netty的blog，介绍了我写的一个小项目叫&lt;a href=&quot;https://github.com/peiliping/hydra&quot;&gt;hydra&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;经过这几个月的完善，已经可以作为一个websocket的压测工具了。&lt;/p&gt;

&lt;p&gt;这两次压测实践中，单实例可以施压5W个并发连接数，满足大多数测试需求。&lt;/p&gt;

&lt;p&gt;通过参数可以配置心跳消息、订阅指令等，满足业务测试的需求。&lt;/p&gt;

&lt;h2 id=&quot;watchdog&quot;&gt;watchdog&lt;/h2&gt;

&lt;p&gt;使用netty作为websocket的client，如果解决重连重试的问题呢？&lt;/p&gt;

&lt;p&gt;在实际业务中，要考虑网络不稳定导致的websocket中断问题。websocket中断后，&lt;/p&gt;

&lt;p&gt;要重新建立连接，还要将业务的订阅指令重新发送一遍。&lt;/p&gt;

&lt;p&gt;在netty的中断分为两种情况，一个是创建连接就直接失败了，一种是在运行中突然中断。&lt;/p&gt;

&lt;p&gt;这两种情况分别有回调的接口可以捕获，而后触发延迟重连。可以参考&lt;a href=&quot;https://github.com/peiliping/watchdog&quot;&gt;watchdog&lt;/a&gt;的实现。&lt;/p&gt;

&lt;h2 id=&quot;bark&quot;&gt;Bark&lt;/h2&gt;

&lt;p&gt;最近无意间发现了一个iOS的App叫Bark，可以自定义手机通知提醒的消息。&lt;/p&gt;

&lt;p&gt;举个例子，你写了一个爬虫监控实时获取某只股票的价格，当他发生剧烈波动的时候，&lt;/p&gt;

&lt;p&gt;给自己的手机发送一条提醒，来提醒自己关注股票。那么如何给手机发送免费的消息呢？&lt;/p&gt;

&lt;p&gt;Bark就可以满足这个需求，安装Bark的App后，你会获得一个Url（包含一个uuid）。&lt;/p&gt;

&lt;p&gt;执行这个Url，你的手机就会收到来自Bark的通知消息了，消息的内容来自Url参数。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;提醒助手&lt;/h2&gt;

&lt;p&gt;将watchdog和Bark结合在一起，实现了一个小功能。&lt;/p&gt;

&lt;p&gt;订阅Huobi的BTC行情信息，经过计算，将满足剧烈波动条件的消息通过Bark发送到手机上。&lt;/p&gt;
</description>
        <pubDate>Mon, 29 Jun 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-06-29-websocket</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-06-29-websocket</guid>
        
        
        <category>websocket</category>
        
        <category>netty</category>
        
      </item>
    
      <item>
        <title>state</title>
        <description>&lt;p&gt;这次来介绍一下fevernova的state功能，与flink的state功能很类似，&lt;/p&gt;

&lt;p&gt;flink的state是保证恰好一次计算的核心点，当然至少一次也需要state。&lt;/p&gt;

&lt;h2 id=&quot;fevernovastate&quot;&gt;fevernova的state用途&lt;/h2&gt;

&lt;p&gt;之前fevernova都是作为数据传输框架，对state的依赖并不高。&lt;/p&gt;

&lt;p&gt;需要state用来存储kafka的offset，或者binlog的filename和position。&lt;/p&gt;

&lt;p&gt;在实现kafka To HDFS模块的时候，也会将关闭的文件列表和commit保存在state里，&lt;/p&gt;

&lt;p&gt;减少重复文件的产生，实现恰好一次。类似于flink的rollingfilesink。&lt;/p&gt;

&lt;h2 id=&quot;state&quot;&gt;state保存的位置&lt;/h2&gt;

&lt;p&gt;因为只保存少量的meta信息，所以state就简单的保存在文件系统里。&lt;/p&gt;

&lt;p&gt;如果需要提高可用性，就通过类似Nas的方式进行目录挂载。这类方案都是非常成熟的。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;计算状态&lt;/h2&gt;

&lt;p&gt;在无意中，发现了一个开源项目&lt;a href=&quot;https://github.com/OpenHFT&quot;&gt;OpenHFT&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;其中的项目质量还是比较高的，利用其中的序列化、持久化的库进行state的保存非常方便。&lt;/p&gt;

&lt;p&gt;让内存中保存状态的对象实现WriteBytesMarshallable和ReadBytesMarshallable接口，&lt;/p&gt;

&lt;p&gt;根据需求自定义序列化和反序列化的方法，就可以完成state的读写操作。&lt;/p&gt;

&lt;p&gt;简单测试了一下性能还是非常好的。fevernova中的exchange模块中有具体的使用。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;去重&lt;/h2&gt;

&lt;p&gt;单纯依靠Chandy-Lamport算法实现的流计算框架并不能在实际需求中完全实现恰好一次计算。&lt;/p&gt;

&lt;p&gt;比如写入kafka的数据有重复，通常就在计算逻辑中去重，这也意味着更多的cpu和内存开销。&lt;/p&gt;

&lt;p&gt;fevernova在exchange模块中实现了一个基于Roaringbitmap的滑窗过滤器，通过统一的去重。&lt;/p&gt;

&lt;p&gt;压缩的位图信息也会随着state进行保存，重启时可以完美衔接。&lt;/p&gt;
</description>
        <pubDate>Mon, 11 May 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-05-11-state</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-05-11-state</guid>
        
        
        <category>state</category>
        
      </item>
    
  </channel>
</rss>
