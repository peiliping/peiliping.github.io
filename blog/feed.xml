<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 01 Sep 2017 09:08:51 +0800</pubDate>
    <lastBuildDate>Fri, 01 Sep 2017 09:08:51 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Lpeg与模式匹配</title>
        <description>&lt;p&gt;去年年底，开发第一版logwatch的时候，就有关注到Lpeg这个项目。&lt;/p&gt;

&lt;p&gt;调研期间看了mozilla的heka项目，在解析日志时引入了lua的sandbox，&lt;/p&gt;

&lt;p&gt;其定义的解析函数主要依赖Lpeg来实现，（LPEG可以称为PEG的Lua实现）。&lt;/p&gt;

&lt;p&gt;PEG相关知识自行google–&amp;gt;解析表达文法。&lt;/p&gt;

&lt;h2 id=&quot;lpeg&quot;&gt;日志领域的Lpeg&lt;/h2&gt;

&lt;p&gt;为什么mozilla的heka要引入lua和lpeg呢？&lt;/p&gt;

&lt;p&gt;heka是基于go开发的高性能日志处理工具，lua也是以性能著称的，&lt;/p&gt;

&lt;p&gt;而且增加或者修改lua文件并不需要重新编译，非常理想的插件模式。&lt;/p&gt;

&lt;p&gt;对于一般的日志文件解析来说正则就足够强大了，但这个世界并不完美，&lt;/p&gt;

&lt;p&gt;总有一些特殊情况，导致了复杂度。假如日志文件里存在一种以上的格式，&lt;/p&gt;

&lt;p&gt;如何高效的进行解析？如何解析抽取UserAgent这样的字段？&lt;/p&gt;

&lt;p&gt;模式匹配是一个很不错的选择，lua领域的lpeg就可以完成这个工作。&lt;/p&gt;

&lt;p&gt;几年前我在看一个解析UserAgent的java库，大概实现思路是要跑N条正则，&lt;/p&gt;

&lt;p&gt;看看哪个可以完成解析，这样的效率显然是很低。&lt;/p&gt;

&lt;h2 id=&quot;lpeg-1&quot;&gt;初识Lpeg&lt;/h2&gt;

&lt;p&gt;Lpeg的入门还是有一些难度的，语法比较怪异，相关的例子也不是很多。&lt;/p&gt;

&lt;p&gt;我在git上建了一个项目，记录了我练习的一些例子，从最简单的计算器、&lt;/p&gt;

&lt;p&gt;到一个日期格式自动识别转化的工具、再到一个简易的模板(支持变量替&lt;/p&gt;

&lt;p&gt;换和for循环语句)。&lt;a href=&quot;https://github.com/peiliping/lpeg-test/tree/master/basic&quot;&gt;【lpeg-test】&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;如果你想用lpeg来自制一门脚本语言parser的话，还是要借助一些高级库，&lt;/p&gt;

&lt;p&gt;比如&lt;a href=&quot;https://github.com/sqmedeiros/lpeglabel&quot;&gt;【label】&lt;/a&gt;、&lt;a href=&quot;https://github.com/andremm/lua-parser&quot;&gt;【parser】&lt;/a&gt;、&lt;a href=&quot;https://github.com/luapower/lexer&quot;&gt;【lexer】&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 01 Sep 2017 09:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-09-01-lpeg</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-09-01-lpeg</guid>
        
        
        <category>lpeg</category>
        
        <category>lua</category>
        
        <category>模式匹配</category>
        
      </item>
    
      <item>
        <title>关于性能优化</title>
        <description>&lt;p&gt;最近两周一直在对去年开发的logwatch进行重构和升级，修复一些小bug、&lt;/p&gt;

&lt;p&gt;扩展了对文件名的正则支持、升级了相关的三方依赖库，重新规划了目录结构，&lt;/p&gt;

&lt;p&gt;当然，优化性能也是很重要的一个目标。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;越来越难的性能优化&lt;/h2&gt;

&lt;p&gt;去年开发logwatch替换logstash的时候，就是因为logstash的性能差。&lt;/p&gt;

&lt;p&gt;所以着重在优化logwatch的性能上，上线的版本可以达到每秒5万行NginxLog。&lt;/p&gt;

&lt;p&gt;当时主要的优化手段是提高正则解析的效率，以最低的回溯代价完成解析。&lt;/p&gt;

&lt;p&gt;而后在一些关键数据结构上做到重用，大大降低了table的性能开销。&lt;/p&gt;

&lt;p&gt;最后有针对性的优化了KafkaClient的参数，保证高效率的消息传递。&lt;/p&gt;

&lt;p&gt;这次再要优化性能已经非常困难了，从profiler的统计看，热点已经不在Lua了。&lt;/p&gt;

&lt;p&gt;所以优化的方向主要是提升依赖的三方库的性能，优化的目标是7万以上。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;三方依赖&lt;/h2&gt;

&lt;p&gt;最吃cpu的三方库就是cjson，花了点时间寻找性能更好的json库。&lt;/p&gt;

&lt;p&gt;参考了网上的一些测试结果，和自己的简单测试，发现rapidjson是最快的。&lt;/p&gt;

&lt;p&gt;rapidjson相关的资料在网上可以搜到，大概比cjson快了一倍多。&lt;/p&gt;

&lt;p&gt;因为lua本身提供的基础库非常有限，甚至连Sleep这样的功能都没有原生提供。&lt;/p&gt;

&lt;p&gt;这次升级和优化时，也将一些通过os.exec来执行的命令替换成相关的三方库。&lt;/p&gt;

&lt;p&gt;比如，引入了LuaFileSystem来丰富对目录和文件的操作，通过ffi来实现sleep。&lt;/p&gt;

&lt;p&gt;虽然这些改进不能明显的提高性能，但是可以降低吞吐量的波动性。&lt;/p&gt;

&lt;p&gt;在数据压缩方面由snappy换成了lz4，测试结果表明lz4还是会更快一些。&lt;/p&gt;

&lt;p&gt;修改kafka的参数socket.blocking.max.ms也可以提高一些性能，测试结果显示&lt;/p&gt;

&lt;p&gt;80-100之间是最佳状态。&lt;/p&gt;

&lt;p&gt;关于Lua的Ipairs和Pairs网上有很多介绍的资料了，性能上ipairs肯定是更好的，&lt;/p&gt;

&lt;p&gt;但是pairs的操作更方便，代码更整洁。所以要根据情况来取舍。&lt;/p&gt;

&lt;p&gt;高密度执行的语句中，尽量使用ipairs，反之可以用pairs。&lt;/p&gt;

&lt;p&gt;经过一番折腾，可以在理想环境(haswell或者broadwell的cpu、网络延迟低)下，&lt;/p&gt;

&lt;p&gt;达到每秒8万以上的吞吐量，一般情况也可以超过7万。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;是否过度优化&lt;/h2&gt;

&lt;p&gt;跟朋友讨论时也谈到logwatch是不是过度优化了性能，应该去实现更多的功能，&lt;/p&gt;

&lt;p&gt;很少有业务能把日志打印量做到每秒几万行，这样的性能几乎无用武之地。&lt;/p&gt;

&lt;p&gt;这里谈一下我的看法：&lt;/p&gt;

&lt;p&gt;性能测试都会基于一定的前提或者一定的测试数据，多少会有一些局限性。&lt;/p&gt;

&lt;p&gt;我的测试数据是来自生产环境上的nginxlog，每行均长是200字节。&lt;/p&gt;

&lt;p&gt;这个测试数据的标准不算很高，我问过几家公司的朋友他们的均长在300左右。&lt;/p&gt;

&lt;p&gt;因为业务的差别和logformat的差异，每家都会不太一样。&lt;/p&gt;

&lt;p&gt;当然即使是300的均长，logwatch的吞吐能力也在6W以上，足够满足需求。&lt;/p&gt;

&lt;p&gt;日志采集的探针是一个小组件，每个人都希望他是低负担的，低成本的。&lt;/p&gt;

&lt;p&gt;如果性能做的好，在部署上就不会带来任何负担。比如，不用单独为它准备&lt;/p&gt;

&lt;p&gt;一个cpucore，或者扩充系统内存之类的。logwatch在生产环境下，&lt;/p&gt;

&lt;p&gt;每秒处理500行log，占用24m内存，单核的百分之1.5的cpu。&lt;/p&gt;

&lt;p&gt;不一定每个使用它的场景都会有那么好的cpu和网络，这些不确定性也会导致&lt;/p&gt;

&lt;p&gt;性能有所下降，提升性能会让它适应能力更强。&lt;/p&gt;

&lt;p&gt;网上看过很多日志采集的方案，最近一年多比较流行的方案是在本地只做基本的&lt;/p&gt;

&lt;p&gt;行和多行切分，其他的解析操作全部扔到后面去做，比如Kafka的Consumer。&lt;/p&gt;

&lt;p&gt;这当然是一个不错的方案，但是将如此重Cpu的工作全部放在后端处理，意味着&lt;/p&gt;

&lt;p&gt;你需要一个比较大的资源池，也会有一些相应的管理成本。&lt;/p&gt;

&lt;p&gt;在我看来适当的将日志解析的工作放在前端agent执行，是更经济的做法。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;任何一种选型或者方案都不会是完美的，要看你对哪一方面更敏感，&lt;/p&gt;

&lt;p&gt;明确知道这个方案的边界，尽量避免触礁，被滥用是很多项目失败的根本原因。&lt;/p&gt;

</description>
        <pubDate>Wed, 09 Aug 2017 09:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-08-09-performance</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-08-09-performance</guid>
        
        
        <category>性能</category>
        
        <category>优化</category>
        
        <category>logwatch</category>
        
      </item>
    
      <item>
        <title>支持long型的bitmap</title>
        <description>&lt;p&gt;日常工作中我们使用到bitmap的场景并不是很多，前几年在面试中倒是经常会被问到，&lt;/p&gt;

&lt;p&gt;比如，一亿用户id的去重、排序、布隆过滤器等等，分析型数据库中bitmap也是利器。&lt;/p&gt;

&lt;p&gt;Java中常用的bitmap实现有BitSet，还有开源的、功能强大的Roaringbitmap。&lt;/p&gt;

&lt;p&gt;近年比较火的OLAP领域，大量的采用Roaringbitmap作为bitmap的基础实现库。&lt;/p&gt;

&lt;p&gt;在读写速度还有内存控制上Roaringbitmap都非常优秀，但是有一个比较大的限制，&lt;/p&gt;

&lt;p&gt;就是只支持int类型的数据写入，而实际工作中，我们想要存入Bitmap的是long型。&lt;/p&gt;

&lt;p&gt;如果你去搜索bitmap三方库的issue就会发现，有此类需求的人非常多。&lt;/p&gt;

&lt;p&gt;众多开源项目在使用Roaringbitmap的时候，也碰到了这问题，有的是扩展实现了对&lt;/p&gt;

&lt;p&gt;long型的支持，有的是做了预处理，将数据控制在int类型范围内。&lt;/p&gt;

&lt;p&gt;之前在meepo项目中引入bitmap，为了解决在两张表中，查找差异的主键ID，&lt;/p&gt;

&lt;p&gt;一般来说一个表的主键ID都是自增的long型(bigint)，所以要扩展long型的支持。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;思考&lt;/h2&gt;

&lt;p&gt;刚才提到bitmap经常被用来存储ID，那么在业务中ID为什么经常被定义为long型呢？&lt;/p&gt;

&lt;p&gt;我们平时使用的大多数表数据量可能只有几百或者几千，这些数据也很少更新和增加。&lt;/p&gt;

&lt;p&gt;这种数据可以称为常量数据，比如定义浏览器、操作系统、运营商等等，这种场景完全&lt;/p&gt;

&lt;p&gt;可以使用int、甚至更短的整数形式，有利于减低索引的开销，还有运行时的内存占用。&lt;/p&gt;

&lt;p&gt;还有一种ID是流水号，比如订单ID、用户ID、商品ID等等。考虑业务未来的增长，&lt;/p&gt;

&lt;p&gt;有必要把他们定义为long型。当然实际上，绝大多数公司都会在流水号上做一些手脚，&lt;/p&gt;

&lt;p&gt;比如在订单流水号的末尾添加用户ID的后四位，用来作为分库分表的依据。&lt;/p&gt;

&lt;p&gt;为了防止ID被穷举，设置适当的跳跃和偏移也是必要的。总之，ID涉及到拼接，&lt;/p&gt;

&lt;p&gt;就极有可能超过int类型的范围了。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;如何实现&lt;/h2&gt;

&lt;p&gt;如果你真有海量数据需要需要填充到bitmap中，你需要考虑一下内存是不是够用了，&lt;/p&gt;

&lt;p&gt;就算支持到long型，内存不够也处理不了。既然一个bitmap可以支持int，那么&lt;/p&gt;

&lt;p&gt;我们使用多个bitmap，依次表达 N × int。这样可以使用现有的Roaringbitmap，&lt;/p&gt;

&lt;p&gt;作为基础实现。这里有实现代码：&lt;a href=&quot;https://github.com/peiliping/meepo/tree/master/src/main/java/meepo/util/hp&quot;&gt;【BitMap】&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;细节&lt;/h2&gt;

&lt;p&gt;在处理N × int的时候，很多人会使用整除和取模的方式，当然这样可以实现功能，&lt;/p&gt;

&lt;p&gt;但是运行效率一般，参考Ringbuffer在处理Sequence时的技巧，实现如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;long seq = data &amp;gt;&amp;gt; 31;
int val = (int) (data &amp;amp; Integer.MAX_VALUE);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;测试下来，整体运行效率可以提高一倍。&lt;/p&gt;

&lt;p&gt;因为这些Roaringbitmap是有序的，使用Treemap当然是最理想的。&lt;/p&gt;

&lt;p&gt;但是在搜索性能上，Treemap不及Hashmap，所以只在局部使用。&lt;/p&gt;

&lt;p&gt;Roaringbitmap的接口非常多，这里只实现了一部分，后面根据需要再补充。&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Aug 2017 09:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-08-01-64bitmap</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-08-01-64bitmap</guid>
        
        
        <category>java</category>
        
        <category>bitmap</category>
        
      </item>
    
      <item>
        <title>Flume优化</title>
        <description>&lt;p&gt;Flume是Apache大数据套件中比较亲民的，安装、配置简单，功能丰富，而且极易定制化。&lt;/p&gt;

&lt;p&gt;Flume的整体设计也是非常值得学习的。之前美团在官方技术blog中，着重讲述了其在Flume&lt;/p&gt;

&lt;p&gt;上的定制化开发和性能优化，也让Flume普及率大大提高了。&lt;/p&gt;

&lt;p&gt;一般使用Flume主要是作为agent抓取日志或者从Kafka读取消息写入HDFS、Hbase等，&lt;/p&gt;

&lt;p&gt;而作为消息通道的功能，这几年渐渐被性能卓越的Kafka所取代。&lt;/p&gt;

&lt;p&gt;而在日志抓取领域，Flume的功能性和性能一直都不是最佳选择。&lt;/p&gt;

&lt;p&gt;下面介绍一下我在Flume定制开发和性能优化中的一些实践。&lt;/p&gt;

&lt;h2 id=&quot;kafkasourcesink&quot;&gt;KafkaSourceSink&lt;/h2&gt;

&lt;p&gt;在我的应用场景中，Flume主要是从Kafka拉取数据写入到HDFS上，还有就是从Kafka到Kafka。&lt;/p&gt;

&lt;p&gt;Kafka这几年的发展很快，从比较流行的0.8.2.2到现在的0.10.X版本，API的兼容不是很好。&lt;/p&gt;

&lt;p&gt;Flume的官方版本支持的是0.9.X，需要定制一下Kafka的版本支持。把KafkaSource和Sink&lt;/p&gt;

&lt;p&gt;中,跟KafkaAPI打交道的方法都封装在抽象类中，提供多种版本的实现，这样就具备了不同Kafka&lt;/p&gt;

&lt;p&gt;版本之间的消息迁移，主要用途就是在业务升级Kafka版本时，作为辅助的数据迁移工具，&lt;/p&gt;

&lt;p&gt;业务方可以分别升级Producer端和Consumer端，减少升级的难度，控制升级的风险。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;优化性能&lt;/h2&gt;

&lt;p&gt;整体来说Flume的性能并不高，很多组件为了实现通用性，都放弃了性能。&lt;/p&gt;

&lt;p&gt;通过JFR的火焰图，我们找到了一些可以优化的点，下面列举一些。&lt;/p&gt;

&lt;h3 id=&quot;hdfseventsink&quot;&gt;HDFSEventSink&lt;/h3&gt;

&lt;p&gt;HDFSEventSink最大的问题是HDFSPath路径的渲染，将EventHeader里的Tag写入Path路径中，&lt;/p&gt;

&lt;p&gt;还有一些预设的变量，比如年月日时分秒。这种渲染逻辑是每条数据都要执行的，所以开销非常大。&lt;/p&gt;

&lt;p&gt;解决办法：&lt;/p&gt;

&lt;p&gt;尽量少的使用变量，可以在Source端将路径的相关信息都拼凑好，写成一两个tag，&lt;/p&gt;

&lt;p&gt;最后在sink端做简单的字符串拼接，性能至少可以提升两三倍。&lt;/p&gt;

&lt;p&gt;注意：日期格式的渲染也要考虑，如果每条数据都将timestamp格式化成YMD也是非常耗时的，&lt;/p&gt;

&lt;p&gt;可以适当引入cache来解决这个问题，比如将timestamp整除60000，缓存一分钟的格式化结果。&lt;/p&gt;

&lt;p&gt;网上见到很多人的flume例子中，都是写TextFile到HDFS的，我是选择写的SequenceFile，&lt;/p&gt;

&lt;p&gt;并且加了Snappy的压缩。SequenceFile比TextFile的好处就不讲了，网上有很多介绍。&lt;/p&gt;

&lt;p&gt;另外sequenceFile也有一点点可以改的地方，将HDFSWritableSerializer的KeyClass修改掉，&lt;/p&gt;

&lt;p&gt;Flume源码里是LongWritable，可以改成NullWritable。修改过的SequenceFile并不影响使用，&lt;/p&gt;

&lt;p&gt;HDFS的文件大小会有百分之X的下降，相应的网络传输也会有一些收益。&lt;/p&gt;

&lt;h3 id=&quot;eventsimpleevent&quot;&gt;Event、SimpleEvent&lt;/h3&gt;

&lt;p&gt;在Flume体系中，Event是数据的载体，一共有两部分组成，一个Header，一个Body。&lt;/p&gt;

&lt;p&gt;Header是一个HashMap，这里的HashMap是可以优化的，参见我上一篇文章吧。&lt;/p&gt;

&lt;p&gt;这里有一个陷阱需要注意，SimpleEvent的实现中，Header是每次创建时就new了一个HashMap。&lt;/p&gt;

&lt;p&gt;按照Flume源码中Kafkasource的逻辑EventBuilder.withBody(eventBody, headers)，&lt;/p&gt;

&lt;p&gt;你在外面构建的headers(map),会在event初始化时复制一遍，这里可以优化一下。&lt;/p&gt;

&lt;h3 id=&quot;channelprocessor&quot;&gt;ChannelProcessor&lt;/h3&gt;

&lt;p&gt;ChannelProcessor的实现比较丰富，但不一定你都需要用到，这里首先可以做了一下裁剪。&lt;/p&gt;

&lt;p&gt;在我的Flume中不会用到optional和InterceptorChain，所以先将相关逻辑删掉了。&lt;/p&gt;

&lt;p&gt;processEventBatch方法的参数events，在下面的实现逻辑中被复制到了reqChannelQueue里，&lt;/p&gt;

&lt;p&gt;在我的Source中，一个batch操作的数据都是指向同一个channel的，所以这个复制也没有意义。&lt;/p&gt;

&lt;p&gt;只需要判断第一个元素的header，选择req的Channel，直接执行Put即可。&lt;/p&gt;

&lt;p&gt;如果一个batch的数据可能是流向不同channel的，那么尽量在source端拆分好。&lt;/p&gt;

&lt;p&gt;source端承载数据的list是可以反复重用的，而且capacity也可以预设大小，避免resize。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;最后&lt;/h3&gt;

&lt;p&gt;写好的代码如果你是以plugin的形式来开发flume的话，那上面的部分代码是没法生效的。&lt;/p&gt;

&lt;p&gt;比如ChannelProcessor，有一个简单的办法，在不用修改Flume源码的情况下，就可以生效。&lt;/p&gt;

&lt;p&gt;找到Flume/bin目录下的flume-ng启动脚本，在这里修改一下java -cp 后面的参数顺序，&lt;/p&gt;

&lt;p&gt;保证你的plugin目录，在flume/lib目录之前，就可以优先加载所覆写的类了。&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Jul 2017 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-07-05-flume</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-07-05-flume</guid>
        
        
        <category>flume</category>
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>关于Map的优化</title>
        <description>&lt;p&gt;Map(HashMap)是Java中最常用的一种数据结构，灵活性好，性能比较均衡。&lt;/p&gt;

&lt;p&gt;提到HashMap的性能，就会想到初始化Capacity，减少数据复制的开销。&lt;/p&gt;

&lt;p&gt;下面我们换一个新的角度来谈谈HashMap的性能优化。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;场景&lt;/h2&gt;

&lt;p&gt;绝大多数性能优化，都是基于一个特定的业务场景，才会有比较明显的效果。&lt;/p&gt;

&lt;p&gt;我们平时使用HashMap承载数据的时候，通常Key的个数和种类都是非常有限的。&lt;/p&gt;

&lt;p&gt;比如，Key的可选项有8个，大多数会使用其中的六七个，而Value几乎每次都不一样。&lt;/p&gt;

&lt;p&gt;具体到一些业务场景，比如：
 1、message的header
 2、record的tag
 3、interface的params、result&lt;/p&gt;

&lt;p&gt;如果用具体的Class作为数据的实体，会有比较高的数据“密度”，读写性能也更高。&lt;/p&gt;

&lt;p&gt;当然在一些开源框架上(比如Flume的EventHeader)，就会使用HashMap来承载数据。&lt;/p&gt;

&lt;p&gt;如果系统中使用的这种HashMap非常多，比如一秒钟要创建和使用几万、几十万个Map，&lt;/p&gt;

&lt;p&gt;就可以参考一下，下面的优化方案了。&lt;/p&gt;

&lt;h3 id=&quot;java&quot;&gt;Java对象的内存布局&lt;/h3&gt;

&lt;p&gt;首先温习一下Java对象的内存布局，这里不再详细讲解了，注意UseCompressedOops的作用。&lt;/p&gt;

&lt;p&gt;再看看HashMap的源码，核心是一个Node的数组，Node中包括hash、key、value、next指针。&lt;/p&gt;

&lt;p&gt;上面设定的业务场景中，Key是具有极大的公用性的，如果把行结构转成列结构，就可以共用了。&lt;/p&gt;

&lt;p&gt;如果列化共用之后，Map的Key部分的内存开销是一个常数，一个对象引用的大小。&lt;/p&gt;

&lt;p&gt;如果Key的使用率太低的话(10个key只有其中的1-2个被写入)，也会造成比较大的浪费。&lt;/p&gt;

&lt;h3 id=&quot;hash&quot;&gt;Hash&lt;/h3&gt;

&lt;p&gt;Hash是一个数学运算过程，属于CPU密集型，也是性能优化中比较难处理的一类问题。&lt;/p&gt;

&lt;p&gt;因为场景中Key的集合相对固定，这里可以考虑彻底放弃Hash，直接使用常量列表，&lt;/p&gt;

&lt;p&gt;把用Hash来定位数据，替换成直接使用数组的下标，这样开销应该是降低到了极限了。&lt;/p&gt;

&lt;p&gt;为了保持和Map的兼容性，也要提供根据key来获取val的功能，这样更容易融合进框架中。&lt;/p&gt;

&lt;h3 id=&quot;entryset&quot;&gt;EntrySet&lt;/h3&gt;

&lt;p&gt;HashMap的Node实现了Map.Entry,所以遍历Map的过程就是遍历Node数组加Node链表。&lt;/p&gt;

&lt;p&gt;前面提到列化、key和value都是在数组中的，所以遍历也就是数组的遍历过程，更加简单一点。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;实现&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/peiliping/meepo/tree/master/src/main/java/meepo/util/hp&quot;&gt;【ArrayMap】&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;测试&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/peiliping/meepo/tree/master/src/test/java/meepo/hp&quot;&gt;【测试】&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;简单的创建和读写Map来进行测试，ArrayMap比HashMap要快一倍左右。&lt;/p&gt;

&lt;p&gt;设置128M的JVM进行内存布局的测试，ArrayMap的大小是HashMap的四分之一左右。&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Jul 2017 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-07-02-map</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-07-02-map</guid>
        
        
        <category>map</category>
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>谈谈日志解析中的正则表达式</title>
        <description>&lt;p&gt;正则表达式算是编程的基础知识，日常功能开发中也经常会用到。&lt;/p&gt;

&lt;p&gt;以Java为例，简单的一个String.format就会用到Pattern.match。&lt;/p&gt;

&lt;p&gt;Nginx的location配置，sed、grep等常用的linux命令也会用到正则。&lt;/p&gt;

&lt;p&gt;还有很多类似正则表达式的应用，比如Spring的PathURI解析。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;日志解析中的正则表达式&lt;/h2&gt;

&lt;p&gt;日志解析领域，是重度依赖Regex的。一提到正则就会有人说性能问题，耗Cpu。&lt;/p&gt;

&lt;p&gt;的确，由于正则的书写方式不合理，导致的性能问题非常之多，甚至还有死循环的bug。&lt;/p&gt;

&lt;p&gt;能写正则和写好正则之间需要大量的实践积累，也需要了解非常多的背景知识。&lt;/p&gt;

&lt;p&gt;去年做过一个日志采集工具，其中就用到了正则来解析NginxLog，性能调的还可以。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;正则表达式的几个基础概念&lt;/h3&gt;

&lt;p&gt;1、DFA和NFA引擎、回溯&lt;/p&gt;

&lt;p&gt;2、贪婪和非贪婪&lt;/p&gt;

&lt;p&gt;3、固化分组&lt;/p&gt;

&lt;p&gt;4、量词匹配、优先匹配&lt;/p&gt;

&lt;p&gt;具体概念就不展开讲了，自行查阅，提供２个blog可以看看。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/yangzhongxuan/article/details/6968556&quot;&gt;引擎&lt;/a&gt;、&lt;a href=&quot;http://blog.csdn.net/lxcnn/article/details/4756030&quot;&gt;贪婪与非贪婪&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;繁琐啰嗦的表达式&lt;/h3&gt;

&lt;p&gt;为了解析一行NginxLog，你可能会把正则写成这样:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;([%d]+/[%a]+/[%d]+:[%d]+:[%d]+:[%d]+ %+0800)&quot; ([%d|%.]+) (.-) ([%d|%.]+) ([%a|%-]+) ([%d]+) &quot;([http|https]+)://([^&quot;]*)&quot; ([%d]+) ([%d]+) &quot;([^&quot;]*)&quot; &quot;(.*)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;精确的提供了每个字段的类型、长度等等，这样的表达式性能很好，但是看起来非常的啰嗦。&lt;/p&gt;

&lt;p&gt;有人为了省事，会大量用(.*)来替代表达式中的明确的类型和长度信息。&lt;/p&gt;

&lt;p&gt;简单测试一下就会发现(.*)的性能惨不忍睹。主要是因为大量的贪婪回溯，导致性能下降。&lt;/p&gt;

&lt;p&gt;注意：最后一个分组字段使用(.*)是非常合理的。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;简化一下&lt;/h3&gt;

&lt;p&gt;用(.*)来简化性能不好，那有没有性能好，又简单的表达式呢？可以试试非贪婪模式。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;(.-)&quot; (.-) (.-) (.-) (.-) (.-) &quot;(.-)://(.-)&quot; (.-) (.-) &quot;(.-)&quot; &quot;(.*)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个看起来是不是非常清晰，一个坑一个字段，最后一个分组仍然使用贪婪模式。&lt;/p&gt;

&lt;p&gt;看到这里是不是觉得以后正则表达式有可能自动生成了，不需要烧脑完成。&lt;/p&gt;

&lt;p&gt;这个正则的语法是以Lua为例的，其他语言也有类似的，只是符号不一样而已。Java是(.*?)&lt;/p&gt;

&lt;p&gt;这个表达式的性能比第一个啰嗦的表达式性能略差，差距很小，基本是可以接受的。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;继续深入&lt;/h3&gt;

&lt;p&gt;将简化的表达式进行一下整理替换，得到下面的：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;([^&quot;]*)&quot; ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) &quot;([^:]*)://([^&quot;]*)&quot; ([^ ]*) ([^ ]*) &quot;([^&quot;]*)&quot; &quot;(.*)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这里就看到比较重的分隔符含义了，一般来说我们的日志都有分隔符在的。&lt;/p&gt;

&lt;p&gt;但列与列之间的分隔符并不一定一致，比如NginxLog，不知道为什么Nginx要把Log默认写成那个样子。&lt;/p&gt;

&lt;p&gt;实际应用中，这种风格写法的Regex非常的实用。看过一些国内日志业务的解析功能也大概是这个思路吧。&lt;/p&gt;

&lt;p&gt;性能上比非贪婪的要好，和第一个表达式的性能是一样的。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;自动化&lt;/h3&gt;

&lt;p&gt;上面两个正则表达式看起来规律性都非常强，也就是说有极大的可能可以自动生成这个表达式。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&quot;$time_local&quot; $remote_addr $upstream_addr $request_time $request_method $status &quot;$scheme://$host$request_uri&quot; $request_length $body_bytes_sent &quot;$http_referer&quot; &quot;$http_user_agent&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这个是Nginx的logformat配置，日志解析的正则表达式自动生成就很简单了。&lt;/p&gt;
</description>
        <pubDate>Thu, 15 Jun 2017 13:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-06-15-regex</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-06-15-regex</guid>
        
        
        <category>regex</category>
        
      </item>
    
      <item>
        <title>Vertica优化之Encode</title>
        <description>&lt;p&gt;Vertica是一个成熟的商用列式数据库，也提供免费版本（限制数据规模小于1T，集群规模小于3台）。&lt;/p&gt;

&lt;p&gt;2015年尝试使用Vertica来存储时序类型的数据，主要应用在内部的JVM监控数据上。&lt;/p&gt;

&lt;p&gt;每天增量在8千万行，保留最近2个月左右的数据，按时间对数据进行分区，保留总量在50亿行左右。&lt;/p&gt;

&lt;p&gt;查询的SQL以sum avg count where group by order by这些关键词为主，简单的数值统计需求。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;时序数据的表有哪些字段&lt;/h3&gt;

&lt;p&gt;谈到时序数据就会想到监控，常见的开源项目有OpenTSDB、Graphite、Druid、Influxdb等等。&lt;/p&gt;

&lt;p&gt;年初Facebook开源的Beringer也掀起了一波浪潮，在规律的数据场景下，如何压缩存储数据呢？&lt;/p&gt;

&lt;p&gt;时序数据表中一般会有如下几种类型的列：&lt;/p&gt;

&lt;p&gt;1、时间戳，可能有不同精度的时间戳（ms、s、min、hour、day等）&lt;/p&gt;

&lt;p&gt;2、metricid、typeid，用来定义数据的类别&lt;/p&gt;

&lt;p&gt;3、dimensionid，数字化的维度信息，比如国家地区编码、性别、年龄、操作系统等等&lt;/p&gt;

&lt;p&gt;4、tag，跟维度类似，但是由于不方便定义成id，就以原始的字符串存下来了&lt;/p&gt;

&lt;p&gt;5、value，数值型用来存储最主要的信息&lt;/p&gt;

&lt;h3 id=&quot;verticaencode&quot;&gt;如何选择Vertica的Encode&lt;/h3&gt;

&lt;p&gt;1、经过测试时间戳类型的字段用COMMONDELTA_COMP存储空间占用最小，比BLOCK_DICT好很多。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;This compression scheme builds a dictionary of all deltas in the block and 
then stores indexes into the delta dictionary using entropy coding.
This scheme is ideal for sorted FLOAT and INTEGER-based
(DATE/TIME/TIMESTAMP/INTERVAL) data columns with predictable sequences and
only occasional sequence breaks, such as timestamps recorded at periodic 
intervals or primary keys. For example, the following sequence compresses 
well: 300, 600, 900,1200, 1500, 600, 1200, 1800, 2400. The following sequence 
does not compress well: 1,3, 6, 10, 15, 21, 28, 36, 45, 55.
If delta distribution is excellent, columns can be stored in less than one bit 
per row. However, this scheme is very CPU intensive. If you use this scheme on 
data with arbitrary deltas, it can cause significant data expansion.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2、MetricId和DimId之类的，一般来说value的变化比较少，比较适合BLOCK_DICT。&lt;/p&gt;

&lt;p&gt;3、tag类型字段选择了RLE（Run Length Encoding），效果还可以。&lt;/p&gt;

&lt;p&gt;4、Value的选择是最难的，前面提到的字段一般都是经过排序的，规律性很强。&lt;/p&gt;

&lt;p&gt;value的变化范围比较大，还有可能是小数，又没经过排序。经过一系列测试在性能和存储空间&lt;/p&gt;

&lt;p&gt;开销上权衡，最理想的encode方案是GCDDELTA&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;For INTEGER and DATE/TIME/TIMESTAMP/INTERVAL columns, and NUMERIC
columns with 18 or fewer digits, data is recorded as the difference from the 
smallest value in the data block divided by the greatest common divisor (GCD) of 
all entries in the block. This encoding has no effect on other data types.
ENCODING GCDDELTA is best used for many-valued, unsorted, integer columns or
integer-based columns, when the values are a multiple of a common factor. For
example, timestamps are stored internally in microseconds, so data that is only 
precise to the millisecond are all multiples of 1000. The CPU requirements for 
decoding GCDDELTA encoding are minimal, and the data never expands, but GCDDELTA 
may take more encoding time than DELTAVAL.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sql&quot;&gt;建表SQL&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE PROJECTION public.jvm_metrics_tmp
(
 parent_id ENCODING BLOCK_DICT,
 metric_id ENCODING BLOCK_DICT,
 dim1 ENCODING BLOCK_DICT,
 dim2 ENCODING BLOCK_DICT,
 dim3 ENCODING BLOCK_DICT,
 dim4 ENCODING BLOCK_DICT,
 mtc1 ENCODING GCDDELTA,
 mtc2 ENCODING GCDDELTA,
 mtc3 ENCODING GCDDELTA,
 mtc4 ENCODING GCDDELTA,
 mtc5 ENCODING GCDDELTA,
 mtc6 ENCODING GCDDELTA,
 mtc7 ENCODING GCDDELTA,
 mtc8 ENCODING GCDDELTA,
 tag1 ENCODING RLE,
 tag2 ENCODING RLE,
 tag3 ENCODING RLE,
 tag4 ENCODING RLE,
 timestamps ENCODING COMMONDELTA_COMP,
 timestamps_1d ENCODING COMMONDELTA_COMP,
 timestamps_1h ENCODING COMMONDELTA_COMP,
 timestamps_10m ENCODING COMMONDELTA_COMP,
 timestamps_1m ENCODING COMMONDELTA_COMP,
 partition ENCODING COMMONDELTA_COMP
)
AS
 SELECT jvm_metrics.parent_id,
        jvm_metrics.metric_id,
        jvm_metrics.dim1,
        jvm_metrics.dim2,
        jvm_metrics.dim3,
        jvm_metrics.dim4,
        jvm_metrics.mtc1,
        jvm_metrics.mtc2,
        jvm_metrics.mtc3,
        jvm_metrics.mtc4,
        jvm_metrics.mtc5,
        jvm_metrics.mtc6,
        jvm_metrics.mtc7,
        jvm_metrics.mtc8,
        jvm_metrics.tag1,
        jvm_metrics.tag2,
        jvm_metrics.tag3,
        jvm_metrics.tag4,
        jvm_metrics.timestamps,
        jvm_metrics.timestamps_1d,
        jvm_metrics.timestamps_1h,
        jvm_metrics.timestamps_10m,
        jvm_metrics.timestamps_1m,
        jvm_metrics.partition
 FROM public.jvm_metrics
 ORDER BY jvm_metrics.dim1,
          jvm_metrics.parent_id,
          jvm_metrics.metric_id,
          jvm_metrics.dim2,
          jvm_metrics.dim3,
          jvm_metrics.dim4,
          jvm_metrics.tag1,
          jvm_metrics.tag2,
          jvm_metrics.tag3,
          jvm_metrics.tag4,
          jvm_metrics.timestamps
UNSEGMENTED ALL NODES;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 05 Jun 2017 16:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-06-05-verticaencoding</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-06-05-verticaencoding</guid>
        
        
        <category>vertica</category>
        
        <category>encode</category>
        
      </item>
    
      <item>
        <title>批量写入Mysql</title>
        <description>&lt;p&gt;Mysql是最常用的一种关系型数据库，随着各种ORM框架的演进，操作数据库也变得越来越简单。&lt;/p&gt;

&lt;p&gt;但是，当你碰到一些极端需求时，还是要回到JDBC这个层面上来操作。&lt;/p&gt;

&lt;p&gt;上篇博客介绍了Meepo这个数据迁移工具，其中就涉及到大量的Mysql写入操作。&lt;/p&gt;

&lt;p&gt;下面介绍一下，我在批量写Mysql时碰到的一些问题。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;真正的批量写&lt;/h3&gt;

&lt;p&gt;使用JDBC来完成批量Mysql写入的一般方法是:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;this.connection.setAutoCommit(false);

this.preparedStatement = this.connection.prepareStatement(this.sql);
for (int i = 0; i &amp;lt; this.schema.size(); i++) {
    this.preparedStatement.setObject(i + 1, data[i], this.schema.get(i));
}
this.preparedStatement.addBatch();

...N次

this.preparedStatement.executeBatch();
this.connection.commit();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;当你写完这段代码，测试性能就会发现，与单条Insert相比，并没有什么提升。&lt;/p&gt;

&lt;p&gt;因为，JDBC实际上仍是以行为单位，发送和执行写入操作的，Batch是假的。&lt;/p&gt;

&lt;p&gt;当你为Datasource的Url添加了参数rewriteBatchedStatements=true，才会真正批量执行。&lt;/p&gt;

&lt;p&gt;具体原因可以自行搜索这个参数，网上有很多文章介绍，性能可以提升三五倍。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;选择好数据库的伴侣——数据源连接池&lt;/h3&gt;

&lt;p&gt;开源的数据源连接池非常多，比如C3P0、Druid、Proxool、BoneCP、HikariCP…&lt;/p&gt;

&lt;p&gt;比较常用的是阿里开源的Druid，综合表现不错。HikariCP也是不错的选择。&lt;/p&gt;

&lt;p&gt;HikariCP和Druid的作者在Github上有一段关于性能测试的争论也可以看看。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;缓冲区&lt;/h3&gt;

&lt;p&gt;涉及到批量操作，就意味着要和缓冲区打交道了，你可能会想到数组、队列、栈等等。&lt;/p&gt;

&lt;p&gt;一般来说批量写入的缓冲区有这么几个要求：&lt;/p&gt;

&lt;p&gt;1、容量空间可控，比如1024条，写满的时候可以阻塞住。&lt;/p&gt;

&lt;p&gt;2、有超时机制，不要无限期等待。&lt;/p&gt;

&lt;p&gt;3、性能好，最好是无锁的。&lt;/p&gt;

&lt;p&gt;Disruptor的Ringbuffer可以满足上面的这些需求，只是初次上手会有一些难度。&lt;/p&gt;

&lt;p&gt;Ringbuffer强制了数据对象的复用，可以减少JVM GC的次数，对性能的提升非常有帮助。&lt;/p&gt;

&lt;p&gt;Ringbuffer的具体使用方法这里就不介绍了，网上有很多文章和例子。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;线程数和批量大小&lt;/h3&gt;

&lt;p&gt;适当的加大并行度和批量大小，是可以提高消费速度的。&lt;/p&gt;

&lt;p&gt;根据测试批量写的线程数不要超过Mysql的Cpu核数+1。&lt;/p&gt;

&lt;p&gt;批量的条数由单行数据大小决定，一般1000条左右。&lt;/p&gt;

&lt;h3 id=&quot;mysql&quot;&gt;Mysql性能优化&lt;/h3&gt;

&lt;p&gt;Mysql性能优化，参考网上的文章，这里就不详细介绍了。&lt;/p&gt;

&lt;p&gt;大多是关闭一些log，提高一些buffer，改变filesync的方式等。&lt;/p&gt;

&lt;p&gt;我们是使用阿里云的RDS进行的测试，几乎不用什么调整，性能就很不错了。&lt;/p&gt;

&lt;p&gt;需要注意表上的索引个数，索引是很影响写入性能的，尽量保证索引精简。&lt;/p&gt;

&lt;h3 id=&quot;jdbc&quot;&gt;JDBC优化&lt;/h3&gt;

&lt;p&gt;经过前面的优化后，再使用JFR对你的程序做一下热点代码的分析，就会发现集中在JDBC的代码上了。&lt;/p&gt;

&lt;p&gt;仔细阅读MysqlConnector的代码就会发现，可以改造的地方还是挺多的。&lt;/p&gt;

&lt;p&gt;下面举几个例子：&lt;/p&gt;

&lt;p&gt;1、批量数据的暂存容器&lt;/p&gt;

&lt;p&gt;提交到Preparestatment中的数据，会暂时存到一个ArrayList中。&lt;/p&gt;

&lt;p&gt;ArrayList跟HashMap一样，随着数据被多次add，就会触发resize和array copy。&lt;/p&gt;

&lt;p&gt;通过Arrays类的copyOf方法对原数组进行拷贝，长度为原数组的1.5倍+1。&lt;/p&gt;

&lt;p&gt;在你初始化一个Preparestatment的时候，根据你的批量大小，对其进行capacity的初始化，会带来不小的性能提升。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;this.batchArgsField = StatementImpl.class.getDeclaredField(&quot;batchedArgs&quot;);
this.batchArgsField.setAccessible(true);
...
this.batchArgsField.set((StatementImpl) ((DruidPooledPreparedStatement) this.preparedStatement).getStatement(), new ArrayList&amp;lt;Object&amp;gt;(stepSize));

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2、日期格式化&lt;/p&gt;

&lt;p&gt;一般数据库表都会有一些日期类型的字段，比如创建时间、更新时间等。&lt;/p&gt;

&lt;p&gt;Java中的日期类型格式化处理性能一般，比如SimpleDateFormat就是一个关键点。&lt;/p&gt;

&lt;p&gt;代码com.mysql.jdbc.PreparedStatement中的tsdf，就是用来格式化日期类型的。&lt;/p&gt;

&lt;p&gt;假如你的表中日期类型字段比较多，可以考虑替换掉SimpleDateFormat的实现。&lt;/p&gt;

&lt;p&gt;Mysql中的日期类型格式是比较固定的，并不需要SimpleDateFormat那么复杂的实现，&lt;/p&gt;

&lt;p&gt;可以使用Calender的接口，通过字符串拼接的方式完成日期数据的格式化。&lt;/p&gt;

&lt;p&gt;性能也是会有一定的提升。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class DateFormatter extends SimpleDateFormat {

    public DateFormatter(String pattern) {
        super(&quot;&quot;, Locale.US);
    }

    @Override public StringBuffer format(Date date, StringBuffer toAppendTo, FieldPosition pos) {
        super.calendar.setTime(date);
        toAppendTo.append(&quot;'&quot;);
        toAppendTo.append(super.calendar.get(1));
        toAppendTo.append(&quot;-&quot;);
        if (super.calendar.get(2) &amp;lt; 9) {
            toAppendTo.append(0);
        }
        toAppendTo.append(super.calendar.get(2) + 1);
        toAppendTo.append(&quot;-&quot;);
        if (super.calendar.get(5) &amp;lt; 10) {
            toAppendTo.append(0);
        }
        toAppendTo.append(super.calendar.get(5));
        toAppendTo.append(&quot; &quot;);
        if (super.calendar.get(11) &amp;lt; 10) {
            toAppendTo.append(0);
        }
        toAppendTo.append(super.calendar.get(11));
        toAppendTo.append(&quot;:&quot;);
        if (super.calendar.get(12) &amp;lt; 10) {
            toAppendTo.append(0);
        }
        toAppendTo.append(super.calendar.get(12));
        toAppendTo.append(&quot;:&quot;);
        if (super.calendar.get(13) &amp;lt; 10) {
            toAppendTo.append(0);
        }
        toAppendTo.append(super.calendar.get(13));
        return toAppendTo;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;3、异常处理&lt;/p&gt;

&lt;p&gt;一个完善的数据处理流程，必然要考虑异常情况，比如网络闪断，数据库重启等等。&lt;/p&gt;

&lt;p&gt;如何在请求失败后重试呢？一般的做法就是记录下批量写入的每一个数据，异常时重新写入一遍。&lt;/p&gt;

&lt;p&gt;前面基于Ringbuffer做了数据对象的复用，为了处理异常再次引入重复对象是很难接受的。&lt;/p&gt;

&lt;p&gt;最简单的办法就是利用前面初始化好的batchArgs，实际上它里面就记录了你写入的每一行数据。&lt;/p&gt;

&lt;p&gt;当出现异常时，只要把它拷贝出来，写入新的Preparestatement中，就可以再次执行了。&lt;/p&gt;

&lt;p&gt;注意executeBatch一定不能丢掉。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;List&amp;lt;Object&amp;gt; batchParams = ((JDBC4PreparedStatement) ((DruidPooledPreparedStatement) this.preparedStatement).getStatement()).getBatchedArgs();
Connection tc = this.dataSource.getConnection();
tc.setAutoCommit(false);
PreparedStatement tp = tc.prepareStatement(this.sql);
StatementImpl target = (StatementImpl) ((DruidPooledPreparedStatement) tp).getStatement();
List&amp;lt;Object&amp;gt; newParams = new ArrayList&amp;lt;&amp;gt;(batchParams);
this.batchArgsField.set(target, newParams);
tp.executeBatch();
tc.commit();
tp.close();
tc.close();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sql&quot;&gt;SQL语法&lt;/h3&gt;

&lt;p&gt;批量写入的SQL语法也不止一种，比较常见的有：&lt;/p&gt;

&lt;p&gt;1、INSERT INTO xxxx (…) VALUES (…)&lt;/p&gt;

&lt;p&gt;2、INSERT IGNORE INTO xxxx (…) VALUES (…)&lt;/p&gt;

&lt;p&gt;3、REPLACE INTO xxxx (…) VALUES (…)&lt;/p&gt;

&lt;p&gt;当主键冲突的时候如何处理，可以根据情况选择合适的SQL模式。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;参数&lt;/h3&gt;

&lt;p&gt;最后附上我所使用的URL参数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rewriteBatchedStatements=true
useUnicode=true
characterEncoding=UTF-8
useSSL=false
verifyServerCertificate=false
failOverReadOnly=false
autoReconnect=true
autoReconnectForPools=true
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;经过这些优化，Meepo可以每秒从Mysql中读取十几万的数据，并写入到一个无索引的新表中。&lt;/p&gt;

&lt;p&gt;8G的JVM，YGC每8-10秒发生一次，Mysql的Cpu会被压满。&lt;/p&gt;
</description>
        <pubDate>Thu, 25 May 2017 16:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-05-25-batch2mysql</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-05-25-batch2mysql</guid>
        
        
        <category>java</category>
        
        <category>mysql</category>
        
        <category>batch</category>
        
        <category>ringbuffer</category>
        
        <category>jdbc</category>
        
      </item>
    
      <item>
        <title>Meepo</title>
        <description>&lt;p&gt;Meepo最开始是为了Mysql到Mysql的数据迁移开发的，今年年初对其进行了重构。&lt;/p&gt;

&lt;p&gt;目前可以基本替代Sqoop完成每天凌晨将Mysql数据拷贝到HDFS上的需求，数据格式为Parquet+Snappy。&lt;/p&gt;

&lt;p&gt;并且Meepo还提供了AVSC文件，方便Hive更新表结构（TBLPROPERTIES (‘avro.schema.url’=’hdfs://onlinecluster/xxxxxxxxxx)）。&lt;/p&gt;

&lt;p&gt;Meepo的Mysql数据表迁移功能也优化了很多：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;支持基本字段类型的自动匹配转化&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;自动识别表结构和主键&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;支持同时使用N个Plugin&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提供了ReplacePlugin，用于系统升级中常见的表字段值替换需求（查另外一张表，来决定替换成什么值）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这次重构中，还引入了Disruptor的Ringbuffer，作为数据缓冲区。&lt;/p&gt;

&lt;p&gt;Ringbuffer强制了对象复用，大幅度减少了GC的频率，使得Meepo可以用更小的JVM来完成任务，性能也有一定的提升。&lt;/p&gt;

&lt;p&gt;在我们的测试中，Meepo的吞吐能力一直在每秒6W行以上，极限可以达到每秒15W。&lt;/p&gt;

&lt;p&gt;这次重构后的测试中，也找到了更多应该暴露的Metric指标，方便对Meepo进行调优。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Apr 2017 09:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-04-18-meepo</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-04-18-meepo</guid>
        
        
        <category>java</category>
        
        <category>mysql</category>
        
        <category>sqoop</category>
        
        <category>parquet</category>
        
        <category>avsc</category>
        
        <category>ringbuffer</category>
        
      </item>
    
      <item>
        <title>Java Flight Recorder</title>
        <description>&lt;p&gt;Profiling是最常见的，用来定位代码性能问题的方法。&lt;/p&gt;

&lt;p&gt;在开发环境中，我们用Visualvm、JProfiler、Yourkit等。这些工具功能强大，支持图形化界面操作，可以让我们很快定位代码问题。&lt;/p&gt;

&lt;p&gt;但是他们对应用性能的影响也非常大，所以不适合在生产环境下使用。还有这些软件要attach到jvm进程上，生产环境一般网络隔离，很难做到。&lt;/p&gt;

&lt;p&gt;在生产环境我们最常用的profiling工具就是java/bin下的jstack，多做几次jstack，也相当于profiling了。有很多工具就是对多次的jstack结果进行合并，来分析问题的。&lt;/p&gt;

&lt;p&gt;jstack方便易用，但并不是特别适合来做profiling，操作频率低，会导致safepoint指标急剧增长等等。&lt;/p&gt;

&lt;p&gt;于是我们尝试使用Jvm原生提供的JFR - Java Flight Recorder 来解决问题。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;使用方法&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid VM.unlock_commercial_features&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.start duration=60s filename=/home/peiliping/dev/logs/test.jfr settings=[default,profile]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.check 检查当前运行状况&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.stop name=test.jfr 或者 jcmd pid JFR.stop recording=3 name和recording的值参见check的结果&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将生成的jfr文件传回到自己的电脑中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;shell下执行jmc，启动图形化客户端，导入jfr文件，就可以看到cpu、gc、线程、io、代码热点等监控信息了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果需要定制化jfr抓取的指标，可以修改setting的xml文件，/…./JDK/jdk1.8.0_51/jre/lib/jfr/&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 31 Mar 2017 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-03-31-jfr</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-03-31-jfr</guid>
        
        
        <category>java</category>
        
      </item>
    
  </channel>
</rss>
