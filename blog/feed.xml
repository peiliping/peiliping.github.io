<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 23 Sep 2021 10:45:56 +0800</pubDate>
    <lastBuildDate>Thu, 23 Sep 2021 10:45:56 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>flock</title>
        <description>&lt;p&gt;最近购买了一台腾讯云的服务器跑一些小程序，在整理crontab时发现了一个腾讯云的定时任务，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;*/5 * * * * flock -xn /tmp/stargate.lock -c '/usr/local/qcloud/stargate/admin/start.sh &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;脚本是为了保证腾讯云agent存活的，这个不是我们关注的重点，重点是flock这个命令。&lt;/p&gt;

&lt;p&gt;虽然经常与服务器打交道，但是flock这个命令还是比较陌生的。&lt;/p&gt;

&lt;h2 id=&quot;flock&quot;&gt;flock&lt;/h2&gt;

&lt;p&gt;以下内容摘抄自cnblogs。&lt;/p&gt;

&lt;p&gt;如果两个进程同时启动了某个脚本，那么很容易导致数据的混乱，这个时候需要锁来协调解决。&lt;/p&gt;

&lt;p&gt;flock是建议性锁，不具备强制性。一个进程使用flock将文件锁住，另一个进程也可以直接操作正在被锁的文件，修改文件中的数据。&lt;/p&gt;

&lt;p&gt;flock只是用于检测文件是否被加锁，针对文件已经被加锁，另一个进程写入数据的情况，内核不会阻止这个进程的写入操作。&lt;/p&gt;

&lt;p&gt;flock主要三种操作类型：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;LOCK_SH，共享锁，多个进程可以使用同一把锁，常被用作读共享锁；
LOCK_EX，排他锁，同时只允许一个进程使用，常被用作写锁；
LOCK_UN，释放锁；
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section&quot;&gt;参数&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;-s,--shared：获取一个共享锁，在定向为某文件的FD上设置共享锁而未释放锁的时间内，其他进程试图在定向为此文件的FD上设置独占锁的请求失败，而其他进程试图在定向为此文件的FD上设置共享锁的请求会成功。
-x，-e，--exclusive：获取一个排它锁，或者称为写入锁，为默认项
-u，--unlock：手动释放锁，一般情况不必须，当FD关闭时，系统会自动解锁，此参数用于脚本命令一部分需要异步执行，一部分可以同步执行的情况。
-n，--nb, --nonblock：非阻塞模式，当获取锁失败时，返回1而不是等待
-w, --wait, --timeout seconds：设置阻塞超时，当超过设置的秒数时，退出阻塞模式，返回1，并继续执行后面的语句
-o, --close：表示当执行command前关闭设置锁的FD，以使command的子进程不保持锁。
-c, --command command：在shell中执行其后的语句
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section-1&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;flock可以让很多脚本程序变得更规范，比如我有一些增量计算数据的脚本，如果不小心并发执行了就会导致数据错乱。&lt;/p&gt;

&lt;p&gt;以前不知道这个命令，都是用一个lock文件来替代，在脚本中判断文件是否存在，非常的繁琐，也不是很严谨。&lt;/p&gt;

&lt;p&gt;你是更喜欢把flock放在脚本外部，还是写在脚本里呢？&lt;/p&gt;
</description>
        <pubDate>Sun, 13 Jun 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-06-13-flock</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-06-13-flock</guid>
        
        
        <category>shell</category>
        
        <category>lock</category>
        
      </item>
    
      <item>
        <title>CMD</title>
        <description>&lt;p&gt;使用linux的命令时，经常会用man来查询可选参数及其含义。偶尔我们也会开发自己的小工具。&lt;/p&gt;

&lt;p&gt;如何给小工具快速添加可选参数呢？&lt;/p&gt;

&lt;h2 id=&quot;java&quot;&gt;java&lt;/h2&gt;

&lt;p&gt;java的开发者应该是更喜欢使用配置文件的方式来与程序交互，无论是property还是yml。&lt;/p&gt;

&lt;p&gt;在参数不是特别多时，cmd的params也是不错的选择。提到给java传参数，大多数人一定是会&lt;/p&gt;

&lt;p&gt;想到main函数的args数组，这是基础，但不太方便。&lt;/p&gt;

&lt;p&gt;推荐使用commons-cli，能够设定长短参数(-i 或 –interval)，还能添加注解。&lt;/p&gt;

&lt;p&gt;具体的方法我就不展开讲了，网上能搜到很多。&lt;/p&gt;

&lt;h2 id=&quot;getopts&quot;&gt;getopt(s)&lt;/h2&gt;

&lt;p&gt;shell中最普遍的解决办法就是getopt，配合while case处理输入的参数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while getopts 'h:j:m:u' OPT;do
    case $OPTin
        j) S_DIR=&quot;$OPTARG&quot;;;
        m) D_DIR=&quot;$OPTARG&quot;;;
        u) upload=&quot;true&quot;;;
        h) func;;
        ?) func;;
    esac
done
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如何你想实现tab自动提示的话，可以了解一下_get_comp_words_by_ref。&lt;/p&gt;

&lt;h2 id=&quot;shell&quot;&gt;shell默认的参数处理&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
$0 : 脚本名
$N : 第N个参数.
$# : 参数的个数，不包括命令本身.
$@ : 参数本身的列表，也不包括命令本身，如上例为 -v -f -out /test.log –prefix=/home
$* : 参数本身的列表，也不包括命令本身，但”$*” 和”\$@”(加引号)并不同，”$*“将所有的参数解释成一个字符串，而”$@”是一个参数数组。

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这种处理方法没有getopt简洁，一般还是推荐使用getopt。但是下面这个特殊用法需要注意一下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&quot;${@:2}&quot;  从第二参数开始往后的所有参数

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 20 May 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-05-20-CMD</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-05-20-CMD</guid>
        
        
        <category>cmd</category>
        
        <category>shell</category>
        
      </item>
    
      <item>
        <title>UniswapOracle</title>
        <description>&lt;p&gt;这次聊聊Uniswap的预言机，上次我们介绍的Chainlink属于通用预言机。&lt;/p&gt;

&lt;p&gt;在Uniswap项目中，内置了一个预言机功能，算是专用吧，具有一定的特殊性。&lt;/p&gt;

&lt;h2 id=&quot;uniswap&quot;&gt;Uniswap&lt;/h2&gt;

&lt;p&gt;Uniswap最近一年非常的火热，算是Defi的基石项目了。随着其V3版本的发布，&lt;/p&gt;

&lt;p&gt;会吸引越来越多的做市商。这里介绍一个&lt;a href=&quot;https://liaoph.com/&quot;&gt;Blog&lt;/a&gt;。可以作为Uniswap的入门资料。&lt;/p&gt;

&lt;h2 id=&quot;uniswaporacle&quot;&gt;Uniswap的Oracle&lt;/h2&gt;

&lt;p&gt;之前讲的Chainlink的预言机，使用者大多关注当前价格，少量场景也需要历史价格。&lt;/p&gt;

&lt;p&gt;Uniswap的Oracle是提供时间加权平均价，并且可以随意指定周期。设计出这样的Oracle，&lt;/p&gt;

&lt;p&gt;主要是为了抵御价格操纵闪电贷之类的攻击。在目前的Defi项目中，这类需求还是比较普遍的。&lt;/p&gt;

&lt;p&gt;我个人觉得Uniswap的Oracle时间加权思路是不错的，但不适合普及使用。比如标的非常有限、&lt;/p&gt;

&lt;p&gt;存储数据的精度问题等等。但是提供的按照时间二分查找的功能是Chainlink所缺少的。&lt;/p&gt;

&lt;h2 id=&quot;ema&quot;&gt;通用化EMA指标预言机&lt;/h2&gt;

&lt;p&gt;在清算类的业务中，一般使用指数类的价格，比如MA、EMA。期货合约的清算逻辑，&lt;/p&gt;

&lt;p&gt;用来计算是否强制平仓的价格，就不会使用现货的当前价格，一般是EMA(5min)之类的。&lt;/p&gt;

&lt;p&gt;主要是为了削弱价格剧烈波动导致的连锁爆仓反应。&lt;/p&gt;

&lt;p&gt;如果提供一种类似EMA计算的指标价格预言机，我相信会对清算类的业务非常友好。&lt;/p&gt;

&lt;p&gt;可以沿用现有预言机的大部分接口，没有数据精度问题，可轻松获取历史轨迹，作为独立&lt;/p&gt;

&lt;p&gt;计算存储的合约，不与其他项目绑定，可重复利用现有“共识”预言机的结果，保证准确。&lt;/p&gt;

&lt;p&gt;当然这样的方案相对Uniswap的Oracle会缺少一个周期的灵活性，但我个人认为这个不是&lt;/p&gt;

&lt;p&gt;十分重要，大多数项目需要的周期都是可以协调的，而且固定。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;预言机的话题就告一段落，这个领域也算是刚刚起步，Chainlink也在快速发展中，希望能够&lt;/p&gt;

&lt;p&gt;有更开放的社区，可以有更多的协作模式，让开发者参与共建。&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Apr 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-04-27-UniswapOracle</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-04-27-UniswapOracle</guid>
        
        
        <category>Uniswap</category>
        
        <category>Oracle</category>
        
      </item>
    
      <item>
        <title>Chainlink</title>
        <description>&lt;p&gt;Chainlink目前已经是预言机领域里的顶流项目，无论是经济模型还是架构设计&lt;/p&gt;

&lt;p&gt;都非常值得学习的。&lt;/p&gt;

&lt;h2 id=&quot;oracle&quot;&gt;预言机Oracle&lt;/h2&gt;

&lt;p&gt;因为以太坊区块链上无法发起对外部世界的请求，也就是无法直接获取外部数据，&lt;/p&gt;

&lt;p&gt;极大的限制了智能合约的使用范围。将外部数据引入区块链世界，就是预言机的职能，&lt;/p&gt;

&lt;p&gt;将拉取数据变为推送数据，保存在合约里。这一点与流计算中的恰好一次，其实是&lt;/p&gt;

&lt;p&gt;非常相似的问题。如果你想让流计算可以反复执行，且结果是恰好一次的，那需要&lt;/p&gt;

&lt;p&gt;严格控制堆外的依赖，比如Redis的计数器、外部系统的实时数据接口等。&lt;/p&gt;

&lt;p&gt;解决外部依赖问题时，经常是将外部数据写入流中（或join）、在流引擎内保存状态。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;成本问题&lt;/h2&gt;

&lt;p&gt;改为推送数据模式后，面临极大的成本问题。如果数据频繁发生变化，那就需要不断调用&lt;/p&gt;

&lt;p&gt;合约的更新方法。但链上业务使用数据并不一定那么频繁。或者是某些数据使用不太频繁。&lt;/p&gt;

&lt;p&gt;这个成本问题就极大的制约了预言机服务的范围，目前看几个主流预言机项目提供的数据&lt;/p&gt;

&lt;p&gt;总共也不超过100种。而且更新频率都不是很高，一般10分钟左右。&lt;/p&gt;

&lt;p&gt;除了写入成本以外，还有共识成本。比如早期的Chainlink所有节点都会把数据上报到合约中，&lt;/p&gt;

&lt;p&gt;最后算一个中位数。每一轮都会有20个左右的节点参与。相当于把写入成本放大了20倍。&lt;/p&gt;

&lt;p&gt;当然现在的Chainlink OCR已经把这个问题解决了，思路就是把共识环节放在低成本链去实现。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;共识问题&lt;/h2&gt;

&lt;p&gt;预言机的数据真的可以依靠共识来解决么？这是个非常值得讨论的话题，虽然共识是区块链&lt;/p&gt;

&lt;p&gt;类型的项目惯用的手法。但很多都是生搬硬套来的，并不是很恰当。API3项目的思路也不错，&lt;/p&gt;

&lt;p&gt;预言机的数据由可信的权威机构来提供，绕过了关于数据正确的证明过程，只解决可用性问题。&lt;/p&gt;

&lt;p&gt;Chainlink是依靠质押处罚、门限签名等手段来防止数据错误，再最新的计划里还将引入一些&lt;/p&gt;

&lt;p&gt;博弈论的思路，比如囚徒困境等，增加被攻击的难度。显然这些手段都是有一定积极效果的，&lt;/p&gt;

&lt;p&gt;但是为此付出的成本也是极大的，我个人并不看好这种发展思路。Chainlink未来的计划还是&lt;/p&gt;

&lt;p&gt;很值得期待的，主要是在零知识证明方向上，可信计算和验证等技术。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;服务模式&lt;/h2&gt;

&lt;p&gt;Chainlink采用的技术以去中心化为主，但是运用模式还是一个典型的中心化模式。&lt;/p&gt;

&lt;p&gt;毕竟当前还是处于发展的早期阶段，希望未来的Chainlink可以越来越自由化。&lt;/p&gt;
</description>
        <pubDate>Tue, 16 Mar 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-03-16-chainlink</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-03-16-chainlink</guid>
        
        
        <category>chainlink</category>
        
      </item>
    
      <item>
        <title>ETH合约</title>
        <description>&lt;p&gt;最近开始接触了一下ETH的智能合约，主要是通过Chainlink这个优秀的预言机项目。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;合约的特点&lt;/h2&gt;

&lt;p&gt;ETH上的合约主要是用Solidity语言来开发的，使用下来感觉语言本身还不是很成熟，&lt;/p&gt;

&lt;p&gt;数据结构比较单一，适合实现简单的计算逻辑和数据存储。&lt;/p&gt;

&lt;p&gt;与其他开发项目相比，代码一旦发布后很难修改，代码“性能”需要特别关注。&lt;/p&gt;

&lt;p&gt;合约代码在执行过程中依据Op来计算需要消耗的gas费，所以代码的质量非常关键。&lt;/p&gt;

&lt;p&gt;在我们了解Chainlink项目和开发自己的合约时碰到了下面几个案例，分享一下。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;写入与更新&lt;/h3&gt;

&lt;p&gt;Chainlink的历史数据是保存在合约的一个Map中，key是roundid，value是价格。&lt;/p&gt;

&lt;p&gt;在我们测试Map的写入与更新时发现，第一次写入某一个key和后面更新key的Value，&lt;/p&gt;

&lt;p&gt;费用差距是巨大的，大概是2倍左右。我们在设计类似保存历史数据的环节时，采用了&lt;/p&gt;

&lt;p&gt;循环key值，比如自增ID对1024取模，这样只有第一轮是insert，第1025次之后就是&lt;/p&gt;

&lt;p&gt;update了，费用会降低下来，在合约里只能查询一段时间的历史记录，之前的会被覆盖。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;代理&lt;/h3&gt;

&lt;p&gt;因为链上的合约一旦部署成功后，就不能修改了，如果想要升级就要使用新的合约地址了，&lt;/p&gt;

&lt;p&gt;这对外部依赖是非常不友好的。参考Chainlink和Openzapplin项目，一般都是采用代理&lt;/p&gt;

&lt;p&gt;模式将接口和实现解耦和，接口层记录了实现合约的地址，提供一个Update实现合约地址的&lt;/p&gt;

&lt;p&gt;方法，进行替换，来达到升级的目的。虽然可以实现，但是开发时非常繁琐。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;存储与计算分离&lt;/h3&gt;

&lt;p&gt;上面提到了升级的问题，如果你的合约里还保存了一些数据，那么在升级时也需要将其转移到&lt;/p&gt;

&lt;p&gt;新的合约里。部署合约是有费用成本的，如果在部署合约时，涉及到了大量的数据copy，&lt;/p&gt;

&lt;p&gt;这个成本会变得非常昂贵。代理模式只是解决了升级当中的持续稳定服务问题，在设计合约时，&lt;/p&gt;

&lt;p&gt;还需要将合约里的存储结构和计算逻辑进行解耦，一般我们只对计算逻辑进行升级，而存储部分&lt;/p&gt;

&lt;p&gt;不会移动，仅仅会修改一些写权限的控制，将新合约地址更新到存储数据的合约中去。&lt;/p&gt;
</description>
        <pubDate>Mon, 22 Feb 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-02-22-contract</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-02-22-contract</guid>
        
        
        <category>contract</category>
        
      </item>
    
      <item>
        <title>Master选举</title>
        <description>&lt;p&gt;今年的第一篇就写写Master的选举吧，在之前的工作经历中，我们经常碰到Master选举问题。&lt;/p&gt;

&lt;p&gt;比如Hbase、Hadoop的Master选举，都是通过Zookeeper来完成的，这几年比较流行K8s，&lt;/p&gt;

&lt;p&gt;很多组件的选举是通过ETCD来完成的。说到这需要补充一点背景知识，那就是Paxos和Raft，&lt;/p&gt;

&lt;p&gt;这里就不详细陈述了，自行搜索。&lt;/p&gt;

&lt;h2 id=&quot;redis&quot;&gt;通过Redis选举&lt;/h2&gt;

&lt;p&gt;不是任何时候我们都能使用ZK、ETCD来完成选举的，比如部署规模的限制。最近碰到了一个场景，&lt;/p&gt;

&lt;p&gt;需要进行Master的选举，但是部署规模非常小，无法引入其他组件来辅助，项目中有使用到Redis，&lt;/p&gt;

&lt;p&gt;于是开发了一个基于Redis的简易选举方案。&lt;/p&gt;

&lt;h3 id=&quot;redis-1&quot;&gt;如何利用Redis选举&lt;/h3&gt;

&lt;p&gt;网上有很多文章介绍，大体都是基于Redis的SetN指令的特性，进行一个分布式锁的争抢过程，&lt;/p&gt;

&lt;p&gt;抢到锁的即为Master。如果你使用过Redission的客户端，可以直接使用Rlock来完成这个工作。&lt;/p&gt;

&lt;p&gt;Redission中大量的封装了LuaScript，来完成一些事务性的工作。&lt;/p&gt;

&lt;h3 id=&quot;redis-2&quot;&gt;利用Redis选举的弊端&lt;/h3&gt;

&lt;p&gt;为了性能考量，在写入时只要主节点成功，就会返回True。所以在故障时，主从可能会不一致。&lt;/p&gt;

&lt;p&gt;在抢锁这个场景中，也就是会短暂出现两把锁。当然通过结构上的设计是可以尽量降低这个概率的，&lt;/p&gt;

&lt;p&gt;但无法彻底消除。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;选举的大致逻辑&lt;/h3&gt;

&lt;p&gt;1、 无锁时，争抢创建锁&lt;/p&gt;

&lt;p&gt;2、 有锁时，没有抢到锁的节点，观察等待锁消失&lt;/p&gt;

&lt;p&gt;3、 有锁时，抢到锁的节点，延续锁的TTL&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;代码示例&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while (true) {
            try {
                RBucket&amp;lt;String&amp;gt; currentLock = this.redis.getBucket(this.lockName, StringCodec.INSTANCE);
                String currentLockValue = currentLock.get();

                if (StringUtils.isBlank(currentLockValue)) {
                    if (log.isDebugEnabled()) {
                        log.debug(&quot;start election .&quot;);
                    }
                    boolean success = currentLock.trySet(this.deviceId, DURATION_TIME, TimeUnit.SECONDS);
                    if (log.isDebugEnabled()) {
                        log.debug(&quot;election result : &quot; + success);
                    }
                    update(success);
                    Util.sleepSec(10);
                } else {
                    long remainTime = currentLock.remainTimeToLive();
                    if (remainTime &amp;lt;= 0) {
                        continue;
                    }
                    String tValue = currentLock.get();
                    if (!currentLockValue.equals(tValue)) {
                        continue;
                    }

                    if (this.deviceId.equals(currentLockValue)) {
                        if (log.isDebugEnabled()) {
                            log.debug(&quot;I am master .&quot;);
                        }
                        if (remainTime &amp;gt;= TimeUnit.SECONDS.toMillis(DISPUTE_TIME)) {
                            currentLock.expire(DURATION_TIME, TimeUnit.SECONDS);
                            if (log.isDebugEnabled()) {
                                log.debug(&quot;renew lock ttl .&quot;);
                            }
                            update(true);
                        } else {
                            update(false);
                            if (log.isDebugEnabled()) {
                                log.debug(&quot;unstable .&quot;);
                            }
                        }
                        Util.sleepSec(10);
                    } else {
                        update(false);
                        if (log.isDebugEnabled()) {
                            log.debug(&quot;wait for next time .&quot;);
                        }
                        Util.sleepMS(remainTime);
                    }
                }
            } catch (Throwable e) {
                log.error(&quot;Election Error : &quot;, e);
                Util.sleepSec(1);
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 19 Jan 2021 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2021-01-19-master</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2021-01-19-master</guid>
        
        
        <category>master</category>
        
      </item>
    
      <item>
        <title>2020年总结</title>
        <description>&lt;p&gt;2020年真的非常魔幻，也经历了很多变化。庆幸的是现在做的事情是自己喜欢的。&lt;/p&gt;

&lt;p&gt;以前都是写写总结，这次就写设想和展望吧。&lt;/p&gt;

&lt;p&gt;希望2021年能更新一下自己的Java知识，这几年一直在使用Java8，也是时候升级了。&lt;/p&gt;

&lt;p&gt;需要补充一点Go或者Rust的知识，看一些区块链项目的时候会用到。如果还有时间的话，&lt;/p&gt;

&lt;p&gt;Lua还需要捡起来了，未来也会用得上。&lt;/p&gt;

&lt;p&gt;2021年需要花点时间在机器学习的入门上，这方面之前没什么涉猎，可能会辛苦一点。&lt;/p&gt;

&lt;p&gt;之前几年的工作都和算法没什么关系，这方面需要多储备一点了。&lt;/p&gt;

&lt;p&gt;2021年需要多学习一些金融知识，尤其是期权和对冲相关的。&lt;/p&gt;

&lt;p&gt;之前几年都在做实时流计算方面的事，尤其是今年实时流计算非常的火热，但我并不看好这个方向。&lt;/p&gt;

&lt;p&gt;实时计算是个非常昂贵的事情，并不能普及在大多数无价值和意义的业务和数据上，完全是在浪费。&lt;/p&gt;

&lt;p&gt;真正有实时价值的业务其实非常的少，目前在跑的实时业务有很多是在滥竽充数，完成KPI而已。&lt;/p&gt;

&lt;p&gt;那些真正具有“实时”要求的业务，Flink也是无法满足的，因为他的实时能力是非常有限的。&lt;/p&gt;

&lt;p&gt;2021年我不会投入精力在这方面了，很有可能会转向CEP，也算是个延续吧。&lt;/p&gt;

&lt;p&gt;工作十年，大多实在研究技术本身，而非业务问题。从2021年开始，我会更关注问题本身，&lt;/p&gt;

&lt;p&gt;从另外一个角度来组合使用这些年的积累和认知。&lt;/p&gt;

&lt;p&gt;感谢各位看官，来年再见。&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Dec 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-12-30-summary</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-12-30-summary</guid>
        
        
        <category>summary</category>
        
      </item>
    
      <item>
        <title>double streaming 2</title>
        <description>&lt;p&gt;上期我们聊了双流的问题，接下来借着一个实际案例来看看。&lt;/p&gt;

&lt;p&gt;有两条信息流，一条是Tesla股票的K线行情变化，一条是用户设置的条件单记录。&lt;/p&gt;

&lt;p&gt;那么要如何设计一个流处理装置，来保证恰好一次计算呢？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;行情信息流&lt;/h2&gt;

&lt;p&gt;该流具备驱动流的特征，有单调性和持续性。因为一直有数据产生，所以不需要额外增加心跳数据包，&lt;/p&gt;

&lt;p&gt;只需要增加一个单调性的filter就可以了（当前数据的时间或者序号需要大于前一条）。当行情数据&lt;/p&gt;

&lt;p&gt;到达时会写入内存缓存中，该缓存会保持一段时间，后面会介绍它的用途。最后通过行情数据本身的&lt;/p&gt;

&lt;p&gt;时间戳来控制条件单记录的加载的时机。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;条件单信息流&lt;/h2&gt;

&lt;p&gt;该流的数据量比较小，而且可能局部乱序，为此增加了心跳数据包，代表时间进度。心跳数据包只包&lt;/p&gt;

&lt;p&gt;含一个时间戳，其含义是该信息流中不会再出现比此时间戳更早的数据了，在生成心跳包的时候我们&lt;/p&gt;

&lt;p&gt;可以刻意的delay几秒。这个和flink中的watermarket很相似。心跳包的数据到达时，可以触发过&lt;/p&gt;

&lt;p&gt;期行情缓存数据的清理工作。因为这些行情信息再也用不到了。条件单的数据到达时，如果早于行情&lt;/p&gt;

&lt;p&gt;当前的时间进度，那么就放在cache里，等待行情数据到达时触发其加载。如果晚于行情的当前的时&lt;/p&gt;

&lt;p&gt;间进度的话，就要触发一个特殊环节，利用行情缓存的历史数据进行计算，之后合并结果。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;上面两条流的处理方式就是前一篇Blog中提到的协调器，满足如下四个功能：&lt;/p&gt;

&lt;p&gt;驱动流缓存池、被动流缓存池、被动流增量加载方法、被流动回溯方法。&lt;/p&gt;

&lt;p&gt;具体代码可以在fevernova的markettracing中找到，这里就不多说了。&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Nov 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-11-19-doublestreaming</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-11-19-doublestreaming</guid>
        
        
        <category>streaming</category>
        
      </item>
    
      <item>
        <title>double streaming</title>
        <description>&lt;p&gt;今天聊聊双流的实时计算问题，我个人觉得算是流处理中最复杂的一个场景了。&lt;/p&gt;

&lt;p&gt;想要在两个Source同时作为input时，保证流处理的恰好一次计算，仅仅依靠chandy-lamport是不够的。&lt;/p&gt;

&lt;p&gt;两个Source的input交叉顺序是随机的行为，在业务上有严格的恰好一次要求，且代码还做不到&lt;/p&gt;

&lt;p&gt;顺序不敏感时，怎么办呢？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;合并流&lt;/h2&gt;

&lt;p&gt;最简单的办法是将两条流合并，将不确定的交叉行为给确定了,这样可以用chandy-lamport了。&lt;/p&gt;

&lt;p&gt;合并流会增加一个merge任务和一个新的kafka topic，相当于增加了一个环节、增加了一点延迟。&lt;/p&gt;

&lt;p&gt;虽然会浪费一点资源，但是简单高效。如果两个Source的Merge依据是Event Time，那么情况还&lt;/p&gt;

&lt;p&gt;要更复杂一些。单纯的把两条流Merge在一起并不能解决问题，还需要在一个时间窗口内进行缓冲排序。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;流转批&lt;/h2&gt;

&lt;p&gt;将流式处理转为批量处理也是可以解决这个问题的，以窗口1min为例。将两个Source的数据都&lt;/p&gt;

&lt;p&gt;缓存1min（内存里或者依赖外部存储），当窗口关闭时发起对这期间的数据进行处理。&lt;/p&gt;

&lt;p&gt;在处理时可指定某种确定的数据排序方法，保证处理顺序的一致性。这种方式只适用于数据量不大，&lt;/p&gt;

&lt;p&gt;对时效性要求不高的场景。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;限位器&lt;/h2&gt;

&lt;p&gt;不想合并出一个新的topic，也不想延迟太高，就需要在Streaming的模式下进行两个流的协调和缓冲。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;驱动流&lt;/h3&gt;

&lt;p&gt;首先，在两个Source中选出来一个，作为时间驱动的，要求是他的数据时间具备单调性，也就是有序的。&lt;/p&gt;

&lt;p&gt;在实际生产中，我们很难保证写入kafkaTopic里的数据一直单调有序，除非启用transaction。&lt;/p&gt;

&lt;p&gt;但是我个人觉得使用事务造成的问题远大于收益。我这里说的单调性和有序是相对的，应该叫整体有序，&lt;/p&gt;

&lt;p&gt;可以接受局部的重复和回退。当我们实时处理这个Source的数据时，有内存状态记录这上一条的时间&lt;/p&gt;

&lt;p&gt;或者序号进行过滤，一旦发生了回退或者重复的数据就直接跳过。这样我们在经过filter后，就得到了&lt;/p&gt;

&lt;p&gt;一条绝对有序的驱动数据流A，（后面简称为A）。注意，如果A在一定时间内没有数据产生，最好写入&lt;/p&gt;

&lt;p&gt;带有时间戳的心跳数据包，以方便时间管理的协调控制后。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;被动流&lt;/h3&gt;

&lt;p&gt;如果另外一个Source也是和驱动流一样，具备整体有序特征的话，就非常简单了。经过filter后，&lt;/p&gt;

&lt;p&gt;与A汇合入同一个Operator中，只需要按照两个流的时间进度进行控制，以A的时间为主，这个时候&lt;/p&gt;

&lt;p&gt;心跳数据包的作用就体现出来了，防止被动流的数据提前被加载进来。&lt;/p&gt;

&lt;p&gt;如果被动流的数据，不具备单调性，就需要建立缓冲空间，将被动流的数据变的有序起来。&lt;/p&gt;

&lt;p&gt;A可以适当延迟个几秒，等带被动流的窗口排序工作完成后再去驱动时间。同时也就是对被动流提出来&lt;/p&gt;

&lt;p&gt;新的要求，那就是虽然可以乱序，但是时效性必须高。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;协调器&lt;/h3&gt;

&lt;p&gt;一共需要四个组件：驱动流缓存池、被动流缓存池、被动流增量加载方法、被流动回溯方法。&lt;/p&gt;

&lt;p&gt;缓存驱动流最近N条数据，主要是给被动流严重delay数据进行回溯时使用的。&lt;/p&gt;

&lt;p&gt;如果被动数据没有严重delay，那么就写入到被动流缓冲池中。&lt;/p&gt;

&lt;p&gt;驱动流有新数据时，触发被流动缓冲池中的数据进行增量加载。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;上面提到的方案有很大的局限性，还需要进一步的实践的检验。&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Oct 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</guid>
        
        
        <category>streaming</category>
        
      </item>
    
      <item>
        <title>transaction</title>
        <description>&lt;p&gt;最近工作中大量的使用了Spring、Mybatis、JDBC的事务，这里稍作一下总结。&lt;/p&gt;

&lt;h2 id=&quot;springtransaction&quot;&gt;Spring的Transaction&lt;/h2&gt;

&lt;p&gt;现在Spring的Annotation就可以完成基本的事务配置，比起以前复杂的xml，确实方便了很多。&lt;/p&gt;

&lt;p&gt;网上能搜到很多介绍Spring-Transaction的，主要是讲事务的隔离级别和传播性，这里就不多说了。&lt;/p&gt;

&lt;p&gt;提醒大家去看看Spring-Transaction失效的N个原因，避免事务没有完整性的执行。&lt;/p&gt;

&lt;p&gt;我们犯的错是同class的非事务方法去调用事务方法，导致事务不起作用。&lt;/p&gt;

&lt;h2 id=&quot;jdbc&quot;&gt;JDBC事务&lt;/h2&gt;

&lt;p&gt;mysql有个参数是flush_tx_commit需要关注一下，可能会影响你的事务性能。&lt;/p&gt;

&lt;p&gt;事务中的操作肯定是串行的，所以还是尽量想办法让事务精简，能在事务外执行的尽量不要放进来。&lt;/p&gt;

&lt;p&gt;比如序列化、反序列化等耗时的操作，尽量提前准备好，再开启事务。单个事务的执行时间越短，&lt;/p&gt;

&lt;p&gt;多事务并发的性能才会更理想。在一些情况下，开启事务和逐个提交比起来会快一些，&lt;/p&gt;

&lt;p&gt;但不要为了追求这种性能而过分的扩大事务范围。锁的范围变大，大概率会与一些业务上的并发发生冲突，&lt;/p&gt;

&lt;p&gt;不利于整体性能的提升。&lt;/p&gt;

&lt;h2 id=&quot;mybatis&quot;&gt;Mybatis&lt;/h2&gt;

&lt;p&gt;这次项目中用的是mybatis-plus，在压测的时候关注了一下，性能确实很一般。&lt;/p&gt;

&lt;p&gt;但是因为项目本身的业务复杂性，直接使用jdbc确实很不方便。第一个性能问题就是分表plugin，&lt;/p&gt;

&lt;p&gt;做表名替换的开销比较大，从sql的参数中提取表名也可能比较慢。第二个性能问题就是通过mybatis&lt;/p&gt;

&lt;p&gt;处理数据，会导致比较频繁的ygc。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;之前并没有太多关于事务类型业务的开发经验，这次优化能提升两三倍还是很满意的。&lt;/p&gt;
</description>
        <pubDate>Sun, 27 Sep 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-09-27-transaction</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-09-27-transaction</guid>
        
        
        <category>transaction</category>
        
      </item>
    
  </channel>
</rss>
