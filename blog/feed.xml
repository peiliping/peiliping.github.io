<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing&#39;s Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 25 May 2017 19:33:38 +0800</pubDate>
    <lastBuildDate>Thu, 25 May 2017 19:33:38 +0800</lastBuildDate>
    <generator>Jekyll v3.1.2</generator>
    
      <item>
        <title>批量写入Mysql</title>
        <description>&lt;p&gt;Mysql是最常用的一种关系型数据库，随着各种ORM框架的演进，操作数据库也越来越简单。&lt;/p&gt;

&lt;p&gt;当你碰到一些极端需求时，还是要在JDBC这个层面上来操作数据库。&lt;/p&gt;

&lt;p&gt;今里就介绍一下，在批量写Mysql时碰到的问题。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;真正的批量写&lt;/h3&gt;

&lt;p&gt;使用JDBC来完成批量Mysql写入的一般方法是:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;this.connection.setAutoCommit(false);

this.preparedStatement = this.connection.prepareStatement(this.sql);
for (int i = 0; i &amp;lt; this.schema.size(); i++) {
    this.preparedStatement.setObject(i + 1, data[i], this.schema.get(i));
}
this.preparedStatement.addBatch();

...N次

this.preparedStatement.executeBatch();
this.connection.commit();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;当你写完这段代码之后，测试性能会发现，并没有什么提升。因为实际上还是一条条发送执行的。&lt;/p&gt;

&lt;p&gt;当你为DatasourceUrl添加了参数rewriteBatchedStatements=true，才会真正生效。&lt;/p&gt;

&lt;p&gt;具体原因可以自行搜索这个参数，网上有很多文章介绍。&lt;/p&gt;

&lt;p&gt;改了参数，性能提升三五倍是很轻松的，具体能提升多少要看实际的情况。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;选择好数据库的伴侣——数据源连接池&lt;/h3&gt;

&lt;p&gt;开源的数据源连接池非常多，c3p0、druid、Proxool、BoneCP、HikariCP等等。&lt;/p&gt;

&lt;p&gt;比较常用的是阿里开源的Druid，性能不是特别突出，但是综合表现不错。&lt;/p&gt;

&lt;p&gt;HikariCP也是性能表现很抢眼的选手。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;缓冲区&lt;/h3&gt;

&lt;p&gt;涉及到批量写入数据库就意味着可能和缓冲区打交道了。&lt;/p&gt;

&lt;p&gt;攒够一个批量（100条），但是也不能无限期的等，需要一个超时时间（15秒）。&lt;/p&gt;

&lt;p&gt;缓冲区可以用框架来实现，比如Disruptor的Ringbuffer无锁队列就可以满足这两个要求。&lt;/p&gt;

&lt;p&gt;Ringbuffer的具体使用方法这里就不介绍了，初次上手会有一些难度。&lt;/p&gt;

&lt;p&gt;Ringbuffer强制了数据对象的复用，来减少JVM GC的次数，对性能的提升非常有帮助。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;线程数和批量大小&lt;/h3&gt;

&lt;p&gt;加大处理数据的线程数也是一个提升处理速度的方法，当然也不能一直加大线程数，&lt;/p&gt;

&lt;p&gt;根据测试批量写的线程数不要超过Mysql的Cpu核数+1。&lt;/p&gt;

&lt;p&gt;批量条数要根据单行数据的大小决定，一般1000条左右。&lt;/p&gt;

&lt;h3 id=&quot;mysql&quot;&gt;Mysql性能优化&lt;/h3&gt;

&lt;p&gt;Mysql的性能优化去参考网上的文章，这里就不详细介绍了。&lt;/p&gt;

&lt;p&gt;大多是关闭一些log，提高一些buffer，改变filesync的方式等。&lt;/p&gt;

&lt;p&gt;表上的索引是很影响写入性能的，尽量保证索引精简。&lt;/p&gt;

&lt;h3 id=&quot;jdbc&quot;&gt;JDBC优化&lt;/h3&gt;

&lt;p&gt;根据前面的优化过后，使用JFR对你的程序做一下热点代码分析，就会发现JDBC的问题了。&lt;/p&gt;

&lt;p&gt;如果你仔细阅读过Java的MysqlConnector的代码就会发现，可以改造的地方还是挺多的。&lt;/p&gt;

&lt;p&gt;下面举几个例子：&lt;/p&gt;

&lt;p&gt;1、批量数据的暂存容器&lt;/p&gt;

&lt;p&gt;你提交到preparestatment中的数据，会暂时存到一个ArrayList中。&lt;/p&gt;

&lt;p&gt;在大批量数据处理时Arraylist就是一个优化点。跟HashMap一样，它也会涉及到resize的过程。&lt;/p&gt;

&lt;p&gt;在你初始化一个preparestatment的时候，根据你的批量大小，对其进行capacity的初始化，会带来不小的性能提升。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;this.batchArgsField = StatementImpl.class.getDeclaredField(&quot;batchedArgs&quot;);
this.batchArgsField.setAccessible(true);
...
this.batchArgsField.set((StatementImpl) ((DruidPooledPreparedStatement) this.preparedStatement).getStatement(), new ArrayList&amp;lt;Object&amp;gt;(stepSize));

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;2、日期格式化&lt;/p&gt;

&lt;p&gt;一般数据库表都会有一些日期类型的字段，比如创建时间、更新时间等。&lt;/p&gt;

&lt;p&gt;Java中的日期类型处理性能一直都不是很高，比如SimpleDateFormat就是一个关键点。&lt;/p&gt;

&lt;p&gt;代码详见com.mysql.jdbc.PreparedStatement.class.getDeclaredField(“tsdf”)，这里就不细说了。&lt;/p&gt;

&lt;p&gt;如果你的表字段日期类型比较多，可以考虑替换掉SimpleDateFormat的实现。&lt;/p&gt;

&lt;p&gt;比如用Calender的接口，通过字符串拼接的方式完成日期数据的格式化。性能也是会有一定的提升的。&lt;/p&gt;

&lt;p&gt;3、失败重试&lt;/p&gt;

&lt;p&gt;一个完善的数据处理流程，必然要考虑很多异常场景。比如网络闪断，数据库重启等等。&lt;/p&gt;

&lt;p&gt;如果在请求失败后重试呢？一般性的做法就是记录下批量写入的每一个参数，重新写入再执行一边。&lt;/p&gt;

&lt;p&gt;前面基于ringbuffer做了数据对象的复用，目的是减少gc，这里为了失败重试，再次引入重复对象是很难接受的。&lt;/p&gt;

&lt;p&gt;而且statement.setObject过程就是一个java对象序列化成byte的过程，重复执行也很浪费。&lt;/p&gt;

&lt;p&gt;最简单的办法就是利用前面初始化好的batchArgs，实际上他里面就记录了你写入的每一行数据。&lt;/p&gt;

&lt;p&gt;只要把它拷贝出来，写入新的preparestatement中，就可以再次执行了。&lt;/p&gt;

&lt;p&gt;注意executeBatch()一定不能丢掉&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;List&amp;lt;Object&amp;gt; batchParams = ((JDBC4PreparedStatement) ((DruidPooledPreparedStatement) this.preparedStatement).getStatement()).getBatchedArgs();
Connection tc = this.dataSource.getConnection();
tc.setAutoCommit(false);
PreparedStatement tp = tc.prepareStatement(this.sql);
StatementImpl target = (StatementImpl) ((DruidPooledPreparedStatement) tp).getStatement();
List&amp;lt;Object&amp;gt; newParams = new ArrayList&amp;lt;&amp;gt;(batchParams);
this.batchArgsField.set(target, newParams);
tp.executeBatch();
tc.commit();
tp.close();
tc.close();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;经过这些优化，我的程序（8G的JVM）可以每秒向Mysql写入十几万行数据（无索引的情况）。&lt;/p&gt;

</description>
        <pubDate>Thu, 25 May 2017 16:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-05-25-batch2mysql</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-05-25-batch2mysql</guid>
        
        
        <category>java</category>
        
        <category>mysql</category>
        
        <category>batch</category>
        
        <category>ringbuffer</category>
        
        <category>jdbc</category>
        
      </item>
    
      <item>
        <title>Meepo</title>
        <description>&lt;p&gt;Meepo最开始是为了Mysql到Mysql的数据迁移开发的，今年年初对其进行了重构。&lt;/p&gt;

&lt;p&gt;目前可以基本替代Sqoop完成每天凌晨将Mysql数据拷贝到HDFS上的需求，数据格式为Parquet+Snappy。&lt;/p&gt;

&lt;p&gt;并且Meepo还提供了AVSC文件，方便Hive更新表结构（TBLPROPERTIES (‘avro.schema.url’=’hdfs://onlinecluster/xxxxxxxxxx)）。&lt;/p&gt;

&lt;p&gt;Meepo的Mysql数据表迁移功能也优化了很多：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;支持基本字段类型的自动匹配转化&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;自动识别表结构和主键&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;支持同时使用N个Plugin&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;提供了ReplacePlugin，用于系统升级中常见的表字段值替换需求（查另外一张表，来决定替换成什么值）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这次重构中，还引入了Disruptor的Ringbuffer，作为数据缓冲区。&lt;/p&gt;

&lt;p&gt;Ringbuffer强制了对象复用，大幅度减少了GC的频率，使得Meepo可以用更小的JVM来完成任务，性能也有一定的提升。&lt;/p&gt;

&lt;p&gt;在我们的测试中，Meepo的吞吐能力一直在每秒6W行以上，极限可以达到每秒15W。&lt;/p&gt;

&lt;p&gt;这次重构后的测试中，也找到了更多应该暴露的Metric指标，方便对Meepo进行调优。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Apr 2017 09:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-04-18-meepo</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-04-18-meepo</guid>
        
        
        <category>java</category>
        
        <category>mysql</category>
        
        <category>sqoop</category>
        
        <category>parquet</category>
        
        <category>avsc</category>
        
        <category>ringbuffer</category>
        
      </item>
    
      <item>
        <title>Java Flight Recorder</title>
        <description>&lt;p&gt;Profiling是最常见的，用来定位代码性能问题的方法。&lt;/p&gt;

&lt;p&gt;在开发环境中，我们用Visualvm、JProfiler、Yourkit等。这些工具功能强大，支持图形化界面操作，可以让我们很快定位代码问题。&lt;/p&gt;

&lt;p&gt;但是他们对应用性能的影响也非常大，所以不适合在生产环境下使用。还有这些软件要attach到jvm进程上，生产环境一般网络隔离，很难做到。&lt;/p&gt;

&lt;p&gt;在生产环境我们最常用的profiling工具就是java/bin下的jstack，多做几次jstack，也相当于profiling了。有很多工具就是对多次的jstack结果进行合并，来分析问题的。&lt;/p&gt;

&lt;p&gt;jstack方便易用，但并不是特别适合来做profiling，操作频率低，会导致safepoint指标急剧增长等等。&lt;/p&gt;

&lt;p&gt;于是我们尝试使用Jvm原生提供的JFR - Java Flight Recorder 来解决问题。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;使用方法&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid VM.unlock_commercial_features&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.start duration=60s filename=/home/peiliping/dev/logs/test.jfr settings=[default,profile]&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.check 检查当前运行状况&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;jcmd pid JFR.stop name=test.jfr 或者 jcmd pid JFR.stop recording=3 name和recording的值参见check的结果&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;将生成的jfr文件传回到自己的电脑中&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;shell下执行jmc，启动图形化客户端，导入jfr文件，就可以看到cpu、gc、线程、io、代码热点等监控信息了&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果需要定制化jfr抓取的指标，可以修改setting的xml文件，/…./JDK/jdk1.8.0_51/jre/lib/jfr/&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 31 Mar 2017 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2017-03-31-jfr</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2017-03-31-jfr</guid>
        
        
        <category>java</category>
        
      </item>
    
      <item>
        <title>Nginx配置</title>
        <description>&lt;p&gt;今年进行了一次Nginx的大面积升级，把Nginx的安装配置方法记录一下。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;依赖准备&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;下载一个稳定版本的&lt;a href=&quot;https://nginx.org/en/download.html&quot;&gt;Nginx源码包&lt;/a&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;因为Nginx一般都是挡在最前面的系统，所以要做一些基本的保护，防止死机，github上有一些开源项目可以集成到Nginx中去，比如nginx-http-sysguard。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;NginxPlus版本有自定义心跳检查的功能，但是免费版没有提供。为什么要自定义，而不是用默认的upstream心跳检查呢？如果能自定义的话，可以做更加优雅平滑的发布，还可以做引流压测。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nginx默认的监控比较弱，同样丰富的监控都在NginxPlus里提供，只能自己开发了。配套定制一下Tsar，将监控信息记录在Tsar中。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;现在绝大多数网站都是https了，所以openssl和证书也要准备好。openssl这两年出了好多头条，慎重选择。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nginx编译时依赖的一些包，比如：pcre、zlib、perl-devel、perl-ExtUtils-Embed等&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nginx的服务器一般都有外网IP，所以也需要定制一些防火墙策略。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为了提高Nginx的吞吐能力需要修改一些系统参数（/etc/sysctl.conf和/etc/security/limits.conf）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Nginx日志默认是没有daily-rolling功能的，需要配和其他软件来实现。之前是用cronlog和fifo文件来实现的，这次统一换成logrotate，logrotate相关资料这里就不介绍了。注意不要使用copy模式，Nginx的accesslog很大，copy非常消耗性能。下面给一个配置的例子：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/log/nginx/*.log {
    daily
    rotate 1
    missingok
    nocompress
    notifempty
    dateext
    postrotate
    if [ -f /pid/nginx.pid ]; then
        kill -USR1 `cat /pid/nginx.pid`
    fi
    endscript
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;编译安装&lt;/h3&gt;

&lt;p&gt;Nginx启动一般需要80端口，如果不想用root来启动的话，就需要特殊处理一下&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;src/nginx/configure --prefix=/local/nginx ....
make -j ${nc} &amp;amp;&amp;amp; make install
chown -R nginx:nginx /local/nginx
chown root:nginx /local/nginx/sbin/nginx
chmod 6755 /local/nginx/sbin/nginx
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;nginx&quot;&gt;Nginx配置&lt;/h3&gt;

&lt;p&gt;Nginx的配置实在是太多了，下面只写一些值得注意的配置项&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;worker_processes和worker_cpu_affinity 在新版nginx中都可以设置为auto&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;log_format中$upstream_addr最好用引号或者中括号扩起来，因为他的输出不仅仅是一个IP，可能是多个Ip或者upstream的名字或者是中横线&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;merge_slashes合并url中连续出现的两个/，防止url拼接错误导致无法访问&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;proxy_set_header设置要注意，在http、server、location层都能够进行定义，但是并不是merge覆盖的逻辑，官方文档是这样说的，These directives are inherited from the previous level if and only if there are no proxy_set_header directives defined on the current level。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;proxy_ignore_client_abort默认为off，千万不要轻易开启。可能会导致Nginx活跃链接数持续增长，tcp状态close_wait持续增长，只能重启Nginx进程才能回收，网上说的修改linux内核参数也无法回收。大致过程是，客户端发起请求，后端的业务服务器无法及时响应该请求等待超时，如果客户端配置了较短的超时，客户端就会主动关闭此连接，当Nginx断开与tomcat的proxy连接时，客户端连接早已不存在了，此连接就会挂在Nginx上，无法释放。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;ssl_ciphers设置不当可能导致某些浏览器无法访问，认为网站是不安全的，在IE和Firefox中尤为明显。ssl相关配置有一些&lt;a href=&quot;https://mozilla.github.io/server-side-tls/ssl-config-generator/&quot;&gt;自动生成器&lt;/a&gt;，github上也有一些自动的shell脚本可以参考。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;简化proxy_pass对应upstream的配置，可以将upstream的名字设置为host的值(proxy_pass http://$host;)，这样很多server的配置就可以复用了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;server同时有80和443可以配置成这样：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;listen 80;
listen 443 ssl;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

</description>
        <pubDate>Fri, 16 Dec 2016 14:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2016-12-16-nginx</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2016-12-16-nginx</guid>
        
        
        <category>nginx</category>
        
      </item>
    
      <item>
        <title>日志采集工具Logwatch</title>
        <description>&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;2016年11月到12月中旬，开发了&lt;a href=&quot;https://github.com/peiliping/logwatch&quot;&gt;Logwatch&lt;/a&gt;的第一个版本。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;去年公司生产环境下的应用日志采集，主要用的是Logstash，也就是ELK豪华套餐中的“L”。碰到的主要问题是：Cpu开销高、内存占用高（比如采集NginxAccessLog，NgxQPS 1000+ ，Logstash要消耗2G的内存，Cpu开销也有很大的波动）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;市面上与Logstash同类的开源项目有Flume、Heka、Fluentd、Graylog、Logkafka，以及各种Syslog和Collecter。不仅开源世界百花齐放，几乎每家云计算服务提供商还都提供日志采集、传输和搜索服务。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;简单总结一下这些开源项目或多或少存在的一些问题：&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;只支持单行Log，无法对Java应用中的ExceptionLog进行有效的采集和解析&lt;/li&gt;
    &lt;li&gt;解析日志不够灵活&lt;/li&gt;
    &lt;li&gt;性能一般&lt;/li&gt;
    &lt;li&gt;不支持Kafka作为输出&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;自己造一个轮子要达到什么目标呢？&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;代码要少，简单可控&lt;/li&gt;
    &lt;li&gt;性能要好，不能因为采集日志影响了应用的性能&lt;/li&gt;
    &lt;li&gt;支持新版Kafka(0.10+)&lt;/li&gt;
    &lt;li&gt;支持单双行混合模式的应用日志&lt;/li&gt;
    &lt;li&gt;对简单格式的日志可以不用编写正则表达式，根据类似nginx的logformat配置格式，自动生成解析正则,也就是logwatch里的grok功能&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;Lua程序优化的心得&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Lua的协程切换开销非常低，封装调度任务非常合适&lt;/li&gt;
    &lt;li&gt;Lua的正则性能非常好，其非贪婪匹配‘(.-)’，可以应用于非常多的解析场景，简单高效,控制好回溯，尽量明确字符类型&lt;/li&gt;
    &lt;li&gt;table要尽量复用，减少创建table和table.insert的过程中resize的开销&lt;/li&gt;
    &lt;li&gt;不要反复做字符串拼接，必要时用table.concat替代&lt;/li&gt;
    &lt;li&gt;尽量使用ipairs，少使用table.foreach&lt;/li&gt;
    &lt;li&gt;尽量不要相信网上传说的Lua优化写法，Luajit已经优化了绝大多数问题了&lt;/li&gt;
    &lt;li&gt;Luajit有profile功能，可以用于测试代码热点&lt;/li&gt;
    &lt;li&gt;程序运行一次很快，运行几亿次再看看性能如何&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 15 Dec 2016 20:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2016-12-15-logwatch</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2016-12-15-logwatch</guid>
        
        
        <category>lua</category>
        
        <category>log</category>
        
        <category>kafka</category>
        
      </item>
    
  </channel>
</rss>
