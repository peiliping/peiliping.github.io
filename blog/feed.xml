<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 13 Oct 2019 15:08:09 +0800</pubDate>
    <lastBuildDate>Sun, 13 Oct 2019 15:08:09 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>FlinkJob双十一前备战注意事项</title>
        <description>&lt;h3 id=&quot;section&quot;&gt;1、确定双十一期间的数据特征&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	1.1、一般为数据条数倍增
	1.2、也有一些业务是单条数据体积增大
		1.2.1、考虑在消息中间件的messagesize的限制
		1.2.2、对序列化、反序列化的性能影响
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-1&quot;&gt;2、准备压测数据&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	2.1、根据业务逻辑随机生成数据
	2.2、通过kafka等消息中间件将多天的数据一次性消费完
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;3、数据源检查&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	3.1、kafka的流控阈值是否合理
	3.2、kafka的pt数是否够用
		3.2.1、临时扩容kafka的pt只对新数据有帮助，历史数据积压无法快速消除
		3.2.2、确定数据在源头没有严重的数据倾斜问题，防止大量数据集中于某一个特定的pt上
		3.2.3、kafkasource的parallelism应为pt数的1/2或1/4，预留临时扩大parallelism的空间
	3.3、增加高效的数据质量校验，检查job逻辑，适当的增加try-catch，注意catch发生时对性能的影响
	3.4、配置好监控
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;4、时间窗口逻辑&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	4.1、如果job存在时间窗口逻辑，要考虑模拟数据的正确性，简单的通过2.2进行性能测试大多无效
	4.2、不单单指flink的window操作，一些job逻辑中也可能包含时间窗口概念（比如：积攒10s的数据再批量输出，统计单位时间的uv等）
	4.3、乱序数据的问题也可能更为严重，合理指定latency或者watermarket逻辑
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;jobio&quot;&gt;5、检查job的外部io依赖&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	5.1、一般job都依赖redis、hbase等存储，在数据处理过程中对数据进行加工
		5.1.1、外部依赖的资源是否够用（存储、性能等）
		5.1.2、配置监控，有容灾方案
	5.2、适当使用asyncIO来提升性能
		5.2.1、不建议将有外部IO依赖的Operator的parallelism设置的非常大，一般都可以通过asyncIO来解决，更利于chaining-strate	gy的优化
		5.2.2、不要一味的提升asyncIO的thread数，适当做batch效果更佳，可参照sdk中的async-batch模型
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sink&quot;&gt;6、关于Sink输出&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	6.1、kafkasink的parallelism不要与pt数绑死，防止pt扩容无效，也不要过大的parallelism
	6.2、如果序列化逻辑过于耗时，建议单独写在一个Operator里
	6.3、尽量不要单条数据sink输出，会对外部造成很大的压力
	6.4、batchsink时注意flush与checkpoint之间的关系
	6.5、batchsink时谨慎处理batchsize和lingertime
	6.6、在sink中实现重试逻辑，尽量不要将exception交给flink，效率太低，代价太大
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;checkpoint&quot;&gt;7、Checkpoint设置&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	7.1、合理设置checkpoint的频率，不要过于频繁
	7.2、慎重使用exactly-once，能不用尽量不用
	7.3、检查任务对于State的依赖程度，配合Savepoint启停任务
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-4&quot;&gt;8、日志&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	8.1、净化日志打印内容
	8.2、避免system.out.println或者e.printstacktrace()等
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-5&quot;&gt;9、内存使用情况&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	9.1、关注ygc、fgc的频率和耗时
	9.2、堆外空间的使用情况
	9.3、networkbuffer的分配比例
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-6&quot;&gt;10、背压&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	10.1、在性能测试时可以使用原生背压探测方式分析背压情况
	10.2、我们定制的背压监控是更为准确的量化指标，无需开启就可实现全天候的监控，不但可以定位，还能分析趋势
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;jobgraph&quot;&gt;11、jobgraph&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	11.1、核心Operator设置uid或uidhash
	11.2、使用预览拓扑功能提交job
	11.3、谨慎控制chaining-strategy，尤其是cpu开销高的Operator尽量分散
	11.4、尽量离散同类slot，控制slot在taskmanager的分配策略
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 08 Oct 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-10-08-flink8-operation</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-10-08-flink8-operation</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>人生第一次手术-ACL</title>
        <description>&lt;h2 id=&quot;section&quot;&gt;绞索&lt;/h2&gt;

&lt;p&gt;当右腿轻轻发力向左侧跳起时，汗水在眼角滑落。没有任何的预兆，右膝关节在腾空的瞬间发生了绞索，嘭的一声。我没有跌倒，左脚缓冲几下后跪在地上，右膝活动受限，尝试几次都没能将绞索打开，我预感情况不会很好。回家冰敷后，几次尝试打开绞索，但没有作用，这次可能真的遇到麻烦了。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;核磁&lt;/h2&gt;

&lt;p&gt;几经辗转，在傍晚时来到德尔康尼专科医院，这里可以在今晚就拍核磁片子，确诊伤的到底有多重。结果当然是令人沮丧的，我的十字韧带前叉断裂、半月板撕裂，医生的建议是手术治疗。喜欢看体育的人应该都听过这个伤——十字韧带断裂+半月板撕裂，会联想起好多名字，皮耶罗、罗纳尔多、欧文、巴乔、卡卡……与这个伤同时出现的一句解说词就是赛季报销了。回家的路很远，我大概知道接下来几个月将面临什么样的困难，也许困难比想的还要多。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;求医&lt;/h2&gt;

&lt;p&gt;在家楼下和哥们家明抽了手术前的最后一颗烟，从明天开始放下一切，全力治伤。来北京的第六个夏天，我习惯了医院的味道。先后在人民医院、北医三院问诊后，明确我的伤一定要做手术了。单纯的十字韧带前叉断裂也不一定需要手术治疗，消肿后断裂的韧带会形成瘢痕，还能起到一点作用，患者加强腿部肌肉力量的训练，可以稳定住关节。但我的半月板伤势也很重，必须要手术治疗。两处伤复合在一起，也意味着我的康复周期会变的漫长。求医问诊的过程中，我渐渐对膝关节有了些了解，对于我未来的康复有了认知，至少三个月，也可能是半年。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;鼓励&lt;/h2&gt;

&lt;p&gt;一周的时间里，无数次放大那些“可能性”，每天过的都很昏暗。把电话打给了雪松，我已经不记得聊了什么，十几年的朋友，他一定知道我的感受。跟他比起来，我所经历的都不算什么。在回复彪哥的微信里我说，我的右膝有陈旧伤，如果不是今年断掉，未来十年也极有可能发生，趁年轻恢复的还快一点。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;手术&lt;/h2&gt;

&lt;p&gt;最佳的手术时间一般是受伤后的两三周，需要等关节基本消肿，这次期间尽量恢复腿部的活动能力，加强肌肉力量。这是我第一次做手术，内心无比恐惧。手术是腰部以下麻醉，躺在手术台上有点冷，渐渐的失去了下肢的感觉。十字韧带前叉做了自体取材的重建手术，半月板进行打磨后缝合了五针，什么锤子、螺丝、电钻都用上了。手术很顺利，半月板比预期还要严重，好在大部分都保留了下来。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;康复&lt;/h2&gt;

&lt;p&gt;手术后的第四天，我拄拐走出医院的时候，恍如隔世。手术只是开始，康复更为重要。接下来我要面临漫长的恢复期，需要不断与疼痛做斗争。为了恢复的快一点，我在一家私立的康复医院继续接受治疗。&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;感谢&lt;/h2&gt;

&lt;p&gt;这个夏天要感谢的人很多。&lt;/p&gt;

&lt;p&gt;我的妻子，在这个夏天经历了太多的心酸，这是我们结婚后的第一个纪念日，只能在医院度过。&lt;/p&gt;

&lt;p&gt;我的父母，开始留意每一样对膝关节有帮助的食物，开始每天等我的视频通话。&lt;/p&gt;

&lt;p&gt;我的朋友们，是你们的鼓励陪我度过了这个艰难的夏天，认识你们是我的福气。&lt;/p&gt;
</description>
        <pubDate>Sat, 20 Jul 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-07-20-acl-operation</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-07-20-acl-operation</guid>
        
        
        <category>手术</category>
        
      </item>
    
      <item>
        <title>初识flink7</title>
        <description>&lt;p&gt;flink基于1.5的定制化开发工作就告一段落了，业务团队对flink的诉求已经超越1.5了，&lt;/p&gt;

&lt;p&gt;主要集中在table、sql、state上，还有2phase的filesink等。&lt;/p&gt;

&lt;h2 id=&quot;or-18&quot;&gt;1.7 or 1.8&lt;/h2&gt;

&lt;p&gt;一个大的社区版本一般要维护1年左右。1.5的社区版我们从18年6月维护到现在，&lt;/p&gt;

&lt;p&gt;但从去年年底开始社区就对1.5停更了，我们只能自己从其他的版本中merge一些需要的bugfix。&lt;/p&gt;

&lt;p&gt;我们决定下一个大版本是1.8，主要基于一下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;社区1.9的巨大投入会严重影响其他分支的更新速度，1.7已经进入暮年。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;1.8的一些小特性我们看来还是非常实用的，值得蹚雷。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;刚刚准备release-1.8.1，未来还能从社区得到3-4个小版本。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;1.9的更新过于巨大，真正稳定下来需要比较长的时间，1.8在未来一年多应该是首选。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;section&quot;&gt;合并&lt;/h2&gt;

&lt;p&gt;1.8.1的一些issue被社区移到1.8.2去完成，所以很快就进入了RC阶段。&lt;/p&gt;

&lt;p&gt;我们在1.8分支上，进行了merge工作，主要是把我们在1.5上的定制工作迁移到1.8。&lt;/p&gt;

&lt;p&gt;合并的工作开展速度还是挺快的，预计2周左右就可以完成，顺手可以做一些小的重构。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;未来&lt;/h2&gt;

&lt;p&gt;在1.8的基础工作完成后，我们就要投入到Sql方向了。&lt;/p&gt;

&lt;p&gt;Sql的方向需要一些铺垫，比如State的管理功能增强，数据Table化等。&lt;/p&gt;

&lt;h3 id=&quot;state&quot;&gt;State增强&lt;/h3&gt;

&lt;p&gt;flink的state是核心组件，无论是故障恢复还是恰好一次，都至关重要。&lt;/p&gt;

&lt;p&gt;但是State的管理功能并不完善，比如如何让savepoint周期性的触发，&lt;/p&gt;

&lt;p&gt;如何合理利用checkpoint来恢复等。&lt;/p&gt;

&lt;h3 id=&quot;table&quot;&gt;数据Table化&lt;/h3&gt;

&lt;p&gt;Flink的数据来源其实是比较集中的，大部分来自Kafka或者MQ。&lt;/p&gt;

&lt;p&gt;再经过一些反序列化工作，应该可以映射为Pojo或者说Table。&lt;/p&gt;

&lt;p&gt;这部分工作在其他公司里也是差不多的，做一些定制化的开发，并不难。&lt;/p&gt;

&lt;p&gt;但是一些数据质量高的公司做这一步就非常快，比如格式比较统一等。&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Jun 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-06-13-flink7</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-06-13-flink7</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>初识flink6</title>
        <description>&lt;p&gt;基于社区版1.5的定制化开发工作已经接近尾声了，最后一个大的Feature是背压指标的量化。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;背压&lt;/h2&gt;

&lt;p&gt;流计算框架上都提供了背压相关的机制，但监控量化的形式各有不同。&lt;/p&gt;

&lt;p&gt;Flink-UI上提供了一个背压探测的功能，基本原理就是Profiling。&lt;/p&gt;

&lt;p&gt;在实际应用中，我们发现了很多问题，比如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;只能观测当前，无法回溯历史；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;一次只能观测一个taskchain，没有全局概念；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;量化概念模糊，不利于告警预警；&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;开销高，无法长期运行；&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;综上，我们决定开发自己的背压监控功能，并为用户提供预警告警的功能。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;量化&lt;/h2&gt;

&lt;p&gt;我们定义背压的指标和之前fregata做伸缩容的指标是一个含义，内部称之为自旋时间，&lt;/p&gt;

&lt;p&gt;简单来说就是数据处理线程等待eventbuffer的时间。&lt;/p&gt;

&lt;p&gt;在flink中，主要修改如下几个类：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
RecordWriter.requestNewBufferBuilder

LocalBufferPool.requestBufferBuilderBlocking

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在LocalBufferPool的requestBuffer时，会进入一段while循环&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
while (availableMemorySegments.isEmpty()) 

    ...
    availableMemorySegments.wait(2000);
    ...

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这块代码主要是我们修改的区域。&lt;/p&gt;

&lt;p&gt;总的来说，我们统计了wait的时间和进入while循环的次数，作为背压的指标。&lt;/p&gt;

&lt;p&gt;进入while循环次数多，我们认为stream是时断时续的，效率不高，类似堵车，&lt;/p&gt;

&lt;p&gt;这类问题大多需要调节networkbuffer大小，并行度等可以有效解决。&lt;/p&gt;

&lt;p&gt;wait的累加时间长（比如1min里有58s在wait），任务下游严重阻塞，&lt;/p&gt;

&lt;p&gt;这类问题最大的可能是下游IO超时阻塞。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;维度&lt;/h2&gt;

&lt;p&gt;我们的监控数据最后是进入Promethues的，有了指标和值，还需要一些维度信息。&lt;/p&gt;

&lt;p&gt;Flink的Metric主要是task级和Operator级，所以我们只要参照flink的&lt;/p&gt;

&lt;p&gt;metric定义方式，就获得了subtask的一系列标签(taskId,index,attemptId等)。&lt;/p&gt;

&lt;p&gt;在此基础上，我们又将数据的target也作为了一个维度，就是RecordWriter中的&lt;/p&gt;

&lt;p&gt;targetChannelId。如果一个task的下游有多个target，我们可以区分出到底是&lt;/p&gt;

&lt;p&gt;哪一个导致背压的。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;开销&lt;/h2&gt;

&lt;p&gt;我们增加的这些统计指标，在程序没法发生背压时是没有任何开销的，一旦发生背压，&lt;/p&gt;

&lt;p&gt;就意味着程序的吞吐极具下降，那么相关逻辑的执行次数也非常少，costtime的计算&lt;/p&gt;

&lt;p&gt;和累加计数器的操作开销也非常低，几乎可以忽略不计。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;效果&lt;/h2&gt;

&lt;p&gt;监控数据打通后，我们在Promethues上进行了一下统计，发现了20多个任务存在背压，&lt;/p&gt;

&lt;p&gt;我们也对比了Flink-WebUI上的探测结果，结论都是准确的，证明方案是可行有效的。&lt;/p&gt;
</description>
        <pubDate>Sat, 18 May 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-05-18-flink6</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-05-18-flink6</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>avro优化</title>
        <description>&lt;p&gt;最近在进行fregata2.0重构时，再次优化avro的反序列化过程。&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;背景&lt;/h3&gt;

&lt;p&gt;fregata-quasi任务是典型的cpu和内存都高度消耗的场景，主要是数据的&lt;/p&gt;

&lt;p&gt;序列化和反序列化。通过JFR多次观测，其中一个热点是avro中的字符串类型&lt;/p&gt;

&lt;p&gt;数据的处理（实际数据中字符串类型出现的比较多，201712的blog也提到过）。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;问题源码&lt;/h3&gt;

&lt;p&gt;对相关代码进行分析后，把目光落在这个区域。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if (length &amp;lt; 0)
    throw new AvroRuntimeException(&quot;Malformed data. Length is negative: &quot;+ length);
int remaining = limit - pos;
if (length &amp;lt;= remaining) {
    System.arraycopy(buf, pos, bytes, start, length);
    pos += length;
} else {
    // read the rest of the buffer
    System.arraycopy(buf, pos, bytes, start, remaining);
    start += remaining;
    length -= remaining;
    pos = limit;
    // finish from the byte source
    source.readRaw(bytes, start, length);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在字符串处理中，Avro引入了一个UTF8对象（本质就是一个byte数组），&lt;/p&gt;

&lt;p&gt;在经过这段代码后，再将UTF8对象转为String，经过string的decode。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;优化&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int start = 0;
int length = readInt();
if (length &amp;lt; 0) {
    throw new AvroRuntimeException(&quot;Malformed data length : &quot; + length);
}
int remaining = limit - pos;
if (length &amp;lt;= remaining) {
    result = new String(buf, pos, length);
    pos += length;
} else {
    //read the rest of the buffer
    result = new String(buf, pos, remaining);
    start += remaining;
    length -= remaining;
    pos = limit;
    //finish from the byte source
    source.readRaw(null, start, length);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里主要是省掉了中间的UTF8对象，减少了一次System.arraycopy&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;结论&lt;/h3&gt;

&lt;p&gt;经过测试，这个优化可以提升10%左右的反序列化速度。&lt;/p&gt;
</description>
        <pubDate>Fri, 26 Apr 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-04-26-avro2</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-04-26-avro2</guid>
        
        
        <category>avro</category>
        
      </item>
    
      <item>
        <title>总结</title>
        <description>&lt;p&gt;Q1马上就要结束了，最近一直在忙一些规划和总结性的东西。&lt;/p&gt;

&lt;p&gt;这次就随便聊聊，没有什么主题。&lt;/p&gt;

&lt;h2 id=&quot;flink&quot;&gt;Flink&lt;/h2&gt;

&lt;h3 id=&quot;section&quot;&gt;1.5升级到1.7&lt;/h3&gt;

&lt;p&gt;因为业务上的需求，最近在准备将我们的Flink版本从1.5升级到1.7，&lt;/p&gt;

&lt;p&gt;开发还算顺利，我们定制的各种特性也都迁移到1.7的版本上。&lt;/p&gt;

&lt;p&gt;不过Flink社区的开发进度，总体上感觉比去年要慢了许多。&lt;/p&gt;

&lt;h3 id=&quot;sql&quot;&gt;SQL化&lt;/h3&gt;

&lt;p&gt;看了不少公司在实时计算平台建设的文章，提到了很多实时任务SQL化的计划，&lt;/p&gt;

&lt;p&gt;从我的感受来说，并没有觉得SQL化的迫切，也许是业务特点不一样吧。&lt;/p&gt;

&lt;p&gt;目前平台上跑的几百个任务来看，用户的编写质量确实很差，&lt;/p&gt;

&lt;p&gt;开发一个性能优异的Flink任务，需要的知识储备其实挺高的，&lt;/p&gt;

&lt;p&gt;绝大多数业务方只能照葫芦画瓢，并没有时间去深入理解和研究。&lt;/p&gt;

&lt;p&gt;由平台方来编写一些标准化的工具，减少粗制滥造的重复开发是很有必要的。&lt;/p&gt;

&lt;p&gt;但工具化、配置化，不一定要是SQL化，当然公司有足够的投入另当别论。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;有状态&lt;/h3&gt;

&lt;p&gt;对有状态任务的支持，是Flink相比其他实时计算框架的巨大优势。&lt;/p&gt;

&lt;p&gt;目前，平台上的任务对State的诉求非常低，这并不是一个健康的状况。&lt;/p&gt;

&lt;p&gt;今年Q2开始，我们会加大力度在对State的支持方面，也做一些周边的开发，&lt;/p&gt;

&lt;p&gt;降低state的开发难度，提升性能和效率。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Mar 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-03-22-summary</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-03-22-summary</guid>
        
        
        <category>summary</category>
        
      </item>
    
      <item>
        <title>自动伸缩</title>
        <description>&lt;p&gt;这次讲一下Fregata重构中的一个重要内容-自动伸缩，主要是解决两个方向的问题：&lt;/p&gt;

&lt;p&gt;1、突发流量需要人工介入，不及时也太耗费人力&lt;/p&gt;

&lt;p&gt;2、周期性波动的数据处理，在波峰波谷时不同处理方式&lt;/p&gt;

&lt;p&gt;为了解决这些问题，我们在重构的Topology基础上，增加了伸缩容功能，可以增减&lt;/p&gt;

&lt;p&gt;Parser和Sink的个数。下面介绍一下伸缩功能的一个基础，那就是如何判断伸缩。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;状态&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;基本状态&lt;/h3&gt;

&lt;p&gt;在讨论这个功能时，我们一度非常困惑于如何对状态进行定义和划分还有转化。&lt;/p&gt;

&lt;p&gt;我们阅读了很多关于状态机的文章和demo，定了4个基础状态：&lt;/p&gt;

&lt;p&gt;1、固定状态（不可以缩、也不可以扩）&lt;/p&gt;

&lt;p&gt;2、最大（不可以扩，可缩）&lt;/p&gt;

&lt;p&gt;3、最小（不可以缩，可扩）&lt;/p&gt;

&lt;p&gt;4、中间状态（可扩，可缩）&lt;/p&gt;

&lt;p&gt;Topology中的Parser和Sink都有自己各自的状态，独立计算互不影响。&lt;/p&gt;

&lt;p&gt;按照其并行度的最小值、最大值、当前值来作为定义状态的基础参数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	this.statesRules.add(new FixedStatus(super.componentType, 1, 1, 1));
        this.statesRules.add(new MinStatus(super.componentType, 3, 1, 1));
        this.statesRules.add(new BriskStatus(super.componentType, 3, 1, 2));
        this.statesRules.add(new MaxStatus(super.componentType, 3, 1, 3));
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;匹配、转化&lt;/h3&gt;

&lt;p&gt;我们的状态匹配方式就是最简单的遍历&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        for (IStatus status : this.statesRules) {
            IStatus result = status.matchStatus(upperBound, lowerBound, cur);
            if (result != null) {
                return result;
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;趋势&lt;/h3&gt;

&lt;p&gt;每个周期的监控指标都会输入到当前状态中，指标的计算会得出一个当前的趋势（伸、缩、不动）。&lt;/p&gt;

&lt;p&gt;在当前状态中，保持一个时间序列的趋势集合，当连续N次趋势产生时，就会触发状态的改变，也会&lt;/p&gt;

&lt;p&gt;触发一个Action事件。每种状态因为其特点不同，对趋势的处理也会有所不同。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;伸缩分类&lt;/h2&gt;

&lt;p&gt;伸缩我们主要分为两类：&lt;/p&gt;

&lt;p&gt;1、Topology的伸缩，也就是增减并行度。&lt;/p&gt;

&lt;p&gt;2、K8s的Deployment的伸缩，也就是增减副本数。&lt;/p&gt;

&lt;h3 id=&quot;topology&quot;&gt;Topology内&lt;/h3&gt;

&lt;p&gt;我们是优先对Topology进行调整，这样的代价是最小的。&lt;/p&gt;

&lt;h3 id=&quot;docker&quot;&gt;Docker副本数&lt;/h3&gt;

&lt;p&gt;当Topology已经是最小时，就考虑适当的减少Docker副本，进一步释放资源。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;收益&lt;/h2&gt;

&lt;p&gt;无论是哪种伸缩，都可以帮助我们在流量增大时，自动提升处理能力去应对，在数据量小的时候，减少对&lt;/p&gt;

&lt;p&gt;外部的负担，减少Tcp连接数、HDFS小文件数、提高数据的密度等。&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Feb 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-02-25-scale</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-02-25-scale</guid>
        
        
        <category>scale</category>
        
        <category>auto</category>
        
        <category>fregata</category>
        
      </item>
    
      <item>
        <title>优化流式任务</title>
        <description>&lt;p&gt;去年花了大半年的时间在Fregata项目上，目前的部署规模在12000个docker的水平。今年上半年打算&lt;/p&gt;

&lt;p&gt;对Fregata项目进行一次框架上的升级，目标是提升性能，为上下游生态系统减负。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;拓扑&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;旧拓扑&lt;/h3&gt;

&lt;p&gt;之前的拓扑是树形拓扑，意味下游节点的并行度不能低于上游的，至少保持一致。&lt;/p&gt;

&lt;p&gt;1个Source，3个Parser，3个Sink，Parser和Sink一一对应，数据不会交叉。&lt;/p&gt;

&lt;p&gt;1个Source，3个Parser，6个Sink，每个Parser后面对应2个Sink。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;新拓扑&lt;/h3&gt;

&lt;p&gt;新拓扑中的Parser可以将数据分发给任何一个Sink。&lt;/p&gt;

&lt;p&gt;1个Source，2个Parser，5个Sink 每个Parser后面都对应5个Sink。&lt;/p&gt;

&lt;p&gt;通过控制数据的离散规则可以达到旧拓扑的效果，也就是说，旧拓扑是新拓扑的一种特例。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;好处&lt;/h3&gt;

&lt;p&gt;通过更加合理的配比，达到最小资源和最大性能，举例说明：&lt;/p&gt;

&lt;p&gt;老：1×Source +　5×Parser + 5×Sink = 11×Component&lt;/p&gt;

&lt;p&gt;新：1×Source +　3×Parser + 6×Sink = 10×Component&lt;/p&gt;

&lt;p&gt;在我们的测试中，新拓扑方案比老的快20%，因为整个Stream的瓶颈在Sink，Parser只需要3个就可以。&lt;/p&gt;

&lt;p&gt;在减少component的情况下，性能依然得到的提升，减少component，意味着线程数的减少，&lt;/p&gt;

&lt;p&gt;buffer区个数会减少，内存预分配的占用也会减少。&lt;/p&gt;

&lt;h2 id=&quot;buffer&quot;&gt;Buffer&lt;/h2&gt;

&lt;p&gt;在这次调优过程中，我们测试了buffer的大小，前后比例对性能的影响。&lt;/p&gt;

&lt;p&gt;buffer超过1024后，对性能的提升帮助不大，前提是sink端的性能相对稳定。&lt;/p&gt;

&lt;p&gt;source到parser间的buffer设置的更大一下，更有利于性能的稳定。&lt;/p&gt;

&lt;h2 id=&quot;kafkasink&quot;&gt;KafkaSink&lt;/h2&gt;

&lt;p&gt;老版里我们在Sink上抽象了一层BatchSink，这次重构我们将Batch的逻辑全部交给Kafka的&lt;/p&gt;

&lt;p&gt;Client去处理，利用它的linger和batchsize等操作。性能得到20%-30%的提升。&lt;/p&gt;

&lt;p&gt;我们对Kafka的Producer也进行了大量的测试，如果我们最大限度的让Producer积攒数据，&lt;/p&gt;

&lt;p&gt;会让数据的体积更小，网络和磁盘的开销都会有2-3倍的节约，在消费解压时也会更快。&lt;/p&gt;

&lt;h2 id=&quot;spintime&quot;&gt;SpinTime&lt;/h2&gt;

&lt;p&gt;在老版里，我们就使用SpinTime来进行系统性能的预警，在新版里我们主要使用Spintime来进行&lt;/p&gt;

&lt;p&gt;自动伸缩容的评判，目前还在测试中。&lt;/p&gt;
</description>
        <pubDate>Sun, 20 Jan 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-01-20-stream</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-01-20-stream</guid>
        
        
        <category>stream</category>
        
        <category>fregata</category>
        
      </item>
    
      <item>
        <title>初识flink5</title>
        <description>&lt;p&gt;先简单介绍一下我们Flink的一个优化，关于asyncfunction的优化&lt;/p&gt;

&lt;h2 id=&quot;asyncfunction&quot;&gt;AsyncFunction&lt;/h2&gt;

&lt;p&gt;阿里为flink社区提供了async的patch，为解决流计算中的IO性能提升带来了新思路，&lt;/p&gt;

&lt;p&gt;但我个人觉得这个问题并没有真正解决，Asyncfunction更像是一个饮鸩止渴的方案。&lt;/p&gt;

&lt;p&gt;随着异步线程的增加，很快会将外部服务打满，性能极具下降。&lt;/p&gt;

&lt;p&gt;我们的优化思路是这样的，在与外部系统交互时，尽量使用小批量，而不是单条数据处理。&lt;/p&gt;

&lt;p&gt;将async和batch结合起来，提升asyncfunction的效率。&lt;/p&gt;

&lt;p&gt;具体的实现：&lt;/p&gt;

&lt;p&gt;引入一个ringbuffer作为缓冲，asyncfunction在asyncinvoke时，将数据写入buffer中，&lt;/p&gt;

&lt;p&gt;配置N个消费线程，消费ringbuffer里的数据，进行batch的积攒，并配置ringbuffer的timeout，&lt;/p&gt;

&lt;p&gt;一次来实现N条最大M秒的批量数据积攒，在消费线程内，对积攒的批量数据进行处理，&lt;/p&gt;

&lt;p&gt;返回结果的拆分，最后调用ResultFuture，将数据交还给asyncfunction。&lt;/p&gt;

&lt;h2 id=&quot;batchasyncfunction&quot;&gt;通用BatchAsyncFunction的实现&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
  @Override
    public void asyncInvoke(IN input, ResultFuture&amp;lt;OUT&amp;gt; resultFuture) throws Exception {
        long seq = this.ringBuffer.next();
        Event event = this.ringBuffer.get(seq);
        event.data = input;
        event.resultFuture = resultFuture;
        this.ringBuffer.publish(seq);
    }


&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section&quot;&gt;通用批量消费线程的抽象&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
public abstract class Processor&amp;lt;D, T, P&amp;gt; implements WorkHandler&amp;lt;Event&amp;lt;D, T&amp;gt;&amp;gt;, TimeoutHandler, LifecycleAware {

    protected AsyncConfig asyncConfig;

    private boolean initedBatch;

    private List&amp;lt;Triple&amp;lt;D, ResultFuture&amp;lt;T&amp;gt;, P&amp;gt;&amp;gt; batch;

    private long lastBatchTime;

    public Processor(AsyncConfig asyncConfig) {
        this.asyncConfig = asyncConfig;
        this.batch = Lists.newArrayList();
    }

    @Override
    public void onStart() {
        cleanAfterBatch();
    }

    @Override
    public void onEvent(Event&amp;lt;D, T&amp;gt; event) throws Exception {
        if (!this.initedBatch) {
            initBatch(false);
            this.initedBatch = true;
        }

        P param = buildBatchParams(event.data);
        this.batch.add(Triple.of(event.data, event.resultFuture, param));

        if ((this.batch.size() &amp;gt;= this.asyncConfig.getRingbufferMaxBatchSize()) || (System.currentTimeMillis() - this
                .lastBatchTime &amp;gt;= this.asyncConfig.getRingbufferLingerMs())) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    @Override
    public void onTimeout(long l) throws Exception {
        if (this.initedBatch) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    @Override
    public void onShutdown() {
        if (this.initedBatch) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    protected abstract void initBatch(boolean retry);

    protected abstract P buildBatchParams(D data);

    protected void cleanAfterBatch() {
        this.initedBatch = false;
        this.batch.clear();
        this.lastBatchTime = System.currentTimeMillis();
    }

    protected void execBatch(int times) {
        Validate.isTrue(this.asyncConfig.getAsyncMaxRetry() &amp;gt; times, &quot;execbatch retry-times : &quot; + times);
        try {
            if (times &amp;gt; 0) {
                initBatch(true);
            }
            commitAndGetResultsAndCloseBatch();
            this.batch.forEach(triple -&amp;gt; pushData(triple.getLeft(), triple.getMiddle(), triple.getRight()));
        } catch (Exception e) {
            try {
                Thread.sleep(this.asyncConfig.getAsyncRetryIntervalMs());
            } catch (InterruptedException e1) {
                throw new RuntimeException(&quot;Failed to exec batch&quot;, e1);
            }
            execBatch(times + 1);
        }
    }

    protected abstract void commitAndGetResultsAndCloseBatch() throws Exception;

    protected abstract void pushData(D data, ResultFuture&amp;lt;T&amp;gt; resultFuture, P param);

}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Dec 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-12-05-flink5</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-12-05-flink5</guid>
        
        
        <category>clone</category>
        
        <category>invoke</category>
        
        <category>beancopy</category>
        
      </item>
    
      <item>
        <title>初识flink4</title>
        <description>&lt;p&gt;我们最近merge了flink1.5.5的官方更新，并对batchsink进行深入开发。&lt;/p&gt;

&lt;h2 id=&quot;monkey&quot;&gt;Monkey&lt;/h2&gt;

&lt;p&gt;上次介绍我们的batchsink具备常规的功能，能够支持按照lingertime、数据大小、数据条数&lt;/p&gt;

&lt;p&gt;进行batch的拆分。这个月我们在其中嵌入了一个叫monkey的字段，动态调节batch大小。&lt;/p&gt;

&lt;p&gt;具体使用方法如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  public boolean checkFull() {
        return WP.get() - RP.get() == this.size - this.monkey;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;通过引入一个变量，实现了ringbuffer大小的动态调节。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;动态调节的时机&lt;/h2&gt;

&lt;p&gt;我们将ringbuffer的每一圈的开始作为汇报监控指标和调节monkey值的时机。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int sq = mod(cur);
if (this.adjustment != null &amp;amp;&amp;amp; sq == 0) {
  this.monkey = this.adjustment.onFirstEvent(ele, RING[mod(cur + 1)], (cur / this.size), this.monkey,
  this.size);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;汇报时将当前写入数据的slot和即将被写入数据的slot当成参数传递个adjustment，&lt;/p&gt;

&lt;p&gt;还提供了圈数、oldmonkey值和圈大小等信息，返回值是新的monkey值。&lt;/p&gt;

&lt;h2 id=&quot;adjustment&quot;&gt;Adjustment&lt;/h2&gt;

&lt;p&gt;那么monkey的动态可以做什么呢？我们想实现对batchsize的自动化测试。&lt;/p&gt;

&lt;p&gt;每当我们给一个开源的软件填写batchsize参数配置时，大多是拍脑袋出来的，&lt;/p&gt;

&lt;p&gt;也可能做了一些简单的性能测试，这个过程比较枯燥，就是反复修改值，反复运行。&lt;/p&gt;

&lt;p&gt;通过monkey的动态，我们可以将每一个batch大小进行几十次测试，然后按照&lt;/p&gt;

&lt;p&gt;一个步长变更batch大小，继续进行测试，将原来手工的方式变成自动化的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    public long onFirstEvent(Element&amp;lt;T&amp;gt; first, Element&amp;lt;T&amp;gt; second, long cycles, long oldMonkey, long maxSize) {
        if (cycles &amp;gt; 0) {
            log.warn(&quot;Cycle {} , Monkey {} , Cost {} ms , Volume {} , Record {} .&quot;, cycles, oldMonkey, first.getTimestampW() -
                    second.getTimestampW(), first.getAccVolume() - second.getAccVolume(), maxSize);

            this.metrics.add(new double[]{oldMonkey, (first.getTimestampW() - second.getTimestampW()), ((double) maxSize *
                    1000) / (first.getTimestampW() - second.getTimestampW())});

            if (cycles % this.intervalCycle == 0) {
                formulaFitting();

                if (maxSize - oldMonkey &amp;lt;= this.monkeyStepSize) {
                    this.result.forEach(doubles -&amp;gt; log.warn(&quot;evaluate : &quot; + Arrays.toString(doubles)));
                    this.result.clear();
                    return this.roundTrip ? 0 : oldMonkey;
                } else {
                    return oldMonkey + this.monkeyStepSize;
                }
            }
        }
        return oldMonkey;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;简单的几行代码，我们就基本实现了这个需求。每运行N圈后，将monkey增加一个monkeystepsize。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;评价&lt;/h2&gt;

&lt;p&gt;经过一系列的测试后，我们如何评估最佳的batchsize呢？&lt;/p&gt;

&lt;p&gt;在运行时，我们已经将一些指标记录到了metrics里，包括monkey大小，跑一圈的cost，还有每秒吞吐条数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   double totalRate = 0;
        for (int i = 0; i &amp;lt; this.metrics.size(); i++) {
            totalRate += this.metrics.get(i)[2];
        }
        double avgRate = totalRate / this.metrics.size();
        double acc = 0;
        for (int i = 0; i &amp;lt; this.metrics.size(); i++) {
            acc += Math.pow(this.metrics.get(i)[2] - avgRate, 2);
        }
        this.result.add(new double[]{this.metrics.get(0)[0], totalRate / this.metrics.size(), acc / (this.metrics.size() - 1)});
        this.metrics.clear();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后我们对metrics进行一些简单的数据分析，计算均值还有方差，来评价最优解。&lt;/p&gt;

&lt;p&gt;在我们的测试中，平均速度差距不大，但是方差有明显的变化趋势，随着batch大小的增长，&lt;/p&gt;

&lt;p&gt;方差越来越大，通过观察jvm的内存变化推测为，由于batchcache的数据量增大，数据更&lt;/p&gt;

&lt;p&gt;容易进入到old区，导致fgc的频率提高，ygc的时间变长，导致速度的波动较大。&lt;/p&gt;
</description>
        <pubDate>Thu, 22 Nov 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-11-22-flink4</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-11-22-flink4</guid>
        
        
        <category>flink</category>
        
      </item>
    
  </channel>
</rss>
