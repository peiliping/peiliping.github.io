<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 07 Mar 2019 11:15:52 +0800</pubDate>
    <lastBuildDate>Thu, 07 Mar 2019 11:15:52 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>自动伸缩</title>
        <description>&lt;p&gt;这次讲一下Fregata重构中的一个重要内容-自动伸缩，主要是解决两个方向的问题：&lt;/p&gt;

&lt;p&gt;1、突发流量需要人工介入，不及时也太耗费人力&lt;/p&gt;

&lt;p&gt;2、周期性波动的数据处理，在波峰波谷时不同处理方式&lt;/p&gt;

&lt;p&gt;为了解决这些问题，我们在重构的Topology基础上，增加了伸缩容功能，可以增减&lt;/p&gt;

&lt;p&gt;Parser和Sink的个数。下面介绍一下伸缩功能的一个基础，那就是如何判断伸缩。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;状态&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;基本状态&lt;/h3&gt;

&lt;p&gt;在讨论这个功能时，我们一度非常困惑于如何对状态进行定义和划分还有转化。&lt;/p&gt;

&lt;p&gt;我们阅读了很多关于状态机的文章和demo，定了4个基础状态：&lt;/p&gt;

&lt;p&gt;1、固定状态（不可以缩、也不可以扩）&lt;/p&gt;

&lt;p&gt;2、最大（不可以扩，可缩）&lt;/p&gt;

&lt;p&gt;3、最小（不可以缩，可扩）&lt;/p&gt;

&lt;p&gt;4、中间状态（可扩，可缩）&lt;/p&gt;

&lt;p&gt;Topology中的Parser和Sink都有自己各自的状态，独立计算互不影响。&lt;/p&gt;

&lt;p&gt;按照其并行度的最小值、最大值、当前值来作为定义状态的基础参数&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	this.statesRules.add(new FixedStatus(super.componentType, 1, 1, 1));
        this.statesRules.add(new MinStatus(super.componentType, 3, 1, 1));
        this.statesRules.add(new BriskStatus(super.componentType, 3, 1, 2));
        this.statesRules.add(new MaxStatus(super.componentType, 3, 1, 3));
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-2&quot;&gt;匹配、转化&lt;/h3&gt;

&lt;p&gt;我们的状态匹配方式就是最简单的遍历&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        for (IStatus status : this.statesRules) {
            IStatus result = status.matchStatus(upperBound, lowerBound, cur);
            if (result != null) {
                return result;
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;趋势&lt;/h3&gt;

&lt;p&gt;每个周期的监控指标都会输入到当前状态中，指标的计算会得出一个当前的趋势（伸、缩、不动）。&lt;/p&gt;

&lt;p&gt;在当前状态中，保持一个时间序列的趋势集合，当连续N次趋势产生时，就会触发状态的改变，也会&lt;/p&gt;

&lt;p&gt;触发一个Action事件。每种状态因为其特点不同，对趋势的处理也会有所不同。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;伸缩分类&lt;/h2&gt;

&lt;p&gt;伸缩我们主要分为两类：&lt;/p&gt;

&lt;p&gt;1、Topology的伸缩，也就是增减并行度。&lt;/p&gt;

&lt;p&gt;2、K8s的Deployment的伸缩，也就是增减副本数。&lt;/p&gt;

&lt;h3 id=&quot;topology&quot;&gt;Topology内&lt;/h3&gt;

&lt;p&gt;我们是优先对Topology进行调整，这样的代价是最小的。&lt;/p&gt;

&lt;h3 id=&quot;docker&quot;&gt;Docker副本数&lt;/h3&gt;

&lt;p&gt;当Topology已经是最小时，就考虑适当的减少Docker副本，进一步释放资源。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;收益&lt;/h2&gt;

&lt;p&gt;无论是哪种伸缩，都可以帮助我们在流量增大时，自动提升处理能力去应对，在数据量小的时候，减少对&lt;/p&gt;

&lt;p&gt;外部的负担，减少Tcp连接数、HDFS小文件数、提高数据的密度等。&lt;/p&gt;
</description>
        <pubDate>Mon, 25 Feb 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-02-25-scale</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-02-25-scale</guid>
        
        
        <category>scale</category>
        
        <category>auto</category>
        
        <category>fregata</category>
        
      </item>
    
      <item>
        <title>优化流式任务</title>
        <description>&lt;p&gt;去年花了大半年的时间在Fregata项目上，目前的部署规模在12000个docker的水平。今年上半年打算&lt;/p&gt;

&lt;p&gt;对Fregata项目进行一次框架上的升级，目标是提升性能，为上下游生态系统减负。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;拓扑&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;旧拓扑&lt;/h3&gt;

&lt;p&gt;之前的拓扑是树形拓扑，意味下游节点的并行度不能低于上游的，至少保持一致。&lt;/p&gt;

&lt;p&gt;1个Source，3个Parser，3个Sink，Parser和Sink一一对应，数据不会交叉。&lt;/p&gt;

&lt;p&gt;1个Source，3个Parser，6个Sink，每个Parser后面对应2个Sink。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;新拓扑&lt;/h3&gt;

&lt;p&gt;新拓扑中的Parser可以将数据分发给任何一个Sink。&lt;/p&gt;

&lt;p&gt;1个Source，2个Parser，5个Sink 每个Parser后面都对应5个Sink。&lt;/p&gt;

&lt;p&gt;通过控制数据的离散规则可以达到旧拓扑的效果，也就是说，旧拓扑是新拓扑的一种特例。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;好处&lt;/h3&gt;

&lt;p&gt;通过更加合理的配比，达到最小资源和最大性能，举例说明：&lt;/p&gt;

&lt;p&gt;老：1×Source +　5×Parser + 5×Sink = 11×Component&lt;/p&gt;

&lt;p&gt;新：1×Source +　3×Parser + 6×Sink = 10×Component&lt;/p&gt;

&lt;p&gt;在我们的测试中，新拓扑方案比老的快20%，因为整个Stream的瓶颈在Sink，Parser只需要3个就可以。&lt;/p&gt;

&lt;p&gt;在减少component的情况下，性能依然得到的提升，减少component，意味着线程数的减少，&lt;/p&gt;

&lt;p&gt;buffer区个数会减少，内存预分配的占用也会减少。&lt;/p&gt;

&lt;h2 id=&quot;buffer&quot;&gt;Buffer&lt;/h2&gt;

&lt;p&gt;在这次调优过程中，我们测试了buffer的大小，前后比例对性能的影响。&lt;/p&gt;

&lt;p&gt;buffer超过1024后，对性能的提升帮助不大，前提是sink端的性能相对稳定。&lt;/p&gt;

&lt;p&gt;source到parser间的buffer设置的更大一下，更有利于性能的稳定。&lt;/p&gt;

&lt;h2 id=&quot;kafkasink&quot;&gt;KafkaSink&lt;/h2&gt;

&lt;p&gt;老版里我们在Sink上抽象了一层BatchSink，这次重构我们将Batch的逻辑全部交给Kafka的&lt;/p&gt;

&lt;p&gt;Client去处理，利用它的linger和batchsize等操作。性能得到20%-30%的提升。&lt;/p&gt;

&lt;p&gt;我们对Kafka的Producer也进行了大量的测试，如果我们最大限度的让Producer积攒数据，&lt;/p&gt;

&lt;p&gt;会让数据的体积更小，网络和磁盘的开销都会有2-3倍的节约，在消费解压时也会更快。&lt;/p&gt;

&lt;h2 id=&quot;spintime&quot;&gt;SpinTime&lt;/h2&gt;

&lt;p&gt;在老版里，我们就使用SpinTime来进行系统性能的预警，在新版里我们主要使用Spintime来进行&lt;/p&gt;

&lt;p&gt;自动伸缩容的评判，目前还在测试中。&lt;/p&gt;
</description>
        <pubDate>Sun, 20 Jan 2019 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2019-01-20-stream</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2019-01-20-stream</guid>
        
        
        <category>stream</category>
        
        <category>fregata</category>
        
      </item>
    
      <item>
        <title>初识flink5</title>
        <description>&lt;p&gt;先简单介绍一下我们Flink的一个优化，关于asyncfunction的优化&lt;/p&gt;

&lt;h2 id=&quot;asyncfunction&quot;&gt;AsyncFunction&lt;/h2&gt;

&lt;p&gt;阿里为flink社区提供了async的patch，为解决流计算中的IO性能提升带来了新思路，&lt;/p&gt;

&lt;p&gt;但我个人觉得这个问题并没有真正解决，Asyncfunction更像是一个饮鸩止渴的方案。&lt;/p&gt;

&lt;p&gt;随着异步线程的增加，很快会将外部服务打满，性能极具下降。&lt;/p&gt;

&lt;p&gt;我们的优化思路是这样的，在与外部系统交互时，尽量使用小批量，而不是单条数据处理。&lt;/p&gt;

&lt;p&gt;将async和batch结合起来，提升asyncfunction的效率。&lt;/p&gt;

&lt;p&gt;具体的实现：&lt;/p&gt;

&lt;p&gt;引入一个ringbuffer作为缓冲，asyncfunction在asyncinvoke时，将数据写入buffer中，&lt;/p&gt;

&lt;p&gt;配置N个消费线程，消费ringbuffer里的数据，进行batch的积攒，并配置ringbuffer的timeout，&lt;/p&gt;

&lt;p&gt;一次来实现N条最大M秒的批量数据积攒，在消费线程内，对积攒的批量数据进行处理，&lt;/p&gt;

&lt;p&gt;返回结果的拆分，最后调用ResultFuture，将数据交还给asyncfunction。&lt;/p&gt;

&lt;h2 id=&quot;batchasyncfunction&quot;&gt;通用BatchAsyncFunction的实现&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
  @Override
    public void asyncInvoke(IN input, ResultFuture&amp;lt;OUT&amp;gt; resultFuture) throws Exception {
        long seq = this.ringBuffer.next();
        Event event = this.ringBuffer.get(seq);
        event.data = input;
        event.resultFuture = resultFuture;
        this.ringBuffer.publish(seq);
    }


&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;section&quot;&gt;通用批量消费线程的抽象&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
public abstract class Processor&amp;lt;D, T, P&amp;gt; implements WorkHandler&amp;lt;Event&amp;lt;D, T&amp;gt;&amp;gt;, TimeoutHandler, LifecycleAware {

    protected AsyncConfig asyncConfig;

    private boolean initedBatch;

    private List&amp;lt;Triple&amp;lt;D, ResultFuture&amp;lt;T&amp;gt;, P&amp;gt;&amp;gt; batch;

    private long lastBatchTime;

    public Processor(AsyncConfig asyncConfig) {
        this.asyncConfig = asyncConfig;
        this.batch = Lists.newArrayList();
    }

    @Override
    public void onStart() {
        cleanAfterBatch();
    }

    @Override
    public void onEvent(Event&amp;lt;D, T&amp;gt; event) throws Exception {
        if (!this.initedBatch) {
            initBatch(false);
            this.initedBatch = true;
        }

        P param = buildBatchParams(event.data);
        this.batch.add(Triple.of(event.data, event.resultFuture, param));

        if ((this.batch.size() &amp;gt;= this.asyncConfig.getRingbufferMaxBatchSize()) || (System.currentTimeMillis() - this
                .lastBatchTime &amp;gt;= this.asyncConfig.getRingbufferLingerMs())) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    @Override
    public void onTimeout(long l) throws Exception {
        if (this.initedBatch) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    @Override
    public void onShutdown() {
        if (this.initedBatch) {
            execBatch(0);
            cleanAfterBatch();
        }
    }

    protected abstract void initBatch(boolean retry);

    protected abstract P buildBatchParams(D data);

    protected void cleanAfterBatch() {
        this.initedBatch = false;
        this.batch.clear();
        this.lastBatchTime = System.currentTimeMillis();
    }

    protected void execBatch(int times) {
        Validate.isTrue(this.asyncConfig.getAsyncMaxRetry() &amp;gt; times, &quot;execbatch retry-times : &quot; + times);
        try {
            if (times &amp;gt; 0) {
                initBatch(true);
            }
            commitAndGetResultsAndCloseBatch();
            this.batch.forEach(triple -&amp;gt; pushData(triple.getLeft(), triple.getMiddle(), triple.getRight()));
        } catch (Exception e) {
            try {
                Thread.sleep(this.asyncConfig.getAsyncRetryIntervalMs());
            } catch (InterruptedException e1) {
                throw new RuntimeException(&quot;Failed to exec batch&quot;, e1);
            }
            execBatch(times + 1);
        }
    }

    protected abstract void commitAndGetResultsAndCloseBatch() throws Exception;

    protected abstract void pushData(D data, ResultFuture&amp;lt;T&amp;gt; resultFuture, P param);

}

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 05 Dec 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-12-05-flink5</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-12-05-flink5</guid>
        
        
        <category>clone</category>
        
        <category>invoke</category>
        
        <category>beancopy</category>
        
      </item>
    
      <item>
        <title>初识flink4</title>
        <description>&lt;p&gt;我们最近merge了flink1.5.5的官方更新，并对batchsink进行深入开发。&lt;/p&gt;

&lt;h2 id=&quot;monkey&quot;&gt;Monkey&lt;/h2&gt;

&lt;p&gt;上次介绍我们的batchsink具备常规的功能，能够支持按照lingertime、数据大小、数据条数&lt;/p&gt;

&lt;p&gt;进行batch的拆分。这个月我们在其中嵌入了一个叫monkey的字段，动态调节batch大小。&lt;/p&gt;

&lt;p&gt;具体使用方法如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  public boolean checkFull() {
        return WP.get() - RP.get() == this.size - this.monkey;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;通过引入一个变量，实现了ringbuffer大小的动态调节。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;动态调节的时机&lt;/h2&gt;

&lt;p&gt;我们将ringbuffer的每一圈的开始作为汇报监控指标和调节monkey值的时机。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;int sq = mod(cur);
if (this.adjustment != null &amp;amp;&amp;amp; sq == 0) {
  this.monkey = this.adjustment.onFirstEvent(ele, RING[mod(cur + 1)], (cur / this.size), this.monkey,
  this.size);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;汇报时将当前写入数据的slot和即将被写入数据的slot当成参数传递个adjustment，&lt;/p&gt;

&lt;p&gt;还提供了圈数、oldmonkey值和圈大小等信息，返回值是新的monkey值。&lt;/p&gt;

&lt;h2 id=&quot;adjustment&quot;&gt;Adjustment&lt;/h2&gt;

&lt;p&gt;那么monkey的动态可以做什么呢？我们想实现对batchsize的自动化测试。&lt;/p&gt;

&lt;p&gt;每当我们给一个开源的软件填写batchsize参数配置时，大多是拍脑袋出来的，&lt;/p&gt;

&lt;p&gt;也可能做了一些简单的性能测试，这个过程比较枯燥，就是反复修改值，反复运行。&lt;/p&gt;

&lt;p&gt;通过monkey的动态，我们可以将每一个batch大小进行几十次测试，然后按照&lt;/p&gt;

&lt;p&gt;一个步长变更batch大小，继续进行测试，将原来手工的方式变成自动化的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    public long onFirstEvent(Element&amp;lt;T&amp;gt; first, Element&amp;lt;T&amp;gt; second, long cycles, long oldMonkey, long maxSize) {
        if (cycles &amp;gt; 0) {
            log.warn(&quot;Cycle {} , Monkey {} , Cost {} ms , Volume {} , Record {} .&quot;, cycles, oldMonkey, first.getTimestampW() -
                    second.getTimestampW(), first.getAccVolume() - second.getAccVolume(), maxSize);

            this.metrics.add(new double[]{oldMonkey, (first.getTimestampW() - second.getTimestampW()), ((double) maxSize *
                    1000) / (first.getTimestampW() - second.getTimestampW())});

            if (cycles % this.intervalCycle == 0) {
                formulaFitting();

                if (maxSize - oldMonkey &amp;lt;= this.monkeyStepSize) {
                    this.result.forEach(doubles -&amp;gt; log.warn(&quot;evaluate : &quot; + Arrays.toString(doubles)));
                    this.result.clear();
                    return this.roundTrip ? 0 : oldMonkey;
                } else {
                    return oldMonkey + this.monkeyStepSize;
                }
            }
        }
        return oldMonkey;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;简单的几行代码，我们就基本实现了这个需求。每运行N圈后，将monkey增加一个monkeystepsize。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;评价&lt;/h2&gt;

&lt;p&gt;经过一系列的测试后，我们如何评估最佳的batchsize呢？&lt;/p&gt;

&lt;p&gt;在运行时，我们已经将一些指标记录到了metrics里，包括monkey大小，跑一圈的cost，还有每秒吞吐条数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   double totalRate = 0;
        for (int i = 0; i &amp;lt; this.metrics.size(); i++) {
            totalRate += this.metrics.get(i)[2];
        }
        double avgRate = totalRate / this.metrics.size();
        double acc = 0;
        for (int i = 0; i &amp;lt; this.metrics.size(); i++) {
            acc += Math.pow(this.metrics.get(i)[2] - avgRate, 2);
        }
        this.result.add(new double[]{this.metrics.get(0)[0], totalRate / this.metrics.size(), acc / (this.metrics.size() - 1)});
        this.metrics.clear();
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后我们对metrics进行一些简单的数据分析，计算均值还有方差，来评价最优解。&lt;/p&gt;

&lt;p&gt;在我们的测试中，平均速度差距不大，但是方差有明显的变化趋势，随着batch大小的增长，&lt;/p&gt;

&lt;p&gt;方差越来越大，通过观察jvm的内存变化推测为，由于batchcache的数据量增大，数据更&lt;/p&gt;

&lt;p&gt;容易进入到old区，导致fgc的频率提高，ygc的时间变长，导致速度的波动较大。&lt;/p&gt;
</description>
        <pubDate>Thu, 22 Nov 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-11-22-flink4</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-11-22-flink4</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>初识flink3</title>
        <description>&lt;p&gt;Flink的更新非常快，1.5的小版本一直都有更新，十一国庆前，我们将自己的定制版分支merge了&lt;/p&gt;

&lt;p&gt;官方的1.5.4，修复了taskmanager堆内外的内存比例，flink-stream使用堆外的量并不是很大，&lt;/p&gt;

&lt;p&gt;我们配置了7:3。&lt;/p&gt;

&lt;h2 id=&quot;asyncio&quot;&gt;AsyncIO&lt;/h2&gt;

&lt;p&gt;阿里给Flink社区提交了很多patch，印象比较深的是AsyncIO，在流式计算中IO导致性能瓶颈，&lt;/p&gt;

&lt;p&gt;是最常见的一个现象，异步化的改造能提升不少性能。Async的Operator实现并不是很复杂，&lt;/p&gt;

&lt;p&gt;简单来说就是创建一个buffer，将Stream数据填充进来并行处理，返回结果时控制一下数据的&lt;/p&gt;

&lt;p&gt;顺序，跟我们最常见的单机多线程的数据处理本质上是一样的。&lt;/p&gt;

&lt;p&gt;但是异步化会带来一个非常严重的后果，那就是IO的接收方会承受巨大的压力，通过调节buffer&lt;/p&gt;

&lt;p&gt;的大小和并行度，我们轻松的获得了几千几万的并行能力，但是这个IO服务（无论是RPC还是DB）&lt;/p&gt;

&lt;p&gt;接收了如性能压测般的流量，最终的结果就是IO服务拥塞，无法提供正常服务了。&lt;/p&gt;

&lt;p&gt;AsyncIO的思路是没有问题的，但是各种Java世界中的各种Client的API风格并非为了Stream而生，&lt;/p&gt;

&lt;p&gt;理想的API风格是kafka Producer的样子，流转批 + 异步回调。&lt;/p&gt;

&lt;h2 id=&quot;stream-batch&quot;&gt;Stream-&amp;gt;Batch&lt;/h2&gt;

&lt;p&gt;为了能让AsyncIO发挥作用，我们需要收敛IO的次数，将多次IO合并为一次Batch，基于Batch再做&lt;/p&gt;

&lt;p&gt;AsyncIO的操作，这样可以在减小并行度的情况下，能保证较高的吞吐量，减少协议部分的开销，&lt;/p&gt;

&lt;p&gt;如果你用过redis的pipeline，差不多一样的道理。&lt;/p&gt;

&lt;p&gt;当然Stream-&amp;gt;Batch并不是那么简单的事情，需要考虑的细节非常多，比如对checkpoint的处理，&lt;/p&gt;

&lt;p&gt;watermarket如何触发等，防止破坏了FLink本身的一致性。&lt;/p&gt;

&lt;p&gt;我们的思路是将AsyncIO和Stream转Batch结合在一起实现，提供一层类似KafkaProducer风格的&lt;/p&gt;

&lt;p&gt;API，将Stream-&amp;gt;Batch转为标准的定义，最后结合AsyncIO的特征来实现，AsyncIO对watermarket&lt;/p&gt;

&lt;p&gt;和checkpoint是有特殊处理的，这部分逻辑要尽量保持复用。&lt;/p&gt;

&lt;h2 id=&quot;batch-sink&quot;&gt;Batch Sink&lt;/h2&gt;

&lt;p&gt;所有任务Sink都是需要Batch特性的，如果是kafkaSink那真的非常简单，天然支持。我读了一下&lt;/p&gt;

&lt;p&gt;业务方的代码，他们在Sink这个环节的实现都非常简陋，大多数都无法保证不丢数据，比如基于&lt;/p&gt;

&lt;p&gt;一个简单的flatmap来实现。&lt;/p&gt;

&lt;p&gt;于是我们开发了BatchSink抽象，提供时间、大小、条数的控制条件，还有checkpoint触发flush。&lt;/p&gt;

&lt;p&gt;值得一提的是flush中的retry实现，批量操作失败如何重试呢？&lt;/p&gt;

&lt;p&gt;这是一个非常好的问题，一年多前我在开发meepo时就有这样的困惑，当时主要是读写mysql，&lt;/p&gt;

&lt;p&gt;我将mysql client的源码读了大半，实现了非常低开销的基于preparestatement的retry。&lt;/p&gt;

&lt;p&gt;但这种方式并不一定适用于所有的client，于是我们在batchsink中嵌入了一个小的ringbuffer，&lt;/p&gt;

&lt;p&gt;用来缓存这个批次的数据，在flush成功后清空ringbuffer。retry时复用handlerElement方法，&lt;/p&gt;

&lt;p&gt;将这一批次的数据进行replay，当然也支持noreplay的retry方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; protected void sendBatch(int times, boolean bySnapshot) {
        Validate.isTrue(this.batchConfig.getMaxRetriesNum() &amp;gt; times, &quot;sendbatch retry-times : &quot; + times);
        try {
            if (times &amp;gt; 0) {
                initBatch(true);
                if (this.batchConfig.isNeedReplayWhenRetry()) {
                    int l = this.buffer.curSize();
                    for (int i = 0; i &amp;lt; l; i++) {
                        Optional&amp;lt;IN&amp;gt; record = this.buffer.get();
                        Validate.notNull(record);
                        IN e = Optional.empty() == record ? null : record.get();
                        handleRecord(e);
                        this.buffer.add(e);
                    }
                }
            }
            flushAndClose(bySnapshot);
        } catch (Exception e) {
            LOG.error(&quot;FlushAndCloseError : &quot;, e);
            try {
                Thread.sleep(this.batchConfig.getBatchDelayPeriodMs());
            } catch (InterruptedException e1) {
                throw new RuntimeException(&quot;Failed to send batchRecords&quot;, e1);
            }
            sendBatch(times + 1, bySnapshot);
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 15 Oct 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-10-15-flink3</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-10-15-flink3</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>初识flink2</title>
        <description>&lt;p&gt;续上一篇Blog，我们从网上下载二进制的Flink包，在其外围进行一些脚本改造，&lt;/p&gt;

&lt;p&gt;docker镜像的开发，可以让我们把Flink在K8s上跑起来了，接下来就是要接触Flink的源码了。&lt;/p&gt;

&lt;p&gt;说道源码还是挺头大的一个事，目前apache下面的跟大数据相关的项目你下载下来就会发现&lt;/p&gt;

&lt;p&gt;子项目子模块非常多，maven编译一下少说十几分钟，hadoop这种级别的项目编译1个小时都正常。&lt;/p&gt;

&lt;h2 id=&quot;flink&quot;&gt;Flink分支&lt;/h2&gt;

&lt;p&gt;将Flink从Git上clone下来，选择一个你中意的分支或者tag，注意Flink的分支和tag的命名规则。&lt;/p&gt;

&lt;p&gt;因为我们后面要持续对Flink进行开发，而且要不断合并社区的更新，这里需要一些git的技巧。&lt;/p&gt;

&lt;p&gt;我们主要是在1.5.X这个系列上进行开发，所以将Flink项目的1.5分支同步到我们自己的仓库里，&lt;/p&gt;

&lt;p&gt;如果后面Flink发布了1.5.4的小版本，也会合并到1.5的分支上，我们只需要同步这些更新到我们&lt;/p&gt;

&lt;p&gt;的仓库即可。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;打包&lt;/h2&gt;

&lt;p&gt;Flink官网给了一个打包的命令，在我和同事的笔记本上执行了一下，大概20分钟左右。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn package -DskipTests -Dhadoop.version=2.7.X

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;因为初步接触Flink，我们打包非常频繁，调试一些问题增加日志之类的需求，所以这个打包&lt;/p&gt;

&lt;p&gt;的速度是无法接受的，大概分析了一下他的打包过程，于是修改了一下打包的命令。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mvn package -DskipTests -Dcheckstyle.skip=true -Dhadoop.version=2.7.X
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;增加了忽略checkstyple过程，速度提升了一倍，十分钟左右可以打包完成。&lt;/p&gt;

&lt;p&gt;如果你还想继续加速打包，可以考虑对pom进行裁剪，比如你不用mesos、yarn这些模块，&lt;/p&gt;

&lt;p&gt;或者你不需要各种connect，也是可以忽略的。但是注意maven的依赖，忽略的子项目有可能&lt;/p&gt;

&lt;p&gt;包含了Flink必须的一些依赖包，而且Flink的pom中大量的使用了shade，处理起来非常麻烦。&lt;/p&gt;

&lt;p&gt;注意，如果你在主POM里裁剪掉了部分的module，一定要记得在dist子项目中也去掉相关的&lt;/p&gt;

&lt;p&gt;dependency，要不然它会从maven仓库再下载一份。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;类冲突&lt;/h2&gt;

&lt;p&gt;测试自定义版Flink的时候，我们与类冲突搏斗了三四天，主要的报错是noclassdeffounderror。&lt;/p&gt;

&lt;p&gt;网上搜索相关错误，会告诉你与此类的static部分有关系，我们碰到的问题大多是hadoop有关的，&lt;/p&gt;

&lt;p&gt;每次处理hadoop的依赖都是一万个XXX。因为公司的现状，我们需要使用定制化的hadoop。&lt;/p&gt;

&lt;p&gt;最终我们在原版打包的基础上，通过控制classpath里jar的顺序，将公司的hdfs替换上去了。&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Sep 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-09-13-flink2</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-09-13-flink2</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>初识flink</title>
        <description>&lt;p&gt;2016年的时候，开始关注flink，觉得是一个非常不错的流计算项目，当时也做了一些简单的demo，&lt;/p&gt;

&lt;p&gt;了解其简单的应用，之后的两年里flink社区发展迅猛，包括阿里的强力支撑blink，在稳定性和性能&lt;/p&gt;

&lt;p&gt;方面都有很大的提升，8月份我们开始筹划上线flink on k8s服务，做了一些基础性的调研工作。&lt;/p&gt;

&lt;h2 id=&quot;flink-on-k8s&quot;&gt;flink on k8s&lt;/h2&gt;

&lt;p&gt;我们在github上搜索了不少关于flink on k8s的资料，基本上都不太靠谱，所以基础镜像方面我们&lt;/p&gt;

&lt;p&gt;是自己制作的，这个过程非常耗时，但事后来看非常的必要，我们对flink有了更为深入的了解。&lt;/p&gt;

&lt;p&gt;jobmanager和taskmanager我们是分为2个deployment，跟唯品会的方案不太相同（statefulset）。&lt;/p&gt;

&lt;p&gt;我们将flink的shell脚本、yaml配置等内容进行了通读，对其参数做了详细的标注，最后将这些&lt;/p&gt;

&lt;p&gt;参数进行合并，整理出大概20多个有效配置项和默认值，之后我们又将这些参数进行分类，大致分为&lt;/p&gt;

&lt;p&gt;两类：容器级参数和业务参数。&lt;/p&gt;

&lt;p&gt;举个例子：容器内存大小就属于容器级别参数，集群名称也属于容器级参数（相当于deploymentname）。&lt;/p&gt;

&lt;p&gt;每个taskmanager有多少个slot，就属于业务参数。jvm的各种堆大小属于容器内存大小的衍生参数，&lt;/p&gt;

&lt;p&gt;有一个统一的计算公式得到，并不进行传递。&lt;/p&gt;

&lt;p&gt;容器级别的参数由docker的env进行传递，业务参数通过http接口获得。&lt;/p&gt;

&lt;p&gt;所以我们的docker启动时，首先获取env中的参数，然后通过脚本调http接口获得一个json，再结合&lt;/p&gt;

&lt;p&gt;本地的default.property文件中的默认值，进行合并，最后渲染配置文件和shell脚本，这里用了一个&lt;/p&gt;

&lt;p&gt;python的模板引擎，类似javaweb中的velocity，freemaker等。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;联通&lt;/h2&gt;

&lt;p&gt;flinkjobmanager的HA是通过zk来实现的，taskmanager和jobmanager之间的服务发现也要基于zk，&lt;/p&gt;

&lt;p&gt;所以在docker模式下是可以很容易组成集群的。比较麻烦的一个问题是jobmanager的webui port，&lt;/p&gt;

&lt;p&gt;由于我们的k8s上是使用物理机IP的，所以port是非常宝贵的资源，如果我们的port只能使用固定的端口，&lt;/p&gt;

&lt;p&gt;意味着一台物理机只能启动一个jobmanager，所以在启动docker时，我们要指定要container的port，&lt;/p&gt;

&lt;p&gt;这样k8s就能根据port来调度，不会发生冲突。为了解决port资源的问题，我们向k8s申请了专用port范围，&lt;/p&gt;

&lt;p&gt;我们的集群随机从范围里选择一个port来启动任务。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;内存使用比率&lt;/h2&gt;

&lt;p&gt;内存比例相关的参数是我们调试最多的一个环节，flink启动脚本中关于内存的计算非常复杂，&lt;/p&gt;

&lt;p&gt;下面列举一些核心的点：&lt;/p&gt;

&lt;p&gt;networkbuffer的大小&lt;/p&gt;

&lt;p&gt;是否使用堆外内存来支持flink框架的计算逻辑&lt;/p&gt;

&lt;p&gt;堆外与堆内的分配比例&lt;/p&gt;

&lt;p&gt;jvm各个分代的大小&lt;/p&gt;

&lt;p&gt;垃圾回收器的选择&lt;/p&gt;

</description>
        <pubDate>Sun, 19 Aug 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-08-19-flink</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-08-19-flink</guid>
        
        
        <category>flink</category>
        
      </item>
    
      <item>
        <title>估算Job的余量</title>
        <description>&lt;p&gt;在运维日志分发任务的时候，经常碰到一些突发性的数据量增大，导致分发资源不足，最后数据延迟了。&lt;/p&gt;

&lt;p&gt;之前，只能依赖监控Kafka的消息积压情况，如果积压非常多，就增加任务的副本数或者增大任务的&lt;/p&gt;

&lt;p&gt;资源规格（分配更多的cpu和内存）。增加多少副本或者资源只能凭经验去判断，无法量化，每个任务的&lt;/p&gt;

&lt;p&gt;数据单条大小是不一样的，连接的HDFS集群也是不一样的，所处的网络环境也会有差异，这些变量都&lt;/p&gt;

&lt;p&gt;导致了无法用一个固定的指标衡量或者预警。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;自旋时间&lt;/h2&gt;

&lt;p&gt;经过一段时间的思考和测试我们选择了一个叫做自旋时间的指标来做衡量。&lt;/p&gt;

&lt;p&gt;我们的任务中使用了ringbuffer作为生产消费模型中的缓冲队列，在高资源规格的任务中，会有多个&lt;/p&gt;

&lt;p&gt;并行的ringbuffer。之前我的blog提到过，我们在选择哪一条channel时有一个复合策略，就是roundrobin&lt;/p&gt;

&lt;p&gt;+余量最大。当source下游的所有ringbuffer都处于full状态时，source就一直处于wait状态（自旋），&lt;/p&gt;

&lt;p&gt;这个自旋的时间被我们统计了下来，通过nanotime的delta来统计。如果每分钟里自旋的累加时间超过5s，&lt;/p&gt;

&lt;p&gt;我们就会认为该任务的消费能力低于生产能力，需要扩大资源规格，具体含义就是写HDFS的性能低于拉&lt;/p&gt;

&lt;p&gt;kafka的性能。在我们的测试中，3个channel同时写HDFS，能超过单线程拉kafka的速度。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;告警的策略&lt;/h2&gt;

&lt;p&gt;有一些kafka的数据是定期上报的，所以会存在短期数据量很大的情况，如果我们设置的报警策略非常敏感&lt;/p&gt;

&lt;p&gt;的话，会导致频繁告警，所以经过一段时间的微调，我们最终选定15分钟内有10次超过5s的自旋，就任务&lt;/p&gt;

&lt;p&gt;该任务需要增加资源规格了。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;副本与资源规格&lt;/h2&gt;

&lt;p&gt;需要注意的是增加副本和增加资源规格其实都能达到降低任务繁忙度的目的，但是增加资源规格从整体&lt;/p&gt;

&lt;p&gt;上来说是更为经济的选择，增加副本还依赖于kafka的partition数量。&lt;/p&gt;

&lt;p&gt;在运维这批任务的时候，我们会有一个基本的原则：&lt;/p&gt;

&lt;p&gt;1、副本数不超过kafka分区数的二分之一，保证至少还有一倍的临时扩容余量。&lt;/p&gt;

&lt;p&gt;2、如果是单副本任务，优先增加副本。&lt;/p&gt;

&lt;p&gt;3、副本数超过5个的话，尽量扩资源规格。&lt;/p&gt;

&lt;p&gt;4、如果单个任务平均每秒处理的数据超过50m，则选择增加副本数量。&lt;/p&gt;

&lt;p&gt;另外，这个自旋时间并不能替代数据延迟的告警，只是用来衡量单任务是否达到性能瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;未来&lt;/h2&gt;

&lt;p&gt;这些扩容的规则还在慢慢积累，不断的在增加Metric的丰富度，希望未来可以通过对metric的实时处理，&lt;/p&gt;

&lt;p&gt;得到运营决策，将系统的运营工作自动化起来。&lt;/p&gt;
</description>
        <pubDate>Sun, 01 Jul 2018 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-07-01-spin</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-07-01-spin</guid>
        
        
        <category>scale</category>
        
        <category>spin</category>
        
      </item>
    
      <item>
        <title>618备战</title>
        <description>&lt;p&gt;在JD第一次参加了大促的备战工作，我所负责的系统也要应对618当天的流量洪峰。&lt;/p&gt;

&lt;p&gt;这半年开发的三个实时相关的工具都上线了，binlog采集、准实时hive表数据、日志分发。&lt;/p&gt;

&lt;p&gt;在618备战期间，我对这半年的开发有很多的思考，主要是平台运营、工具特性，性能与监控等方面。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;平台型和工具型&lt;/h2&gt;

&lt;p&gt;作为一个工具，你可以只关心功能，关心配置的灵活度，水平扩展能力和性能的极限。&lt;/p&gt;

&lt;p&gt;但是作为一个平台型的东西，这些是远远不够的。&lt;/p&gt;

&lt;p&gt;比如平台上的任务一定是绝大多数任务压力很小，有少数任务流量压力很大。&lt;/p&gt;

&lt;p&gt;业务上也会出现，某些任务只在一些特定的时间流量压力大，而其他时间流量很低。&lt;/p&gt;

&lt;p&gt;数据的表现上有条数多，或者单条体积大。甚至还要考虑有一些任务所使用的网络比其他任务要差一些。&lt;/p&gt;

&lt;p&gt;单从工具的角度来说，我们的三个tool的表现都非常优异，每种任务都可以使用3-4个性能档位配置，&lt;/p&gt;

&lt;p&gt;工具的配置非常灵活，暴露的可调节的参数也非常多，核心逻辑采用状态机等设计模式，&lt;/p&gt;

&lt;p&gt;非常好的兼容能力。性能上也做了诸多优化，binlog采集的性能甚至超过了正常从库同步的性能。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;临时解决问题&lt;/h2&gt;

&lt;p&gt;在任务上线的初期，经历了两周的阵痛，每天都有很多细碎的问题，比如某些任务延迟了，&lt;/p&gt;

&lt;p&gt;某些任务长时间无流量，某些任务经常报错等等。经过两周对监控的调整，大大降低了告警的次数，&lt;/p&gt;

&lt;p&gt;并且摸索出一套简单的运营办法，可以解决绝大多数问题。但是偶尔还是会有特例，&lt;/p&gt;

&lt;p&gt;在备战618的过程中，还是需要花非常多的时间去梳理核心任务和数据量大的任务，提前进行扩容。&lt;/p&gt;

&lt;p&gt;甚至在618前的一两个小时里，我们还在梳理增长迅猛的任务，并适当的扩容。&lt;/p&gt;

&lt;p&gt;这种工作无论你花多少时间，多么有耐心，还是会有遗漏的情况，因为这些都是实时数据或者&lt;/p&gt;

&lt;p&gt;准实时数据，临时人工处理一定已经晚了。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;基础准备&lt;/h2&gt;

&lt;p&gt;因为现实业务上的复杂性，所以我们的任务本身需要做一些基础的准备。&lt;/p&gt;

&lt;p&gt;第一、做好水平扩展能力，可以通过增加一个docker副本来实现性能的水平扩展。&lt;/p&gt;

&lt;p&gt;第二、当不能通过水平扩展提升能力时，可以通过增加资源来提供能力，比如cpu、mem。&lt;/p&gt;

&lt;p&gt;其实很多业务系统经常是增加了资源并不能提升处理能力，或者说不满足预期。&lt;/p&gt;

&lt;p&gt;第三、Job本身能够估算出自己的余量，这一点非常重要，能做到这一点的少之又少。&lt;/p&gt;

&lt;p&gt;第四、能够借助像docker、k8s等方式对运行时环境进行管理。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;未来&lt;/h2&gt;

&lt;p&gt;在产品端开发和运行时任务之间应该有一个运营质量管理系统，将监控和伸缩容量等结合起来，&lt;/p&gt;

&lt;p&gt;通过规则集或者AI相关技术，来解决需要大量人力时间的工作。&lt;/p&gt;

&lt;p&gt;在docker盛行的年代，传统运维方式发生了变化，监控也随之发生了变化，&lt;/p&gt;

&lt;p&gt;同样运营方法也在产生着巨大的变化，接来下几个月我会投入Flink相关的开发工作中，&lt;/p&gt;

&lt;p&gt;建设一个实时计算的平台，运营的实时化问题，会被我当成一个业务场景来对待，&lt;/p&gt;

&lt;p&gt;希望今年年底前能够彻底拜托人工运营的现状。&lt;/p&gt;
</description>
        <pubDate>Tue, 19 Jun 2018 20:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-06-16-618</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-06-16-618</guid>
        
        
        <category>618</category>
        
      </item>
    
      <item>
        <title>聊聊对channel的认识</title>
        <description>&lt;p&gt;今天聊一聊channel的话题，最近几年从事的工作内容都跟消息流和数据通道有关系，&lt;/p&gt;

&lt;p&gt;结合最近项目的调优，说说我对channel的认识。&lt;/p&gt;

&lt;h2 id=&quot;ringbuffer&quot;&gt;ringbuffer&lt;/h2&gt;

&lt;p&gt;说到channel，就不能不提disrupter的ringbuffer，最近几年非常热门的开源项目。&lt;/p&gt;

&lt;p&gt;ringbuffer强调对象的高度复用，减少GC的次数，有无数据的timeout的回调，方便实现batch逻辑，&lt;/p&gt;

&lt;p&gt;多种策略的选择，应对多种业务时效场景。&lt;/p&gt;

&lt;h2 id=&quot;selector&quot;&gt;selector&lt;/h2&gt;

&lt;p&gt;无论是实时流计算，还是消息通道，都会有一个类似selector的组件，基于某些字段对消息进行分类，&lt;/p&gt;

&lt;p&gt;将event投递到不同的channel中，主要是为了解决一定程度的顺序问题，&lt;/p&gt;

&lt;p&gt;比如将相同主键的消息顺序输出。flume中的selector就是针对header中的某个key进行mapping，&lt;/p&gt;

&lt;p&gt;实现了灵活强大的分流功能。当然使用key也尽量不要出现热点，要不然整体的消费能力就会提早到达瓶颈。&lt;/p&gt;

&lt;h2 id=&quot;broadcast&quot;&gt;broadcast&lt;/h2&gt;

&lt;p&gt;broadcast功能在channel中也是非常实用的，比如checkpoint相关的event向下游传递，如果下游有&lt;/p&gt;

&lt;p&gt;多个channel，那么就需要一个broadcast功能。在业务中broadcast的应用也非常广，比如上游计算&lt;/p&gt;

&lt;p&gt;导致了某种meta信息的变更，就可以通过broadcast的功能通知下游，这种方式比借助外部存储要高效的多，&lt;/p&gt;

&lt;p&gt;而且天然不用解决多version的问题。&lt;/p&gt;

&lt;h2 id=&quot;balance&quot;&gt;balance&lt;/h2&gt;

&lt;p&gt;如果你碰到了一拆N的channel场景，并且对数据的顺序不那么敏感时，肯定希望能最大限度的发挥下游&lt;/p&gt;

&lt;p&gt;channel的能力，很多人都在selector上选择roundrobin，或者是基于timestamp取模的方法，如果下游&lt;/p&gt;

&lt;p&gt;的消费能力非常强，这种做法是没有问题的。但如果你在下游sink是重IO类型的，这种做法就不会达到&lt;/p&gt;

&lt;p&gt;你想要的效果了。你会发现流经常会因为某一条下游的blocking，导致整条链路卡主，你使用了多条通道&lt;/p&gt;

&lt;p&gt;，但性能并没有成线性增长。这个问题在我的分发kafka消息至hdfs时就碰到了，一旦HDFS的响应速度下降&lt;/p&gt;

&lt;p&gt;整个job的吞吐量大大降低，增加channel并没有解决这个问题，只能增加jvm实例来解决，非常耗资源。&lt;/p&gt;

&lt;p&gt;这时，你需要的是类似负载均衡方面的WLC算法的解决方案。首先，你需要让下游的channel暴露出自己&lt;/p&gt;

&lt;p&gt;的余量。然后根据余量的情况选择最为空闲的节点，这样你增加的channel才会有意义。当然如果你有&lt;/p&gt;

&lt;p&gt;大量的broadcast消息，也会极大的影响你的性能。&lt;/p&gt;
</description>
        <pubDate>Thu, 10 May 2018 18:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2018-05-10-channel</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2018-05-10-channel</guid>
        
        
        <category>channel</category>
        
        <category>hdfs</category>
        
        <category>kafka</category>
        
      </item>
    
  </channel>
</rss>
