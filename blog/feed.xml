<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pei LiPing's Blog</title>
    <description>Augur
</description>
    <link>http://peiliping.github.io/blog/</link>
    <atom:link href="http://peiliping.github.io/blog/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 01 Nov 2020 16:17:12 +0800</pubDate>
    <lastBuildDate>Sun, 01 Nov 2020 16:17:12 +0800</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>double streaming</title>
        <description>&lt;p&gt;今天聊聊双流的实时计算问题，我个人觉得算是流处理中最复杂的一个场景了。&lt;/p&gt;

&lt;p&gt;想要在两个Source同时作为input时，保证流处理的恰好一次计算，仅仅依靠chandy-lamport是不够的。&lt;/p&gt;

&lt;p&gt;两个Source的input交叉顺序是随机的行为，在业务上有严格的恰好一次要求，且代码还做不到&lt;/p&gt;

&lt;p&gt;顺序不敏感时，怎么办呢？&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;合并流&lt;/h2&gt;

&lt;p&gt;最简单的办法是将两条流合并，将不确定的交叉行为给确定了,这样可以用chandy-lamport了。&lt;/p&gt;

&lt;p&gt;合并流会增加一个merge任务和一个新的kafka topic，相当于增加了一个环节、增加了一点延迟。&lt;/p&gt;

&lt;p&gt;虽然会浪费一点资源，但是简单高效。如果两个Source的Merge依据是Event Time，那么情况还&lt;/p&gt;

&lt;p&gt;要更复杂一些。单纯的把两条流Merge在一起并不能解决问题，还需要在一个时间窗口内进行缓冲排序。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;流转批&lt;/h2&gt;

&lt;p&gt;将流式处理转为批量处理也是可以解决这个问题的，以窗口1min为例。将两个Source的数据都&lt;/p&gt;

&lt;p&gt;缓存1min（内存里或者依赖外部存储），当窗口关闭时发起对这期间的数据进行处理。&lt;/p&gt;

&lt;p&gt;在处理时可指定某种确定的数据排序方法，保证处理顺序的一致性。这种方式只适用于数据量不大，&lt;/p&gt;

&lt;p&gt;对时效性要求不高的场景。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;限位器&lt;/h2&gt;

&lt;p&gt;不想合并出一个新的topic，也不想延迟太高，就需要在Streaming的模式下进行两个流的协调和缓冲。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;驱动流&lt;/h3&gt;

&lt;p&gt;首先，在两个Source中选出来一个，作为时间驱动的，要求是他的数据时间具备单调性，也就是有序的。&lt;/p&gt;

&lt;p&gt;在实际生产中，我们很难保证写入kafkaTopic里的数据一直单调有序，除非启用transaction。&lt;/p&gt;

&lt;p&gt;但是我个人觉得使用事务造成的问题远大于收益。我这里说的单调性和有序是相对的，应该叫整体有序，&lt;/p&gt;

&lt;p&gt;可以接受局部的重复和回退。当我们实时处理这个Source的数据时，有内存状态记录这上一条的时间&lt;/p&gt;

&lt;p&gt;或者序号进行过滤，一旦发生了回退或者重复的数据就直接跳过。这样我们在经过filter后，就得到了&lt;/p&gt;

&lt;p&gt;一条绝对有序的驱动数据流A，（后面简称为A）。注意，如果A在一定时间内没有数据产生，最好写入&lt;/p&gt;

&lt;p&gt;带有时间戳的心跳数据包，以方便时间管理的协调控制后。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;被动流&lt;/h3&gt;

&lt;p&gt;如果另外一个Source也是和驱动流一样，具备整体有序特征的话，就非常简单了。经过filter后，&lt;/p&gt;

&lt;p&gt;与A汇合入同一个Operator中，只需要按照两个流的时间进度进行控制，以A的时间为主，这个时候&lt;/p&gt;

&lt;p&gt;心跳数据包的作用就体现出来了，防止被动流的数据提前被加载进来。&lt;/p&gt;

&lt;p&gt;如果被动流的数据，不具备单调性，就需要建立缓冲空间，将被动流的数据变的有序起来。&lt;/p&gt;

&lt;p&gt;A可以适当延迟个几秒，等带被动流的窗口排序工作完成后再去驱动时间。同时也就是对被动流提出来&lt;/p&gt;

&lt;p&gt;新的要求，那就是虽然可以乱序，但是时效性必须高。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;协调器&lt;/h3&gt;

&lt;p&gt;一共需要四个组件：驱动流缓存池、被动流缓存池、被动流增量加载方法、被流动回溯方法。&lt;/p&gt;

&lt;p&gt;缓存驱动流最近N条数据，主要是给被动流严重delay数据进行回溯时使用的。&lt;/p&gt;

&lt;p&gt;如果被动数据没有严重delay，那么就写入到被动流缓冲池中。&lt;/p&gt;

&lt;p&gt;驱动流有新数据时，触发被流动缓冲池中的数据进行增量加载。&lt;/p&gt;

&lt;h3 id=&quot;section-6&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;上面提到的方案有很大的局限性，还需要进一步的实践的检验。&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Oct 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-10-14-doublestreaming</guid>
        
        
        <category>streaming</category>
        
      </item>
    
      <item>
        <title>transaction</title>
        <description>&lt;p&gt;最近工作中大量的使用了Spring、Mybatis、JDBC的事务，这里稍作一下总结。&lt;/p&gt;

&lt;h2 id=&quot;springtransaction&quot;&gt;Spring的Transaction&lt;/h2&gt;

&lt;p&gt;现在Spring的Annotation就可以完成基本的事务配置，比起以前复杂的xml，确实方便了很多。&lt;/p&gt;

&lt;p&gt;网上能搜到很多介绍Spring-Transaction的，主要是讲事务的隔离级别和传播性，这里就不多说了。&lt;/p&gt;

&lt;p&gt;提醒大家去看看Spring-Transaction失效的N个原因，避免事务没有完整性的执行。&lt;/p&gt;

&lt;p&gt;我们犯的错是同class的非事务方法去调用事务方法，导致事务不起作用。&lt;/p&gt;

&lt;h2 id=&quot;jdbc&quot;&gt;JDBC事务&lt;/h2&gt;

&lt;p&gt;mysql有个参数是flush_tx_commit需要关注一下，可能会影响你的事务性能。&lt;/p&gt;

&lt;p&gt;事务中的操作肯定是串行的，所以还是尽量想办法让事务精简，能在事务外执行的尽量不要放进来。&lt;/p&gt;

&lt;p&gt;比如序列化、反序列化等耗时的操作，尽量提前准备好，再开启事务。单个事务的执行时间越短，&lt;/p&gt;

&lt;p&gt;多事务并发的性能才会更理想。在一些情况下，开启事务和逐个提交比起来会快一些，&lt;/p&gt;

&lt;p&gt;但不要为了追求这种性能而过分的扩大事务范围。锁的范围变大，大概率会与一些业务上的并发发生冲突，&lt;/p&gt;

&lt;p&gt;不利于整体性能的提升。&lt;/p&gt;

&lt;h2 id=&quot;mybatis&quot;&gt;Mybatis&lt;/h2&gt;

&lt;p&gt;这次项目中用的是mybatis-plus，在压测的时候关注了一下，性能确实很一般。&lt;/p&gt;

&lt;p&gt;但是因为项目本身的业务复杂性，直接使用jdbc确实很不方便。第一个性能问题就是分表plugin，&lt;/p&gt;

&lt;p&gt;做表名替换的开销比较大，从sql的参数中提取表名也可能比较慢。第二个性能问题就是通过mybatis&lt;/p&gt;

&lt;p&gt;处理数据，会导致比较频繁的ygc。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;之前并没有太多关于事务类型业务的开发经验，这次优化能提升两三倍还是很满意的。&lt;/p&gt;
</description>
        <pubDate>Sun, 27 Sep 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-09-27-transaction</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-09-27-transaction</guid>
        
        
        <category>transaction</category>
        
      </item>
    
      <item>
        <title>ta4j2</title>
        <description>&lt;p&gt;上期讲了我在造一个类似ta4j的轮子，这次讲讲造轮子过程中的一些体会。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;关于回调的使用场景&lt;/h2&gt;

&lt;p&gt;在我的实现中，回调是贯穿始终的，我之前使用这种模式的次数不多，稍微总结一下。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;粗粒度的K线可以由细粒度的K线回调触发更新，非常方便回测实现。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;指标可以由K线或者其他指标的回调触发更新，保证数据的实时更新。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;当K线触发完所有指标的更新后，会触发Rule的回调，进行Rule的判断。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;规则判断后如果为True，可触发规则结果的回调，比如发消息、更新趋势、信号等。&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section-1&quot;&gt;多依赖指标的回调问题&lt;/h2&gt;

&lt;p&gt;某些指标的计算依赖多个其他指标的计算结果，于是更新这个指标的回调就有了路径问题，比如MACD。&lt;/p&gt;

&lt;p&gt;可以看看PairIndicatorSeries这个源码，构造时会进行指标的回调血缘分析。&lt;/p&gt;

&lt;p&gt;多依赖指标的回调，并不需要人为设定，根据分析结果可自动选择最佳的触发时机（最近的共同父节点）。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;指标重用问题&lt;/h2&gt;

&lt;p&gt;如果两个指标都使用了某一条K线的MA(20)作为构成的一部分，那么这个MA(20)是可以共用的。&lt;/p&gt;

&lt;p&gt;这样可以极大的减少计算量和内存开销，最典型的就是取K线的Close，极为常用。&lt;/p&gt;

&lt;p&gt;指标在某一时刻无论重复计算多少次，其结果都是一样的。当然重复计算我们也想尽量避免，&lt;/p&gt;

&lt;p&gt;在回调中提供了一个sequence，可以辅助去重。&lt;/p&gt;

&lt;p&gt;指标的构造和相同功能节点的自动复用，目前这块设计是有问题的，还需要重构打磨。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;规则重用问题&lt;/h2&gt;

&lt;p&gt;上面提到的指标是可以复用的，但规则绝对不可以，在Manager中有是否使用过的检查。&lt;/p&gt;

&lt;p&gt;Rule在某一时刻重复判断，其结果可能是不一样的，比如翻转规则、连续N次等。&lt;/p&gt;

&lt;p&gt;举几个复杂规则的例子，有同时判断2条指标的规则，比如快慢指标的上穿判断；&lt;/p&gt;

&lt;p&gt;还有由两个规则叠加起来组成的规则集，比如逻辑与运算。规则比指标要略微复杂一点。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;订单与仓位&lt;/h2&gt;

&lt;p&gt;订单的止盈止损也是个复杂问题，比如简单的止盈止损、追踪止盈止损等。&lt;/p&gt;

&lt;p&gt;在波动幅度较大的标的物上，追踪止盈止损并不能起到很好的效果，需要谨慎使用。&lt;/p&gt;

&lt;p&gt;控制盈利率与仓位比重是相对合理的做法，这样才能相对安全的达到收益最大化。&lt;/p&gt;

&lt;p&gt;在回测中，经常有人会为了收益最大化而过度调节止盈止损，基本上都是过拟合效果。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;最后&lt;/h2&gt;

&lt;p&gt;ta4j的话题就到此为止了，我个人认为简单的量化交易策略是不可能挣钱的，&lt;/p&gt;

&lt;p&gt;但是通过程序化的方式，做个辅助交易助手还是非常现实可行的。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Aug 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-08-18-ta4j2</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-08-18-ta4j2</guid>
        
        
        <category>ta4j</category>
        
      </item>
    
      <item>
        <title>ta4j</title>
        <description>&lt;p&gt;今天介绍一个比较有意思的java库叫&lt;a href=&quot;https://github.com/ta4j/ta4j&quot;&gt;ta4j&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;最近一段时间接触了一些跟程序化交易、自动交易有关的业务，每天跟k线、指标打交道，&lt;/p&gt;

&lt;p&gt;无意中在github上发现了一个叫ta4j的java库，虽然不是很成熟，但还是很有借鉴意义的。&lt;/p&gt;

&lt;p&gt;从综合成本上来说，不建议用java来搞程序化交易，python和nodejs更为合适一些，&lt;/p&gt;

&lt;p&gt;公共库更为成熟，而且更利于支持可视化的需求。&lt;/p&gt;

&lt;h2 id=&quot;ta4j&quot;&gt;ta4j主要提供了如下功能：&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;k线&lt;/li&gt;
    &lt;li&gt;指标&lt;/li&gt;
    &lt;li&gt;判断规则、规则的逻辑运算&lt;/li&gt;
    &lt;li&gt;策略&lt;/li&gt;
    &lt;li&gt;回测、报告&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;section&quot;&gt;关于指标&lt;/h2&gt;

&lt;p&gt;k线的技术指标主要是基于k线值的算术运算得来的，比如均值、加权均值、差值、方差等。&lt;/p&gt;

&lt;p&gt;指标会随着k线的实时变化而变化，其表现形式跟K线是一样的，存储在一个时间序列数组里。&lt;/p&gt;

&lt;p&gt;ta4j在保存时间序列数据时采用的ArrayList，这个地方不是很好。当超过一定数量时，&lt;/p&gt;

&lt;p&gt;就需要淘汰最老的数据，会不断触发ArrayList的arraycopy，感觉换成ringbuffer更合理。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;关于规则、策略&lt;/h2&gt;

&lt;p&gt;基于K线和指标线的逻辑判断就是规则，比如在股票里我们常听说的多头排列。&lt;/p&gt;

&lt;p&gt;这种图形上的形态，需要转化为代码，成为一个识别规则(match)。ta4j里提供了一些常见的规则，&lt;/p&gt;

&lt;p&gt;比如交叉、向上突破、向下突破、阈值等等。&lt;/p&gt;

&lt;p&gt;因为在K线的使用和识别中，会应用到很多个规则的组合，所以规则需要支持逻辑运算(and/or/xor)。&lt;/p&gt;

&lt;p&gt;针对买入和卖出的一系列规则的集合，我们可以称之为策略，这个是整个程序交易的核心。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;关于回测&lt;/h2&gt;

&lt;p&gt;程序化交易里面回测是非常重要的一个环节，回测越接近真实，你的策略盈利的可能性就越大。&lt;/p&gt;

&lt;p&gt;最理想的回测就是将实时数据录制下来，这是最准的了。但是如此明细的数据是很难拿到的，&lt;/p&gt;

&lt;p&gt;大多数是用1min的k线替代明细数据。其实这样的数据是严重失真的，1min里的变化压缩为一个点。&lt;/p&gt;

&lt;p&gt;我一般的做法是将1min的k线点拆分为4个点，分别是开、高、低、收，依次写入数据集合进行测试。&lt;/p&gt;

&lt;p&gt;这样能尽量还原一个k线点的轨迹，比如一个K线点是上涨的，那就是开、低、高、收，依次变化。&lt;/p&gt;

&lt;p&gt;另外还要特别注意，在回测的时候用到的数据会不会是“未来的数据”，可能会让程序未卜先知。&lt;/p&gt;

&lt;p&gt;比如短线指标基于15min，中线是1hour的指标，在判断15min的指标规则时，1hour指标就是“未来”。&lt;/p&gt;

&lt;p&gt;我一般在回测的时候，其他粒度的k线会用1min的聚合而来，保持与1minK线的同步关系。&lt;/p&gt;

&lt;h2 id=&quot;watchdog-hubble&quot;&gt;watchdog-hubble&lt;/h2&gt;

&lt;p&gt;ta4j虽然给了我很多启发，但是问题还是非常多的。所以我自己造了一个轮子，放在watchdog下。&lt;/p&gt;

&lt;p&gt;结合上个月介绍的websocket和bark，我自己用起来还是非常顺手的。&lt;/p&gt;
</description>
        <pubDate>Mon, 20 Jul 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-07-20-ta4j</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-07-20-ta4j</guid>
        
        
        <category>ta4j</category>
        
      </item>
    
      <item>
        <title>websocket</title>
        <description>&lt;p&gt;最近一个多月在和websocket打交道，这次来总结一下最近一阶段的工作吧。&lt;/p&gt;

&lt;h2 id=&quot;hydra&quot;&gt;hydra&lt;/h2&gt;

&lt;p&gt;三月份写了一篇关于netty的blog，介绍了我写的一个小项目叫&lt;a href=&quot;https://github.com/peiliping/hydra&quot;&gt;hydra&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;经过这几个月的完善，已经可以作为一个websocket的压测工具了。&lt;/p&gt;

&lt;p&gt;这两次压测实践中，单实例可以施压5W个并发连接数，满足大多数测试需求。&lt;/p&gt;

&lt;p&gt;通过参数可以配置心跳消息、订阅指令等，满足业务测试的需求。&lt;/p&gt;

&lt;h2 id=&quot;watchdog&quot;&gt;watchdog&lt;/h2&gt;

&lt;p&gt;使用netty作为websocket的client，如果解决重连重试的问题呢？&lt;/p&gt;

&lt;p&gt;在实际业务中，要考虑网络不稳定导致的websocket中断问题。websocket中断后，&lt;/p&gt;

&lt;p&gt;要重新建立连接，还要将业务的订阅指令重新发送一遍。&lt;/p&gt;

&lt;p&gt;在netty的中断分为两种情况，一个是创建连接就直接失败了，一种是在运行中突然中断。&lt;/p&gt;

&lt;p&gt;这两种情况分别有回调的接口可以捕获，而后触发延迟重连。可以参考&lt;a href=&quot;https://github.com/peiliping/watchdog&quot;&gt;watchdog&lt;/a&gt;的实现。&lt;/p&gt;

&lt;h2 id=&quot;bark&quot;&gt;Bark&lt;/h2&gt;

&lt;p&gt;最近无意间发现了一个iOS的App叫Bark，可以自定义手机通知提醒的消息。&lt;/p&gt;

&lt;p&gt;举个例子，你写了一个爬虫监控实时获取某只股票的价格，当他发生剧烈波动的时候，&lt;/p&gt;

&lt;p&gt;给自己的手机发送一条提醒，来提醒自己关注股票。那么如何给手机发送免费的消息呢？&lt;/p&gt;

&lt;p&gt;Bark就可以满足这个需求，安装Bark的App后，你会获得一个Url（包含一个uuid）。&lt;/p&gt;

&lt;p&gt;执行这个Url，你的手机就会收到来自Bark的通知消息了，消息的内容来自Url参数。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;提醒助手&lt;/h2&gt;

&lt;p&gt;将watchdog和Bark结合在一起，实现了一个小功能。&lt;/p&gt;

&lt;p&gt;订阅Huobi的BTC行情信息，经过计算，将满足剧烈波动条件的消息通过Bark发送到手机上。&lt;/p&gt;
</description>
        <pubDate>Mon, 29 Jun 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-06-29-websocket</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-06-29-websocket</guid>
        
        
        <category>websocket</category>
        
        <category>netty</category>
        
      </item>
    
      <item>
        <title>state</title>
        <description>&lt;p&gt;这次来介绍一下fevernova的state功能，与flink的state功能很类似，&lt;/p&gt;

&lt;p&gt;flink的state是保证恰好一次计算的核心点，当然至少一次也需要state。&lt;/p&gt;

&lt;h2 id=&quot;fevernovastate&quot;&gt;fevernova的state用途&lt;/h2&gt;

&lt;p&gt;之前fevernova都是作为数据传输框架，对state的依赖并不高。&lt;/p&gt;

&lt;p&gt;需要state用来存储kafka的offset，或者binlog的filename和position。&lt;/p&gt;

&lt;p&gt;在实现kafka To HDFS模块的时候，也会将关闭的文件列表和commit保存在state里，&lt;/p&gt;

&lt;p&gt;减少重复文件的产生，实现恰好一次。类似于flink的rollingfilesink。&lt;/p&gt;

&lt;h2 id=&quot;state&quot;&gt;state保存的位置&lt;/h2&gt;

&lt;p&gt;因为只保存少量的meta信息，所以state就简单的保存在文件系统里。&lt;/p&gt;

&lt;p&gt;如果需要提高可用性，就通过类似Nas的方式进行目录挂载。这类方案都是非常成熟的。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;计算状态&lt;/h2&gt;

&lt;p&gt;在无意中，发现了一个开源项目&lt;a href=&quot;https://github.com/OpenHFT&quot;&gt;OpenHFT&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;其中的项目质量还是比较高的，利用其中的序列化、持久化的库进行state的保存非常方便。&lt;/p&gt;

&lt;p&gt;让内存中保存状态的对象实现WriteBytesMarshallable和ReadBytesMarshallable接口，&lt;/p&gt;

&lt;p&gt;根据需求自定义序列化和反序列化的方法，就可以完成state的读写操作。&lt;/p&gt;

&lt;p&gt;简单测试了一下性能还是非常好的。fevernova中的exchange模块中有具体的使用。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;去重&lt;/h2&gt;

&lt;p&gt;单纯依靠Chandy-Lamport算法实现的流计算框架并不能在实际需求中完全实现恰好一次计算。&lt;/p&gt;

&lt;p&gt;比如写入kafka的数据有重复，通常就在计算逻辑中去重，这也意味着更多的cpu和内存开销。&lt;/p&gt;

&lt;p&gt;fevernova在exchange模块中实现了一个基于Roaringbitmap的滑窗过滤器，通过统一的去重。&lt;/p&gt;

&lt;p&gt;压缩的位图信息也会随着state进行保存，重启时可以完美衔接。&lt;/p&gt;
</description>
        <pubDate>Mon, 11 May 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-05-11-state</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-05-11-state</guid>
        
        
        <category>state</category>
        
      </item>
    
      <item>
        <title>DB2DB</title>
        <description>&lt;p&gt;几年前写过一个叫meepo的小项目，用来解决一些临时导表的需求。&lt;/p&gt;

&lt;p&gt;很意外居然还有网友在git上提issue，看来需求还是很广泛的。&lt;/p&gt;

&lt;p&gt;meepo整体设计有很多问题，而且bug也比较多，不建议使用。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;改版重构&lt;/h2&gt;

&lt;p&gt;最近又碰到了类似的需求，从mysql的一种表抽取部分字段写到另外一张表。&lt;/p&gt;

&lt;p&gt;因为是定时数据处理，而且需要全量数据的导出，所以基于JDBC是最简单的方案。&lt;/p&gt;

&lt;p&gt;在数据摄取和分发部分，沿用了fevernova框架，这也比meepo更佳成熟稳定。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;流批一体&lt;/h2&gt;

&lt;p&gt;这两年有一个特别火的概念叫流批一体，flink社区也在努力统一数据底层模型。&lt;/p&gt;

&lt;p&gt;fevernova是一个类似flink的流式数据处理框架，之前也没试过做批处理。&lt;/p&gt;

&lt;p&gt;这次为了实现批处理的需求，为source增加了jobfinished的指令。&lt;/p&gt;

&lt;p&gt;当source完成预定处理，会等待一个checkpoint的周期，就结束任务了。&lt;/p&gt;

&lt;h2 id=&quot;rdb&quot;&gt;RDB&lt;/h2&gt;

&lt;p&gt;这次还需要支持postgre，虽然JDBC是通用的，但是Datasource和Sql拼装，&lt;/p&gt;

&lt;p&gt;都有很大的差别，需要重新设计扩展。&lt;/p&gt;

&lt;p&gt;举几个例子，table的scheme在mysql和postgre是不同的，在解决upsert场景的时候，&lt;/p&gt;

&lt;p&gt;mysql可以用replace，pg则要写on conflict子句。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;性能&lt;/h2&gt;

&lt;p&gt;这次性能优化并没有meepo那么激进，尽量做通用的优化，减少对依赖的侵入性修改。&lt;/p&gt;

&lt;p&gt;Postgre有一个unlogged类型的table，可以极大的提高写入速度，&lt;/p&gt;

&lt;p&gt;大家可以根据自己的需求酌情使用。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;规范&lt;/h2&gt;

&lt;p&gt;使用JDBC做增量数据导出，有一些需要注意的地方，比如：&lt;/p&gt;

&lt;p&gt;1、不能使用delete&lt;/p&gt;

&lt;p&gt;2、insert和update操作要更新updatetime字段&lt;/p&gt;

&lt;p&gt;3、需要对updatetime做索引&lt;/p&gt;

&lt;p&gt;4、有long型的自增主键，方便遍历&lt;/p&gt;
</description>
        <pubDate>Tue, 28 Apr 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-04-28-DB2DB</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-04-28-DB2DB</guid>
        
        
        <category>jdbc</category>
        
        <category>database</category>
        
      </item>
    
      <item>
        <title>hydra</title>
        <description>&lt;p&gt;之前写过一篇关于netty的blog，经过几次梳理，hydra项目的代码基本稳定了。&lt;/p&gt;

&lt;p&gt;hydra项目分为client和server两部分。&lt;/p&gt;

&lt;h2 id=&quot;client&quot;&gt;client&lt;/h2&gt;

&lt;p&gt;client用于weboscket的功能和性能测试，短时间可以轻松建立50000个连接。&lt;/p&gt;

&lt;p&gt;可以通过参数指定subscribe的字符串，也可以定期发送指令维持heartbeat。&lt;/p&gt;

&lt;p&gt;如果server返回的数据是gzip压缩的binary数据，也是支持解压缩的。&lt;/p&gt;

&lt;p&gt;我尝试用client订阅了huobi的行情数据，配置启动参数就可以完成。其他同类网站也是没有问题的。&lt;/p&gt;

&lt;p&gt;当然不要用它来对别人的网站进行压力测试，会被封IP的。&lt;/p&gt;

&lt;h2 id=&quot;server&quot;&gt;server&lt;/h2&gt;

&lt;p&gt;server主要是一个推送服务的基础框架。&lt;/p&gt;

&lt;p&gt;推送的消息来源是从redis的topic中拉去的，采用redission的client。&lt;/p&gt;

&lt;p&gt;从消息中提取部分字段信息，构建nameSpace，通过ChannelManager进行推送。&lt;/p&gt;

&lt;p&gt;推送的消息格式，目前只支持text，未来需要考虑支持binary的压缩格式。&lt;/p&gt;

&lt;p&gt;除了以nameSpace为基础的推送外，还实现了基于Uid的推送模式，之前的blog已经介绍过原理了。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;websocket推送可以应用的领域非常广，弹幕、聊天室、股票行情软件等等。&lt;/p&gt;

&lt;p&gt;基于hydra的基础，后面要尝试一下netty的优化实践。&lt;/p&gt;
</description>
        <pubDate>Wed, 18 Mar 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-03-18-hydra</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-03-18-hydra</guid>
        
        
        <category>hydra</category>
        
        <category>netty</category>
        
      </item>
    
      <item>
        <title>时序索引</title>
        <description>&lt;p&gt;这次讲一个索引设计的例子，数据具有时序特征，比如，监控数据、股票k线数据等等。&lt;/p&gt;

&lt;p&gt;如果时序数据同时还具备多维度，那就需要druid、clickhouse来完成。&lt;/p&gt;

&lt;p&gt;像股票k线这样的数据，就没有太多的维度，按照股票的ID和K线的类型进行过滤即可。&lt;/p&gt;

&lt;p&gt;下面介绍一个股票K线数据索引的设计思路。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;时间戳&lt;/h2&gt;

&lt;p&gt;要做时序数据首先要定义时间字段，最简单的unixtime，精度到秒，比如1583769600。&lt;/p&gt;

&lt;p&gt;用4字节的int来存储unixtime，现在是可以存下的，未来还可以使用十几年，如果还不放心，&lt;/p&gt;

&lt;p&gt;可以考虑用无符号整形，足够用到退休了。&lt;/p&gt;

&lt;h2 id=&quot;k&quot;&gt;k线的类型&lt;/h2&gt;

&lt;p&gt;股票的K线主要是按照时间区分的，1min、3min、5min….一共十几种，1个字节就够了。&lt;/p&gt;

&lt;h2 id=&quot;id&quot;&gt;股票的ID&lt;/h2&gt;

&lt;p&gt;short对应的是两个字节的整形，最大可以到32768，无符号可以到65536。&lt;/p&gt;

&lt;p&gt;国内的A股也就四五千只股票的规模，考虑到可能退市等因素，2个字节也足够了。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;合并&lt;/h2&gt;

&lt;p&gt;为这三个字段建联合唯一索引，肯定是可以满足需求的，但是这样很铺张浪费。&lt;/p&gt;

&lt;p&gt;我的目标是用一个long型字段，来满足需求。long是8个字节，三个字段加起来是7个字节，&lt;/p&gt;

&lt;p&gt;还可以留下一个byte作为扩展。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
 ((long) this.symbolId &amp;lt;&amp;lt; 40) | ((long) this.type.value &amp;lt;&amp;lt; 32) | (long) this.timeSeq

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;合并成一个long型的字段，可以节省索引空间，高效的使用btree来处理Between，使用bitmap优化也没问题。&lt;/p&gt;

&lt;h2 id=&quot;query&quot;&gt;Query&lt;/h2&gt;

&lt;p&gt;在检索的时候，股票ID是确定的，k线类型也是确定的，时间是一个范围查询。&lt;/p&gt;

&lt;p&gt;将时间范围的起点和终点，通过上面的合并方法进行处理，可以得到两个long值，&lt;/p&gt;

&lt;p&gt;Between就可以搞定了。&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Feb 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-02-24-timeindex</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-02-24-timeindex</guid>
        
        
        <category>index</category>
        
      </item>
    
      <item>
        <title>netty</title>
        <description>&lt;p&gt;新年第一篇，写点有关netty和websocket推送相关的。&lt;/p&gt;

&lt;p&gt;这些年用到netty的项目挺多的，但也一直没有仔细研究一下，最近在做websocket的测试，&lt;/p&gt;

&lt;p&gt;所以就用netty分别写了client端和server端，只是一个简单的应用。&lt;/p&gt;

&lt;h2 id=&quot;hydra&quot;&gt;hydra&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/peiliping/hydra&quot;&gt;Hydra&lt;/a&gt; 项目在这里，代码细节我就不介绍了，大家在网上都可以搜到。&lt;/p&gt;

&lt;h2 id=&quot;websocket&quot;&gt;关于websocket的压缩&lt;/h2&gt;

&lt;p&gt;我在性能测试过程中，曾经开启过WebSocketServerCompressionHandler，发生了缓慢内存泄露。&lt;/p&gt;

&lt;p&gt;经排查，Jvm堆内、外都没有问题，但free -m显示的内存剩余一直在降低，直到被OS-Kill掉。&lt;/p&gt;

&lt;p&gt;在netty的git-issue上搜索找到了相关信息（见ISSUE-9803）。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;推送&lt;/h2&gt;

&lt;p&gt;说到推送，肯定会提到socket.io这个项目，这几年非常火，值得研究一下。&lt;/p&gt;

&lt;p&gt;推送里有一个非常常见的问题，就是同一个账号的多端推送。&lt;/p&gt;

&lt;p&gt;举例：你在手机和网页都登录了，当你的账号有新的订单成交时，都应获得通知消息的推送。&lt;/p&gt;

&lt;p&gt;所以在推送服务器的内存中，就要维护一个Map，Key为Uid，Value是多端的Channels集合。&lt;/p&gt;

&lt;p&gt;在编写这段逻辑时，我希望尽量少的使用lock，但是uid所在的entry，需要保持原子性。&lt;/p&gt;

&lt;p&gt;如果手机端退出登录和网页端登录，在同一时刻发生，维护这个channels在map中的原子性就非常困难。&lt;/p&gt;

&lt;p&gt;解决方案有两种：&lt;/p&gt;

&lt;p&gt;1、当channels集合为空时，并不把它从map中remove掉，会导致Map中有一些垃圾信息。&lt;/p&gt;

&lt;p&gt;2、使用ConcurrentSkipListMap来替代Map&amp;lt;String,Set&lt;string&gt;&amp;gt;的嵌套结构。&lt;/string&gt;&lt;/p&gt;

&lt;p&gt;最后我选择了方案2，在Hydra项目中的Server模块ChannelManager中。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;结束&lt;/h2&gt;

&lt;p&gt;疫情还在继续，大家保重。&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Jan 2020 10:00:00 +0800</pubDate>
        <link>http://peiliping.github.io/blog/archivers/2020-01-06-netty</link>
        <guid isPermaLink="true">http://peiliping.github.io/blog/archivers/2020-01-06-netty</guid>
        
        
        <category>netty</category>
        
      </item>
    
  </channel>
</rss>
