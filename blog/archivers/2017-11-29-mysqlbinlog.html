<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>关于Mysql的Binlog抽取 « Pei LiPing's Blog</title>
  <meta name="description" content="这个月换了工作，双十一之前入职了京东大数据平台——实时数据组。">

  <link rel="stylesheet" href="/blog/css/main.css">
  <link rel="canonical" href="http://peiliping.github.io/blog/archivers/2017-11-29-mysqlbinlog">
  <link rel="alternate" type="application/rss+xml" title="Pei LiPing's Blog" href="http://peiliping.github.io/blog/feed.xml" />
</head>


  <body>

    <header class="header">
  <div class="wrapper">
    <a class="site-title" href="/blog/">Pei LiPing's Blog</a>
    <nav class="site-nav">
      
        
      
        
        <a class="page-link" href="/blog/about/">About</a>
        
      
        
        <a class="page-link" href="/blog/category/">Category</a>
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    </nav>
  </div>
</header>

    <div class="page-content">
      <div class="wrapper">
        <div class="col-main">
          <div class="post">

  <header class="post-header">
    <h1 class="post-title">关于Mysql的Binlog抽取</h1>
    <p class="post-meta">Nov 29, 2017</p>
  </header>

  <article class="post-content">
    <p>这个月换了工作，双十一之前入职了京东大数据平台——实时数据组。</p>

<p>着手关于MysqlBinlog相关系统的重构工作，这次就讲讲Binlog吧。</p>

<h2 id="binlog">Binlog转实时数据流的开源动态</h2>

<p>伪装MysqlSlave来获取MysqlBinlog的技术这几年已经非常普及了，很多中等规模的公司都有相关的</p>

<p>基础技术组件，大多数是基于阿里几年前开源的Canal项目，在此基础上进行二次开发，将数据写入Kafka</p>

<p>或者其他MQ系统中去，阿里云的RDS还提供类似的服务，也非常省心。</p>

<p>17年年初的时候我也有意要做类似的项目，所以已经进行了最基础的技术选型和调研。</p>

<p>Java系中最早的binlog开源项目有tungsten-replicator 、open-replicator等，后来都慢慢废弃了。</p>

<p>之后Canal几乎统一了这个领域，但是阿里的这个开源项目最近几年的更新频率很一般。</p>

<p>最近两年比较新的项目有mysql-time-machine，zendesk的maxwell都不错。</p>

<p>shyiko的mysql-binlog-connector-java是一个BinlogClient的超精简内核，也被很多开源项目采用。</p>

<h2 id="mysqlbinlog">Mysql的Binlog</h2>

<p>Mysql的Binlog协议和格式我就不多介绍了，网上可以搜到很多。</p>

<p>值得注意的时候，Mysql一定要配置成Row模式的，而且image需要配置成Full模式的。</p>

<p>我采用shyiko的mysql-binlog-connector-java的方案进行了一下性能测试，可以达到80M/s。</p>

<h2 id="section">数据解析</h2>

<p>shyiko的mysql-binlog-connector-java已经将数据解析成Java类型了，接下来只需要针对公司的规范</p>

<p>进行数据的清洗和整理即可，最后转成标准序列化格式，比如AVRO、Pb、Json等。</p>

<p>这中间性能损耗最大的地方就是序列化的开销了，要考虑异步或者多线程流等方式解决。</p>

<p>在开发解析逻辑时碰到了不少细节问题，用shyiko的mysql-binlog-connector-java解析的数据与canal</p>

<p>有一些细小的差别，比如datetime和timestamp字段解析的结果不一样，有可能受时区的影响；</p>

<p>还有像text类型的字段是byte数组，需要自己指定charset转为string；decimal也有差异，需要使用</p>

<p>numberformat进行格式化，group设置为false，并且setMinimumFractionDigits(1)。</p>

<h2 id="kafka">写Kafka有序</h2>

<p>将数据写到Kafka的速度是非常快的，但是因为Binlog的特殊性，需要一些设计，来保证数据的有序。</p>

<p>Kafka的Client会把收到的数据根据meta进行进行重新组织，按照broker的使用情况进行分批发送。</p>

<p>所以我们要根据业务情况指定Kafka的MessageKey，将相同业务含义的数据写到同一个Partition</p>

<p>下，保证有序，乱序会导致最新值被老值覆盖。</p>

<p>在写Kafka的过程中难免会有一些失败的情况发生，错误的重试机制由Kafka来保证，并且要强制设置</p>

<p>ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION = 1，以防止重试时发生数据顺序错误。</p>

<h2 id="task">Task的结构</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">P1</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">B1</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">P2</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">B2</th>
      <th style="text-align: center"> </th>
      <th style="text-align: center">P3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">单线程拉Binlog</td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">Ringbuffer</td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">单线程转化成AVRO对象</td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">Ringbuffer</td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">序列化并发送Kafka</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: center"> </td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">Ringbuffer</td>
      <td style="text-align: center">&gt;</td>
      <td style="text-align: center">序列化并发送Kafka</td>
    </tr>
  </tbody>
</table>

<p>注释：P一般对应一个线程，B对应一个Disrupter的Ringbuffer。</p>

<p>P1和P2环节的性能都非常好，所以采用的是单线程，阶段并行模式。</p>

<p>P3阶段采用并行模式，P2处理好的数据根据一些key进行选择，路由到N个B2中去，一般可以用库表名称。</p>

<p>压测时，这个Task跑起来之后可以让负载达到400%，基本上把Cpu资源跑满了。</p>

<h2 id="section-1">持久化位点信息</h2>

<p>什么是位点信息？</p>

<p>简单来说就是binlog的filename和offset，为了保证at least once，</p>

<p>我们需要定期记录消费的位置，以便任务重启之后，继续消费，不丢数据（可有少量的重复）。</p>

<p>如果P3阶段是单线程的，那么记录位点非常简单，提交kafka成功后，记录最后一条数据的offset，</p>

<p>可以异步刷到远程存储中去，防止阻塞数据流。可是，现在P3阶段是多线程的，如何记录位点呢？</p>

<p>定期让P2对所有的B2发送一条相同的含有位点信息的心跳包（位点值为P2最后处理的一条数据的位点）</p>

<p>通过这种方式，将各个P3的信息进行更新，每次P3将数据成功发送到Kafka后就将其中的心跳包记录下来，</p>

<p>作为一个可信的回退点，注意这个心跳包一定要在数据流中流转，起到挤压数据的作用，</p>

<p>防止某些P3无数据的情况发生。相关代码参考我的sucker项目，这里就不介绍代码细节了。</p>

<p>解决这个问题的思路源于Flink介绍文章中的一段话：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Stream Barrier是Flink分布式Snapshotting中的核心元素，它会作为数据流的记录被同等看待，

被插入到数据流中，将数据流中记录的进行分组，并沿着数据流的方向向前推进。每个Barrier会携带

一个Snapshot ID，属于该Snapshot的记录会被推向该Barrier的前方。因为Barrier非常轻量，所以

并不会中断数据流。带有Barrier的数据流。

</code></pre>
</div>

  </article>
  
  




</div>

        </div>
        <div class="col-second">
          <div class="col-box col-box-author">
  <img class="avatar" src="//www.gravatar.com/avatar/your_email_md5?d=mm&s=135" alt="Pei LiPing">
  <div class="col-box-title name">Pei LiPing</div>
  <p>The Cabin Of Pei LiPing.</p>
  <p class="contact">
    
    
    
    <a href="mailto:peilipingplp@gmail.com">Email</a>
    
  </p>
</div>

<div class="col-box">
  <div class="col-box-title">Newest Posts</div>
  <ul class="post-list">
    
      <li><a class="post-link" href="/blog/archivers/2018-08-19-flink">初识flink</a></li>
    
      <li><a class="post-link" href="/blog/archivers/2018-07-01-spin">估算Job的余量</a></li>
    
      <li><a class="post-link" href="/blog/archivers/2018-06-16-618">618备战</a></li>
    
      <li><a class="post-link" href="/blog/archivers/2018-05-10-channel">聊聊对channel的认识</a></li>
    
      <li><a class="post-link" href="/blog/archivers/2018-04-15-maintain">项目问题总结</a></li>
    
  </ul>
</div>

<div class="col-box post-toc hide">
  <div class="col-box-title">TOC</div>
</div>
        </div>
      </div>
    </div>

    <footer class="footer">
<div class="wrapper">
&copy; 2016 Pei LiPing
</div>
</footer>

<script src="//upcdn.b0.upaiyun.com/libs/jquery/jquery-1.9.0.min.js"></script>
<script src="/blog/js/easybook.js"></script>

  </body>

</html>
